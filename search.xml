<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Nginx 实用配置</title>
      <link href="/9/ngninx/ck0669dbn0003agaae2mjtqqn/"/>
      <url>/9/ngninx/ck0669dbn0003agaae2mjtqqn/</url>
      
        <content type="html"><![CDATA[<h3 id="1-防盗链"><a href="#1-防盗链" class="headerlink" title="1 防盗链"></a>1 防盗链</h3><p>相关配置：</p><blockquote><p><a href="http://nginx.org/en/docs/http/ngx_http_referer_module.html" target="_blank" rel="noopener">valid_referers</a></p></blockquote><pre><code>location ~* \.(gif|jpg|png)$ {    # 只允许 192.168.0.1 请求资源    valid_referers none blocked 192.168.0.1;    if ($invalid_referer) {       rewrite ^/ http://$host/logo.png;    }}</code></pre><h3 id="2-根据文件类型设置过期时间"><a href="#2-根据文件类型设置过期时间" class="headerlink" title="2 根据文件类型设置过期时间"></a>2 根据文件类型设置过期时间</h3><pre><code>location ~.*\.css$ {    expires 1d;    break;}location ~.*\.js$ {    expires 1d;    break;}location ~* \.(js|css|jpg|jpeg|gif|png)$ {    expires 1h;    break;}</code></pre><h3 id="3-禁止访问某个目录"><a href="#3-禁止访问某个目录" class="headerlink" title="3 禁止访问某个目录"></a>3 禁止访问某个目录</h3><pre><code>location ~* \.(txt|doc)${    root /opt/htdocs/site/test;    deny all;}</code></pre><h3 id="4-静态资源访问"><a href="#4-静态资源访问" class="headerlink" title="4 静态资源访问"></a>4 静态资源访问</h3><pre><code>http {    # 这个将为打开文件指定缓存，默认是没有启用的，max 指定缓存数量，    # 建议和打开文件数一致，inactive 是指经过多长时间文件没被请求后删除缓存。    open_file_cache max=204800 inactive=20s;    # open_file_cache 指令中的inactive 参数时间内文件的最少使用次数，    # 如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个    # 文件在inactive 时间内一次没被使用，它将被移除。    open_file_cache_min_uses 1;    # 这个是指多长时间检查一次缓存的有效信息    open_file_cache_valid 30s;    # 默认情况下，Nginx的gzip压缩是关闭的， gzip压缩功能就是可以让你节省不    # 少带宽，但是会增加服务器CPU的开销哦，Nginx默认只对text/html进行压缩 ，    # 如果要对html之外的内容进行压缩传输，我们需要手动来设置。    gzip on;    gzip_min_length 1k;    gzip_buffers 4 16k;    gzip_http_version 1.0;    gzip_comp_level 2;    gzip_types text/plain application/x-javascript text/css application/xml;    server {        listen       80;        server_name www.test.com;        charset utf-8;        root   /data/www.test.com;        index  index.html index.htm;    }}</code></pre><h3 id="5-日志配置"><a href="#5-日志配置" class="headerlink" title="5 日志配置"></a>5 日志配置</h3><h4 id="5-1-日志字段说明"><a href="#5-1-日志字段说明" class="headerlink" title="5.1 日志字段说明"></a>5.1 日志字段说明</h4><p>字段 | 说明 |<br>— | — | —<br>remote_addr 和 http_x_forwarded_for | 客户端 IP 地址<br>remote_user | 客户端用户名称<br>request | 请求的 URI 和 HTTP 协议<br>status | 请求状态<br>body_bytes_sent | 返回给客户端的字节数，不包括响应头的大小<br>bytes_sent | 返回给客户端总字节数<br>connection | 连接的序列号<br>connection_requests | 当前同一个 TCP 连接的的请求数量<br>msec | 日志写入时间。单位为秒，精度是毫秒<br>pipe | 如果请求是通过HTTP流水线(pipelined)发送，pipe值为“p”，否则为“.”<br>http_referer | 记录从哪个页面链接访问过来的<br>http_user_agent | 记录客户端浏览器相关信息<br>request_length | 请求的长度（包括请求行，请求头和请求正文）<br>time_iso8601 | ISO8601标准格式下的本地时间<br>time_local | 记录访问时间与时区</p><h4 id="5-1-access-log-访问日志"><a href="#5-1-access-log-访问日志" class="headerlink" title="5.1 access_log 访问日志"></a>5.1 access_log 访问日志</h4><pre><code>http {    log_format  access  '$remote_addr - $remote_user [$time_local] $host "$request" '                  '$status $body_bytes_sent "$http_referer" '                  '"$http_user_agent" "$http_x_forwarded_for" "$clientip"';    access_log  /srv/log/nginx/talk-fun.access.log  access;}</code></pre><h4 id="5-2-error-log-日志"><a href="#5-2-error-log-日志" class="headerlink" title="5.2 error_log 日志"></a>5.2 error_log 日志</h4><pre><code>error_log  /srv/log/nginx/nginx_error.log  error;# error_log /dev/null; # 真正的关闭错误日志http {    # ...}</code></pre><h3 id="6-反向代理"><a href="#6-反向代理" class="headerlink" title="6 反向代理"></a>6 反向代理</h3><pre><code>http {    include mime.types;    server_tokens off;    ## 配置反向代理的参数    server {        listen    8080;        ## 1. 用户访问 http://ip:port，则反向代理到 https://github.com        location / {            proxy_pass  https://github.com;            proxy_redirect     off;            proxy_set_header   Host             $host;            proxy_set_header   X-Real-IP        $remote_addr;            proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;        }        ## 2.用户访问 http://ip:port/README.md，则反向代理到        ##   https://github.com/zibinli/blog/blob/master/README.md        location /README.md {            proxy_set_header  X-Real-IP  $remote_addr;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_pass https://github.com/zibinli/blog/blob/master/README.md;        }    }}</code></pre><h3 id="7-负载均衡"><a href="#7-负载均衡" class="headerlink" title="7 负载均衡"></a>7 负载均衡</h3><pre><code>http {    upstream test.net {        ip_hash;        server 192.168.10.13:80;        server 192.168.10.14:80  down;        server 192.168.10.15:8009  max_fails=3  fail_timeout=20s;        server 192.168.10.16:8080;    }    server {        location / {            proxy_pass  http://test.net;        }    }}</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Ngninx </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 负载均衡 </tag>
            
            <tag> Nginx </tag>
            
            <tag> 反向代理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟着大彬读源码 - Redis 10 - 对象编码之整数集合</title>
      <link href="/8/redis/yuanma/ck0669dre0033agaa25vkwigp/"/>
      <url>/8/redis/yuanma/ck0669dre0033agaa25vkwigp/</url>
      
        <content type="html"><![CDATA[<p>整数集合是 Redis 集合键的底层实现之一。当一个集合只包含整数值元素，并且元素数量不多时，Redis 就会使用整数集合作为集合键的底层实现。</p><h3 id="1-整数集合的实现"><a href="#1-整数集合的实现" class="headerlink" title="1 整数集合的实现"></a>1 整数集合的实现</h3><p>整数集合是 Redis 用于保存整数值的集合抽象数据结构。它可以保存类型为 int16_t、int32_t、int64_t 的整数值，并且保证集合中不会出现重复元素。</p><p>每个 <code>intset.h/intset</code> 结构表示一个整数集合：</p><pre><code>typedef struct intset {    uint32_t encoding;    uint32_t length;    int8_t contents[];} intset;</code></pre><ul><li>encding：编码方式</li><li>length：集合包含的元素数量</li><li>contents[]：保存元素的数组</li></ul><p>contents 数组是整数集合的底层实现：整数集合的每个元素都是 contents 数组的一个数组项，各个项在数组中按值的大小从小到大有序排列，并且数组中不包含重复项。</p><p>length 属性记录了整数集合记录的<strong>元素数量</strong>，也就是 contents 数组的长度。</p><p>虽然 intset 结构将 contents 属性声明为 int8_t 类型的数组，但实际上 contents 数组并不保存任何 int8_t 类型的值，contents 数组的真正类型取决于 encoding 属性的值，比如：如果 encoding 属性的值为 INTSET_ENC_INT16，那么 contents 就是一个 int16_t 类型的数组，数组里的每个项都是一个 int16_t 类型的整数值，取值范围为：[-32768-32767]（2^(16-1)）。</p><p>与之类似，encoding 的值为 INTSET_ENC_INT32，那么数组每项的取值范围为：[-2147483648, 2147483647]（2^(32-1）。</p><p>这里也引发了一个问题，当我们对一个 encoding 为 INTSET_ENC_INT8 的 intset，插入 129 时（int8_t 的取值范围是 [-128, 127]），会出现什么？</p><p>这也就引发了 intset 的升级操作。与之对应，也有降级操作。接下来，我们来详细认识下 intset 的升降级操作。</p><h3 id="2-升级操作"><a href="#2-升级操作" class="headerlink" title="2 升级操作"></a>2 升级操作</h3><p>每当我们要将一个新元素添加到整数集合时，如果新元素的类型比整数集合的 encoding 类型大，整数集合就需要先进行<strong>升级操作（upgrade）</strong>，然后才能将新元素添加到整数集合中。</p><p>整个升级操作源码如下：</p><pre><code>// intset.c/intsetUpgradeAndAdd()/* Upgrades the intset to a larger encoding and inserts the given integer. */static intset *intsetUpgradeAndAdd(intset *is, int64_t value) {    uint8_t curenc = intrev32ifbe(is-&gt;encoding);    uint8_t newenc = _intsetValueEncoding(value);    int length = intrev32ifbe(is-&gt;length);    int prepend = value &lt; 0 ? 1 : 0;    /* First set new encoding and resize */    is-&gt;encoding = intrev32ifbe(newenc);    is = intsetResize(is,intrev32ifbe(is-&gt;length)+1);    /* Upgrade back-to-front so we don't overwrite values.     * Note that the "prepend" variable is used to make sure we have an empty     * space at either the beginning or the end of the intset. */    while(length--)        _intsetSet(is,length+prepend,_intsetGetEncoded(is,length,curenc));    /* Set the value at the beginning or the end. */    if (prepend)        _intsetSet(is,0,value);    else        _intsetSet(is,intrev32ifbe(is-&gt;length),value);    is-&gt;length = intrev32ifbe(intrev32ifbe(is-&gt;length)+1);    return is;}</code></pre><p>升级整数集合并添加新元素，共分为三步进行：</p><ol><li><strong>扩展底层数组大小</strong>。根据新元素的类型，扩展整数集合底层数组的大小，并为新元素分配空间。</li><li><strong>元素转换，并保持原有顺序</strong>。将底层数组现有的所有元素，都转换成与新元素相同的类型，并将转换后的元素放在正确的位置上，保证原有顺序不发生改变。</li><li>将新元素添加到底层数组中。</li></ol><p>此外，一旦因插入新元素引发升级操作，就说明新插入的元素比集合中现有的所有元素的长度大，所以这个新元素的值要么大于所有现有元素（正值），要么就小于所有现有元素（负值），那么：</p><ul><li>在新元素<strong>小于</strong>所有现有元素时，新元素就会被放在底层数组的最开头的位置，即索引为 0 的位置；</li><li>在新元素<strong>大于</strong>所有现有元素时，新元素就会被放在底层数组的最末尾的位置；</li></ul><h3 id="3-升级优势"><a href="#3-升级优势" class="headerlink" title="3 升级优势"></a>3 升级优势</h3><p>整数集合的升级策略主要有以下两个好处：</p><ol><li>提示整数集合的灵活性；</li><li>尽可能的节约内存；</li></ol><h4 id="3-1-提示灵活性"><a href="#3-1-提示灵活性" class="headerlink" title="3.1 提示灵活性"></a>3.1 提示灵活性</h4><p>因为 C 语言是静态类型语言，为了避免类型错误，我们通常不会将两种不同类型的值放在同一个数据结构中。</p><p>但是，因为有了升级操作，整数集合可以通过它来自适应新元素，所以我们可以随意地将 int16_t、int32_t、和 int64_t 类型的整数添加到集合中，而不必担心出现类型错误，大大的提升了整数集合的灵活性。</p><h4 id="3-2-节约内存"><a href="#3-2-节约内存" class="headerlink" title="3.2 节约内存"></a>3.2 节约内存</h4><p>当然，要让一个数组可以同时保存 int16_t、int32_t、和 int64_t 类型的整数值，我们可以粗暴的直接使用 int64_t 类型的数组作为整数集合的底层实现，来保存不同类型的值。但是，这样一来，即使添加到集合中的都是 int16_t、int32_t 类型的值，数组也都是需要使用 int64_t 类型的空间去保存，出现浪费内存的情况。</p><p>而整数集合的升级操作，既能同时保存三种不同类型的值，又可以确保升级操作只会在有需要的时候进行，达到节省内存的目的。</p><h3 id="4-交、并、差集算法"><a href="#4-交、并、差集算法" class="headerlink" title="4 交、并、差集算法"></a>4 交、并、差集算法</h3><p>Redis 中的集合实现了<strong>交、并、差</strong>等操作，相关操作可参加 <code>t_set.c</code>，其中<br><code>sinterGenericCommand()</code> 实现交集，<code>sunionDiffGenericCommand()</code> 实现并集和差集。</p><p>它们都能同时对多个集合进行元素。当对多个集合进行差集运算时，会先计算出第一个和第二个集合的差值，然后再与第三个集合做差集，依次类推。</p><p>接下来，我们一起来认识下三个操作的实现思路。</p><h4 id="4-1-交集"><a href="#4-1-交集" class="headerlink" title="4.1 交集"></a>4.1 交集</h4><p>计算交集的过程大概可以分为三部分：</p><ol><li>检查各个集合，对于不存在的集合当做空集来处理。一旦出现空集，则不用继续计算了，最终的交集就是空集。</li><li>对各个集合按照元素个数由少到多进行排序。这个排序有利于后面计算的时候从最小的集合开始，需要处理的元素个数较少。</li><li>对排序后第一个集合（也就是最小集合）进行遍历，对于它的每一个元素，依次在后面的所有集合中进行查找。只有在所有集合中都能找到的元素，才加入到最后的结果集合中。</li></ol><p>需要注意的是，上述第 3 步在集合中进行查找，对于 intset 和 dict 的存储来说时间复杂度分别是 O(log n) 和 O(1)。但由于只有小集合才使用 intset，所以可以粗略地认为 intset 的查找也是常数时间复杂度的。</p><h4 id="4-2-并集"><a href="#4-2-并集" class="headerlink" title="4.2 并集"></a>4.2 并集</h4><p>并集操作最简单，只要遍历所有集合，将每一个元素都添加到最后的结果集中即可。向集合中添加元素会自动去重，所以插入的时候无需检测元素是否已存在。</p><h4 id="4-3-差集"><a href="#4-3-差集" class="headerlink" title="4.3 差集"></a>4.3 差集</h4><p>计算差集有两种可能的算法，它们的时间复杂度有所区别。</p><p><strong>第一种算法</strong></p><p>对第一个集合进行遍历，对于它的每一个元素，依次在后面的所有集合中进行查找。只有在所有集合中都找不到的元素，才加入到最后的结果集合中。</p><p>这种算法的时间复杂度为O(N*M)，其中N是第一个集合的元素个数，M是集合数目。</p><p><strong>第二种算法</strong></p><ol><li>将第一个集合的所有元素都加入到一个中间集合中。</li><li>遍历后面所有的集合，对于碰到的每一个元素，从中间集合中删掉它。</li><li>最后中间集合剩下的元素就构成了差集。</li><li>这种算法的时间复杂度为O(N)，其中N是所有集合的元素个数总和。</li></ol><p>在计算差集的开始部分，会先分别估算一下两种算法预期的时间复杂度，然后选择复杂度低的算法来进行运算。还有两点需要注意：</p><ul><li>在一定程度上优先选择第一种算法，因为它涉及到的操作比较少，只用添加，而第二种算法要先添加再删除。</li><li>如果选择了第一种算法，那么在执行该算法之前，Redis的实现中对于第二个集合之后的所有集合，按照元素个数由多到少进行了排序。这个排序有利于以更大的概率查找到元素，从而更快地结束查找。</li></ul><h3 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h3><ol><li>整数集合是集合键的底层实现之一。</li><li>整数集合以有序、无重复的方式保存集合元素。在有需要时，会根据新添加元素的类型，改变底层数组的类型。</li><li>升级操作提升了操作的灵活性，并尽可能的节约了内存。</li><li>集合可以进行<strong>交、并、差</strong>集操作。</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 源码 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> intset </tag>
            
            <tag> 整数集合 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟着大彬读源码 - Redis 9 - 对象编码之 三种list</title>
      <link href="/8/redis/yuanma/ck0669dsx003oagaavfdmgiz0/"/>
      <url>/8/redis/yuanma/ck0669dsx003oagaavfdmgiz0/</url>
      
        <content type="html"><![CDATA[<p>Redis 底层使用了 ziplist、skiplist 和 quicklist 三种 list 结构来实现相关对象。顾名思义，ziplist 更节省空间、skiplist 则注重查找效率，quicklist 则对空间和时间进行折中。</p><p>在典型的双向链表中，我们有称为<strong>节点</strong>的结构，它表示列表中的每个值。每个节点都有三个属性：指向列表中的前一个和下一个节点的指针，以及指向节点中字符串的指针。而每个值字符串值实际上存储为三个部分：一个表示长度的整数、一个表示剩余空闲字节数的整数以及字符串本身后跟一个空字符。</p><p>可以看到，链表中的每一项都占用独立的一块内存，各项之间用地址指针（或引用）连接起来。这种方式会带来大量的内存碎片，而且地址指针也会占用额外的内存。这就是普通链表的<strong>内存浪费</strong>问题。</p><p>此外，在普通链表中执行随机查找操作时，它的时间复杂度为 O(n)，这对于注重效率的 Redis 而言也是不可接受的。这是普通链表的<strong>查找效率太低</strong>问题。</p><p>针对上述两个问题，Redis 设计了<strong>ziplist（压缩列表）</strong>、<strong>skiplist（跳跃表）</strong>和<strong>快速链表</strong>进行相关优化。</p><h3 id="1-ziplist"><a href="#1-ziplist" class="headerlink" title="1 ziplist"></a>1 ziplist</h3><p>对于 ziplist，它要解决的就是<strong>内存浪费</strong>的问题。也就是说，它的设计目标就是是<strong>为了节省空间，提高存储效率</strong>。</p><p>基于此，Redis 对其进行了特殊设计，使其成为一个经过特殊编码的<strong>双向链表</strong>。将表中每一项存放在前后连续的地址空间内，一个 ziplist 整体占用一大块内存。它是一个表（list），但其实不是一个链表（linked list）。</p><p>除此之前，ziplist 为了在细节上节省内存，对于值的存储采用了变长的编码方式，大概意思是说，对于大的整数，就多用一些字节来存储，而对于小的整数，就少用一些字节来存储。</p><p>也正是为了这种高效率的存储，ziplist 有很多 bit 级别的操作，使得代码变得较为晦涩难懂。不过不要紧，我们本节的目标之一是为了<strong>了解 ziplist 对比普通链表，做了哪些优化，可以更好的节省空间</strong>。</p><p>接下来我们来正式认识下压缩列表的结构。</p><h4 id="1-1-压缩列表的结构"><a href="#1-1-压缩列表的结构" class="headerlink" title="1.1 压缩列表的结构"></a>1.1 压缩列表的结构</h4><p>一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。</p><p>图 1-1 展示了压缩列表的各个组成部分：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190723124326650_29558.png" alt="图 1-1：压缩列表的结构"></p><p>相关字段说明如下：</p><ul><li>zlbytes：4 字节，表示 ziplist 占用的字节总数（包括 zlbytes 本身占用的 4 个字节）。</li><li>zltail：4 字节，表示 ziplist 表中最后一项距离列表的起始地址有多少字节，也就是表尾节点的偏移量。通过此字段，程序可以快速确定表尾节点的地址。</li><li>zllen：2 字节：表示 ziplist 的节点个数。要注意的是，由于此字段只有 16bit，所以可表达的最大值为 2^16-1。一旦列表节点个数超过这个值，就要遍历整个压缩列表才能获取真实的节点数量。</li><li>entry：表示 ziplist 的节点。长度不定，由保存的内容决定。要注意的是，列表的节点（entry）也有自己的数据结构，后续会详细说明。</li><li>zlend：ziplist 的结束标记，值固定为 255，用于标记压缩列表的末端。</li></ul><p>图 1-2 展示了一个包含五个节点的压缩列表：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190725202858638_4824.png" alt="图 1-2：包含五个节点的压缩列表"></p><ul><li>列表 zlbytes 属性的值为 0xd2（十进制 210），表示压缩列表的总长为 210 字节。</li><li>列表 zltail 属性的值为 0xb3,（十进制 179），表示尾结点相比列表的起始地址有 179 字节的距离。假如列表的起始地址为 p，那么指针 p + 179 = entry5 的地址。</li><li>列表 zllen 属性的值为 0x5（十进制 5），表示压缩列表包含 5 个节点。</li></ul><h4 id="1-2-列表节点的结构"><a href="#1-2-列表节点的结构" class="headerlink" title="1.2 列表节点的结构"></a>1.2 列表节点的结构</h4><p>节点的结构源码如下（ziplist.c）：</p><pre><code>typedef struct zlentry {    unsigned int prevrawlensize, prevrawlen;    unsigned int lensize, len;    unsigned int headersize;    unsigned char encoding;    unsigned char *p;} zlentry;</code></pre><p>如图 1-3，展示了压缩列表节点的结构。</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190729125748351_27862.png" alt="图 1-3：压缩列表节点结构"></p><ul><li>prevrawlen：表示前一个节点占用的总字节数。此字段是为了让 ziplist 能够从后向前遍历。</li><li>encoding：此字段记录了节点的 content 属性中所保存的数据类型。</li><li>lensize：此字段记录了节点所保存的数据长度。</li><li>headersize：此字段记录了节点 header 的大小。</li><li>*p：此字段记录了指向节点保存内容的指针。</li></ul><h4 id="1-3-压缩列表如何节省了内存"><a href="#1-3-压缩列表如何节省了内存" class="headerlink" title="1.3 压缩列表如何节省了内存"></a>1.3 压缩列表如何节省了内存</h4><p>回到我们最开始对普通链表的认识，普通链表中，每个节点包：</p><ul><li>一个表示长度的整数</li><li>一个表示剩余空闲字节数的整数</li><li>字符串本身</li><li>结尾空字符。</li></ul><p>以图 1-4 为例：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190730095415325_22348.png" alt="图 1-4：普通链"></p><p>图 1-4 展示了一个普通链表的三个节点，这三个节点中，每个节点实际存储内容只有 1 字节，但是它们除了实际存储内容外，还都要有：</p><ul><li>3 个指针 - 占用 3 byte</li><li>2 个整数 - 占用 2 byte</li><li>内容字符串 - 占用 1 byte</li><li>结尾空字符的空间 - 占用 1 byte</li></ul><p>这样来看，存储 3 个字节的数据，至少需要 21 字节的开销。可以看到，这样的存储效率是很低的。</p><p>另一方面，普通链表通过前后指针来关联节点，地址不连续，多节点时容易产生内存碎片，降低了内存的使用率。</p><p>最后，普通链表对存储单位的操作粒度是 byte，这种方式在存储较小整数或字符串时，每个字节实际上会有很大的空间是浪费的。就像上面三个节点中，用来存储<strong>剩余空闲字节数的整数</strong>，实际存储空间只需要 1 bit，但是有了 1 byte 来表示剩余空间大小，这一个 byte 中，剩余 7 个 bit 就被浪费了。</p><p>那么，Redis 是如何使用 ziplist 来改造普通链表的呢？通过以下两方面：</p><p>一方面，ziplist <strong>使用一整块连续内存，避免产生内存碎片，提高了内存的使用率</strong>。</p><p>另一方面，ziplist <strong>将存储单位的操作粒度从 byte 降低到 bit</strong>，有效的解决了存储较小数据时，单个字节中浪费 bit 的问题。</p><h3 id="2-skiplist"><a href="#2-skiplist" class="headerlink" title="2 skiplist"></a>2 skiplist</h3><p>skiplist 是一种<strong>有序</strong>数据结构，它通过在每个节点中维持多个指向其他节点的指针，来达到快速访问节点的目的。</p><p>skiplist 本质上是一种查找结构，用于解决算法中的查找问题。即根据指定的值，快速找到其所在的位置。</p><p>此外，我们知道，”查找” 问题的解决方法一般分为两大类：<strong>平衡树</strong>和<strong>哈希表</strong>。有趣的是，skiplist 这种查找结构，因为其特殊性，并不在上述两大类中。但在大部分情况下，它的效率可以喝平衡树想媲美，而且跳跃表的实现要更为简单，所以有不少程序都使用跳跃表来代替平衡树。</p><p>本节没有介绍跳跃表的定义及其原理，有兴趣的童鞋可以参考<a href="https://lotabout.me/2018/skip-list/" target="_blank" rel="noopener">这里</a>。</p><p>认识了跳跃表是什么，以及做什么的，接下来，我们再来看下在 redis 中，是怎么实现跳跃表的。</p><p>在 <code>server.h</code> 中可以找到跳跃表的源码，如下：</p><pre><code>typedef struct zskiplist {    struct zskiplistNode *header, *tail;    unsigned long length;    int level;} zskiplist;typedef struct zskiplistNode {    robj *obj;    double score;    struct zskiplistNode *backward;    struct zskiplistLevel {        struct zskiplistNode *forward;        unsigned int span;    } level[];} zskiplistNode;</code></pre><p>Redis 中的 skiplist 和普通的 skiplist 相比，在结构上并没有太大不同，只是在一些细节上有以下差异：</p><ul><li>分数（score）可以重复。就是说 Redis 中的 skiplist 在分值字段上是允许重复的，而普通的 skiplist 则不允许重复。</li><li>第一层链表不是单向链表，而是双向链表。这种方式可以用倒序方式获取一个范围内的元素。</li><li>比较时，除了比较 score 之外，还比较数据本身。在 Redis 的 skiplist 中，数据本身的内容是这份数据的唯一标识，而不是由 score 字段做唯一标识。此外，当多个元素分数相同时，还需要根据数据内容进行字典排序。</li></ul><h3 id="3-quicklist"><a href="#3-quicklist" class="headerlink" title="3 quicklist"></a>3 quicklist</h3><p>对于 quicklist，在 <code>quicklist.c</code> 中有以下说明：</p><blockquote><p>A doubly linked list of ziplists</p></blockquote><p>它是一个双向链表，并且是一个由 ziplist 组成的双向链表。</p><p>相关源码结构可在 <code>quicklist.h</code> 中查找，如下：</p><pre><code>/* quicklistNode is a 32 byte struct describing a ziplist for a quicklist. * We use bit fields keep the quicklistNode at 32 bytes. * count: 16 bits, max 65536 (max zl bytes is 65k, so max count actually &lt; 32k). * encoding: 2 bits, RAW=1, LZF=2. * container: 2 bits, NONE=1, ZIPLIST=2. * recompress: 1 bit, bool, true if node is temporarry decompressed for usage. * attempted_compress: 1 bit, boolean, used for verifying during testing. * extra: 12 bits, free for future use; pads out the remainder of 32 bits */typedef struct quicklistNode {    struct quicklistNode *prev;    struct quicklistNode *next;    unsigned char *zl;    unsigned int sz;             /* ziplist size in bytes */    unsigned int count : 16;     /* count of items in ziplist */    unsigned int encoding : 2;   /* RAW==1 or LZF==2 */    unsigned int container : 2;  /* NONE==1 or ZIPLIST==2 */    unsigned int recompress : 1; /* was this node previous compressed? */    unsigned int attempted_compress : 1; /* node can't compress; too small */    unsigned int extra : 10; /* more bits to steal for future usage */} quicklistNode;/* quicklistLZF is a 4+N byte struct holding 'sz' followed by 'compressed'. * 'sz' is byte length of 'compressed' field. * 'compressed' is LZF data with total (compressed) length 'sz' * NOTE: uncompressed length is stored in quicklistNode-&gt;sz. * When quicklistNode-&gt;zl is compressed, node-&gt;zl points to a quicklistLZF */typedef struct quicklistLZF {    unsigned int sz; /* LZF size in bytes*/    char compressed[];} quicklistLZF;/* quicklist is a 32 byte struct (on 64-bit systems) describing a quicklist. * 'count' is the number of total entries. * 'len' is the number of quicklist nodes. * 'compress' is: -1 if compression disabled, otherwise it's the number *                of quicklistNodes to leave uncompressed at ends of quicklist. * 'fill' is the user-requested (or default) fill factor. */typedef struct quicklist {    quicklistNode *head;    quicklistNode *tail;    unsigned long count;        /* total count of all entries in all ziplists */    unsigned int len;           /* number of quicklistNodes */    int fill : 16;              /* fill factor for individual nodes */    unsigned int compress : 16; /* depth of end nodes not to compress;0=off */} quicklist;</code></pre><p>上面介绍链表的时候有说过，链表由多个节点组成。而对于 quicklist 而言，它的每一个节点都是一个 ziplist。quicklist 这样设计，其实就是我们篇头所说的，是一个空间和时间的折中。</p><p>ziplist 相比普通链表，主要优化了两个点：<strong>降低内存开销</strong>和<strong>减少内存碎片</strong>。正所谓，事物总是有两面性。ziplist 通过连续内存解决了普通链表的内存碎片问题，但与此同时，也带来了新的问题：<strong>不利于修改操作</strong>。</p><p>由于 ziplist 是一整块连续内存，所以每次数据变动都会引发一次内存的重分配。当在 ziplist 很大的时候，每次重分配都会出现大批量的数据拷贝操作，降低性能。</p><p>于是，结合了双向链表和 ziplist 的优点，就有了 quicklist。</p><p>quicklist 的基本思想就是，给每一个节点的 ziplist 分配合适的大小，避免出现因数据拷贝，降低性能的问题。这又是一个需要找平衡点的难题。我们先从存储效率上分析：</p><ul><li>每个 quicklist 节点上的 ziplist 越短，则内存碎片越多。而内存碎片多了，就很有可能产生很多无法被利用的内存小碎片，降低存储效率。</li><li>每个 quicklist 节点上的 ziplist 越长，则为 ziplist 分配大块连续内存的难度就越大。有可能出现，内存里有很多较小块的内存，却找不到一块足够大的空闲空间分配给 ziplist 的情况。这同样会降低存储效率。</li></ul><p>可见，一个 quicklist 节点上的 ziplist 需要保持一个合理的长度。这里的合理取决于实际应用场景。基于此，Redis 提供了一个配置参数，让使用者可以根据情况，自己调整：</p><blockquote><p>list-max-ziplist-size -2</p></blockquote><p>这个参数可以取正值，也可以取负值。</p><p>当取正值的时候，表示按照<strong>数据项个数</strong>来限定每个 quicklist 节点上 ziplist 的长度。比如配置为 2 时，就表示 quicklist 的每个节点上的 ziplist 最多包含 2 个数据项。</p><p>当取负值的时候，表示按照<strong>占用字节数</strong>来限定每个 quicklist 节点上 ziplist 的长度。此时，它的取值范围是 [-1, -5]，每个值对应不同含义：</p><ul><li>-1：每个 quicklist 节点上的 ziplist 大小不能超过 4Kb；</li><li>-2：每个 quicklist 节点上的 ziplist 大小不能超过 8Kb（默认值）；</li><li>-3：每个 quicklist 节点上的 ziplist 大小不能超过 16Kb；</li><li>-4：每个 quicklist 节点上的 ziplist 大小不能超过 32Kb；</li><li>-5：每个 quicklist 节点上的 ziplist 大小不能超过 64Kb；</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>普通链表存在两个问题：<strong>内存利用率低</strong>和<strong>容易产生内存碎片</strong>。</li><li>ziplist 使用连续内存，减少内存碎片，提供内存利用率。</li><li>skiplist 可以用相对简单的实现，达到和平衡树相同的查找效率。</li><li>quicklist 汲取了普通链表和压缩链表的优点，保证性能的前提下，尽可能的提高内存利用率。</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 源码 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ziplist </tag>
            
            <tag> skiplist </tag>
            
            <tag> quicklist </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟着大彬读源码 - Redis 8 - 对象编码之字典</title>
      <link href="/8/redis/yuanma/ck0669dt3003qagaam2q0co8j/"/>
      <url>/8/redis/yuanma/ck0669dt3003qagaam2q0co8j/</url>
      
        <content type="html"><![CDATA[<p>字典，是一种用于保存键值对的抽象数据结构。由于 C 语言没有内置字典这种数据结构，因此 Redis 构建了自己的字典实现。</p><p>在 Redis 中，就是使用字典来实现数据库底层的。对数据库的 CURD 操作也是构建在对字典的操作之上。</p><p>除了用来表示数据库之外，字典还是哈希键的底层实现之一。当一个哈希键包含的键值对比较多，又或者键值对中的元素都是比较长的字符串时，Redis 就会适应字典作为哈希键的底层实现。</p><h3 id="1-字典的实现"><a href="#1-字典的实现" class="headerlink" title="1 字典的实现"></a>1 字典的实现</h3><p>Redis 的字典使用哈希表作为底层实现。一个哈希表里面可以有多个哈希表节点，而每个哈希表节点就保存了字典中的一个键值对。</p><h4 id="1-1-哈希表"><a href="#1-1-哈希表" class="headerlink" title="1.1 哈希表"></a>1.1 哈希表</h4><p>Redis 字典所使用的哈希表结构：</p><pre><code>typedef struct dictht {    dictEntry **table;      // 哈希表数组    unsigned long size;     // 哈希表大小    unsigned long sizemask; // 哈希表大小掩码，用来计算索引    unsigned long used;     // 哈希表现有节点的数量} dictht;</code></pre><ul><li>table 属性是一个数组。数组中的每个元素都是一个指向 dictEntry 结构的指针，每个 dictEntry 结构保存着一个键值对。</li><li>size 属性记录了哈希表的大小，也即是 table 数组的大小。</li><li>used 属性记录了哈希表目前已有节点（键值对）的数量。</li><li>sizemask 属性的值总数等于 size-1，这个属性和哈希值一起决定一个键应该被放到 table 数组中哪个索引上。</li></ul><p>图 1 展示了一个大小为 4 的空哈希表。</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190515203213897_23208.png" alt="大小为4的空哈希表"></p><h4 id="1-2-哈希表节点"><a href="#1-2-哈希表节点" class="headerlink" title="1.2 哈希表节点"></a>1.2 哈希表节点</h4><p>哈希表节点使用 dictEntry 结构表示，每个 dictEntry 结构中都保存着一个键值对：</p><pre><code>typedef struct dictEntry {    void *key;              // 键    union {        void *val;          // 值类型之指针        uint64_t u64;       // 值类型之无符号整型        int64_t s64;        // 值类型之有符号整型        double d;           // 值类型之浮点型    } v;                    // 值    struct dictEntry *next; // 指向下个哈希表节点，形成链表} dictEntry;</code></pre><ul><li>key 属性保存着键，而 v 属性则保存着值。</li><li>next 属性是指向另一个哈希表节点的指针。这个指针可以将多个哈希值相同的键值对连接在一起，以此来解决键冲突的问题。</li></ul><p>图 2 展示了通过 next 指针，将两个索引相同的键 k1 和 k0 连接在一起的情况。</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190515205808155_12978.png" alt="连接在一起的键 k1 和 k0"></p><h4 id="1-3-字典"><a href="#1-3-字典" class="headerlink" title="1.3 字典"></a>1.3 字典</h4><p>字典的结构：</p><pre><code>typedef struct dict {    dictType *type; // 类型特定函数    void *privdata; // 私有数据    dictht ht[2];   // 哈希表(两个)    long rehashidx; // 记录 rehash 进度的标志。值为 -1 表示 rehash 未进行    int iterators;  // 当前正在迭代的迭代器数} dict;</code></pre><p>dictType 的结构如下：</p><pre><code>typedef struct dictType {    // 计算哈希值的函数    unsigned int (*hashFunction)(const void *key);    // 复制键的函数    void *(*keyDup)(void *privdata, const void *key);    // 复制值的函数    void *(*valDup)(void *privdata, const void *obj);    // 对比键的函数    int (*keyCompare)(void *privdata, const void *key1, const void *key2);    // 销毁键的函数    void (*keyDestructor)(void *privdata, void *key);    // 销毁值的函数    void (*valDestructor)(void *privdata, void *obj);} dictType;</code></pre><p>type 属性和 privdata 属性是针对不同类型的键值对，为创建多态字典而设置的。其中：</p><ul><li>type 属性是一个指向 dictType 结构的指针，每个 dictType 结构保存了一簇用于操作特定类型键值对的函数。Redis 会为用途不用的字典设置不同的类型特定函数。</li><li>privdata 属性保存了需要传给那些类型特定函数的可选参数。</li></ul><p>而  ht 属性是一个包含两个哈希表的数组。一般情况下，字典只使用 ht[0]，只有在对 ht[0] 进行 rehash 时才会使用 ht[1]。</p><p>rehashidx 属性，它记录了 rehash 目前的进度，如果当前没有进行 rehash，它的值为 -1。至于什么是 rehash，别急，后面会详细说明。</p><p>图 3 是没有进行 rehash 的字典：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190516124719503_21953.png" alt="没有进行 rehash 的字典"></p><h3 id="2-插入算法"><a href="#2-插入算法" class="headerlink" title="2 插入算法"></a>2 插入算法</h3><p>当在字典中添加一个新的键值对时，Redis 会先根据键值对的键计算出哈希值和索引值，然后再根据索引值，将包含新键值对的哈希表节点放到哈希表数组指定的索引上。具体算法如下：</p><pre><code># 使用字典设置的哈希函数，计算 key 的哈希值hash = dict-&gt;type-&gt;hashFunction(key);# 使用哈希表的 sizemask 属性和哈希值，计算出索引值# 根据不同情况，使用 ht[0] 或 ht[1]index = hash &amp; dict[x].sizemask;</code></pre><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190516130418875_30449.png" alt="图 4 - 空字典"><br>如图 4，如果把键值对 [k0, v0] 添加到字典中，插入顺序如下：</p><pre><code>hash = dict-type-&gt;hashFunction(k0);index = hash &amp; dict-&gt;ht[0].sizemask; # 8 &amp; 3 = 0</code></pre><p>计算得出，[k0, v0] 键值对应该被放在哈希表数组索引为 0 的位置上，如图 5：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190516130514422_8506.png" alt="图 5 - 添加 k0-v0 后的字典"></p><h4 id="2-1-键冲突"><a href="#2-1-键冲突" class="headerlink" title="2.1 键冲突"></a>2.1 键冲突</h4><p>当有两个或以上数量的键被分配到了哈希表数组的同一个索引上面时，我们认为这些键发生了<strong>建冲突</strong>。</p><p>Redis 的哈希表使用<strong>链地址法</strong>来解决建冲突。每个哈希表节点都有一个 next 指针，多个哈希表节点可以用 next 指针构成一个单向链表，被分配到同一个索引的多个节点用 next 指针链接成一个单向链表。</p><p>举个栗子，假设我们要把 [k2, v2] 键值对添加到图 6 所示的哈希表中，并且计算得出 k2 的索引值为 2，和 k1 冲突，因此，这里就用 next 指针将 k2 和 k1 所在的节点连接起来，如图 7。</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190516131134721_9353.png" alt="图 6 - 一个包含两个键值对的哈希表"></p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190516131209807_20748.png" alt="图 7 - 使用链表解决 k2 和 k1 冲突"></p><h3 id="3-rehash-与-渐进式-rehash"><a href="#3-rehash-与-渐进式-rehash" class="headerlink" title="3 rehash 与 渐进式 rehash"></a>3 rehash 与 渐进式 rehash</h3><p>随着对字典的操作，哈希表报错的键值对会逐渐增多或者减少，为了让哈希表的<strong>负载因子</strong>维持在一个合理的范围之内，当哈希表报错的键值对数量太多或者太少时，程序需要对哈希表进行相应的扩容或收缩。这个扩容或收缩的过程，我们称之为 rehash。</p><p>对于负载因子，可以通过以下公式计算得出：</p><pre><code># 负载因子 = 哈希表已保存节点数量 / 哈希表大小load_factor = ht[0].used / ht[0].size;</code></pre><h4 id="3-1-哈希表的扩容与收缩"><a href="#3-1-哈希表的扩容与收缩" class="headerlink" title="3.1 哈希表的扩容与收缩"></a>3.1 哈希表的扩容与收缩</h4><p><strong>扩容</strong></p><p>对于哈希表的扩容，源码如下：</p><pre><code>if (d-&gt;ht[0].used &gt;= d-&gt;ht[0].size &amp;&amp;    (dict_can_resize ||     d-&gt;ht[0].used/d-&gt;ht[0].size &gt; dict_force_resize_ratio)){    return dictExpand(d, d-&gt;ht[0].used*2);}</code></pre><p>当以下条件被满足时，程序会自动开始对哈希表执行扩展操作：</p><ul><li>服务器当前没有进行 rehash；</li><li>哈希表已保存节点数量大于哈希表大小；</li><li>dict_can_resize 参数为 1，或者负载因子大于设定的比率（默认为 5）；</li></ul><p><strong>收缩</strong></p><p>哈希表的收缩，源码如下：</p><pre><code>int htNeedsResize(dict *dict) {    long long size, used;    size = dictSlots(dict); // ht[2] 两个哈希表的大小之和    used = dictSize(dict);  // ht[2] 两个哈希表已保存节点数量之和    # DICT_HT_INITIAL_SIZE 默认为 4，HASHTABLE_MIN_FILL 默认为 10。    return (size &gt; DICT_HT_INITIAL_SIZE &amp;&amp;            (used*100/size &lt; HASHTABLE_MIN_FILL));}void tryResizeHashTables(int dbid) {    if (htNeedsResize(server.db[dbid].dict))        dictResize(server.db[dbid].dict);    if (htNeedsResize(server.db[dbid].expires))        dictResize(server.db[dbid].expires);}</code></pre><p>当 ht[] 哈希表的大小之和大于 DICT_HT_INITIAL_SIZE（默认 4），且已保存节点数量与总大小之比小于 4，HASHTABLE_MIN_FILL（默认 10，也就是 10%），会对哈希表进行收缩操作。</p><h4 id="3-2-rehash"><a href="#3-2-rehash" class="headerlink" title="3.2 rehash"></a>3.2 rehash</h4><p>扩容和收缩哈希表都是通过执行 rehash 操作来完成，哈希表执行 rehash 的步骤如下：</p><ol><li>为字典的 ht[1] 哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及 ht[0] 当前包含的键值对数量。<ol><li>如果执行的是扩容操作，那么 ht[1] 的大小为**第一个大于等于 ht[0].usedx2 的 2^n。</li><li>如果执行的是收缩操作，那么 ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n。</li></ol></li><li>将保存在 ht[0] 中的所有键值对 rehash 到 ht[1] 上面：rehash 指的是重新计算键的哈希值和索引值，然后将键值对都迁移到 ht[1] 哈希表的指定位置上。</li><li>当 ht[0] 包含的所有键值对都迁移到 ht[1] 后，此时 ht[0] 变成空表，释放 ht[0]，将 ht[1] 设置为 ht[0]，并在 ht[1] 新创建一个空白哈希表，为下一次 rehash 做准备。</li></ol><p>示例：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190516204031410_827.png" alt="图 8 - 将要执行 rehash 的字典"><br>假设程序要对图 8 所示字典的 ht[0] 进行扩展操作，那么程序将执行以下步骤：<br>1）ht[0].used 当前的值为 4，那么 4*2 = 8，而 2^3 恰好是第一个大于等于 8 的，2 的 n 次方。所以程序会将 ht[1] 哈希表的大小设置为 8。图 9 是 ht[1] 在分配空间之后的字典。</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190516204403952_2009.png" alt="图 9 - 为字典的 ht1 哈希表分配空间"></p><p>2）将 ht[0] 包含的四个键值对都 rehash 到 ht[1]，如图 10。</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190516204537618_21341.png" alt="图 10 - ht0 所有键值对都迁移到 ht1"></p><p>3）释放 ht[0]，并将 ht[1] 设置为 ht[0]，然后为 ht[1] 分配一个空白哈希表。如图 11：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190516204710040_19690.png" alt="图 11 - 完成 rehash 之后的字段"></p><p>至此，对哈希表的扩容操作执行完毕，程序成功将哈希表的大小从原来的 4 改为了 8。</p><h4 id="3-3-渐进式-rehash"><a href="#3-3-渐进式-rehash" class="headerlink" title="3.3 渐进式 rehash"></a>3.3 渐进式 rehash</h4><p>对于 Redis 的 rehash 而言，并不是一次性、集中式的完成，而是分多次、渐进式地完成，所以也叫<strong>渐进式 rehash</strong>。</p><p>之所以采用渐进式的方式，其实也很好理解。当哈希表里保存了大量的键值对，要一次性的将所有键值对全部 rehash 到 ht[1] 里，很可能会导致服务器在一段时间内只能进行 rehash，不能对外提供服务。</p><p>因此，为了避免 rehash 对服务器性能造成影响，Redis 分多次、渐进式的将 ht[0] 里面的键值对 rehash 到 ht[1]。</p><p>渐进式 rehash 就用到了索引计数器变量 rehashidx，详细步骤如下：</p><ol><li>为 ht[1] 分配空间，让字典同时持有 ht[0] 和 ht[1] 两个哈希表。</li><li>在字段中维持一个索引计数器变量 rehashidx，并将它的值设置为 0，表示开始 rehash。</li><li>在 rehash 期间，每次对字典执行 CURD 操作时，程序除了执行指定的操作外，还会将 ht[0] 哈希表在 rehashidx 索引上的所有键值对移动到 ht[1]，当 rehash 完成后，程序将 rehashidx 的值加一。</li><li>随着不断操作字典，最终在某个时间点上，ht[0] 的所有键值对都会被 rehash 到 ht[1]，这时程序将 rehashidx 属性的值设为 -1，表示 rehash 已完成。</li></ol><p>渐进式 rehash 才有分而治之的方式，将 rehash 键值对所需要的计算工作均摊到对字典的 CURD 操作上，从而避免了集中式 rehash 带来的问题。</p><p>此外，字典在进行 rehash 时，删除、查找、更新等操作会在两个哈希表上进行。例如，在字典张查找一个键，程序会现在 ht[0] 里面进行查找，如果没找到，再去 ht[1] 上查找。</p><p>要注意的是，新增的键值对一律只保存在 ht[1] 里，不在对 ht[0] 进行任何添加操作，保证了 ht[0] 包含的键值对数量只减不增，随着 rehash 操作最终变成空表。</p><p>图 12 至 图 17 展示了一次完整的渐进式 rehash 过程：</p><p>1）未进行 rehash 的字典</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190517124408102_7277.png" alt="图 12 - 未进行 rehash 的字典"></p><p>2） rehash 索引 0 上的键值对</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190517124520346_18511.png" alt="图 13 - rehash 索引 0 上的键值对"></p><p>3）rehash 索引 1 上的键值对</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190517124558334_4268.png" alt="图 14 - rehash 索引 1 上的键值对"></p><p>4）rehash 索引 2 上的键值对</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190517124630179_28797.png" alt="图 15 - rehash 索引 2 上的键值对"></p><p>5）rehash 索引 3 上的键值对</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190517124709578_3968.png" alt="图 16 - rehash 索引 3 上的键值对"></p><p>6）rehash 执行完毕</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190517124801249_31619.png" alt="图 17 - rehash 执行完毕"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>字段被广泛用于实现 Redis 的各种功能，其中包括数据库和哈希键。</li><li>Redis 中的字典使用哈希表作为底层实现，每个字典带有两个哈希表，一个平时使用，一个仅在 rehash 时使用。</li><li>哈希表使用链地址法来解决键冲突，被分配到同一个索引上的多个键值对会连接成一个单向链表。</li><li>在对哈希表进行扩容或收缩操作时，使用渐进式完成 rehash。</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 源码 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> dict </tag>
            
            <tag> 字典 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟着大彬读源码 - Redis 7 - 对象编码之简单动态字符串</title>
      <link href="/7/redis/yuanma/ck0669dsu003lagaaz7kjozog/"/>
      <url>/7/redis/yuanma/ck0669dsu003lagaaz7kjozog/</url>
      
        <content type="html"><![CDATA[<p>Redis 没有直接使用 C 语言传统的字符串表示（以空字符串结尾的字符数组），而是构建了一种名为<strong>简单动态字符串（simple dynamic string）</strong>的抽象类型，并将 SDS 用作 Redis 的默认字符串表示。</p><p>在 Redis 中，C 字符串只会作为字符串字面量用在一些无需对字符串进行修改的地方，比如打印日志：</p><blockquote><p>serverLog(LL_WARNING,”SIGTERM received but errors trying to shut down the server, check the logs for more information”);</p></blockquote><p>当 Redis 需要的不仅仅是一个字符串字面量，而是一个可以被修改的字符串值时，Redis 就会适应 SDS 来表示字符串。比如在数据库中，包含字符串值的键值对在底层都是由 SDS 实现的。</p><p>还是拿简单的 SET 命令举例，执行以下命令</p><pre><code>redis&gt; SET msg "hello world"ok</code></pre><p>那么，Redis 将在数据中创建一个新的键值对，其中：</p><ul><li>键值对的键是一个字符串对着，对象的底层实现是一个保存着字符串 “msg” 的 SDS。</li><li>键值对的值也是一个字符串对象，对象的底层实现是一个保存着字符串 “hello world” 的 SDS。</li></ul><p>除了用来保存数据库中的字符串值之外， SDS 还被用作缓冲区。AOF 模块中的 AOF 缓冲区，以及客户端状态中的输入缓冲区，都是由 SDS 实现的。</p><p>接下来，我们就来详细认识下 SDS。</p><h3 id="1-SDS-的定义"><a href="#1-SDS-的定义" class="headerlink" title="1 SDS 的定义"></a>1 SDS 的定义</h3><p>在 sds.h 中，我们会看到以下结构：</p><pre><code>typedef char *sds;</code></pre><p>可以看到，SDS 等同于 char * 类型。这是因为 SDS 需要和传统的 C 字符串保存兼容，因此将其类型设置为 char *。但是要注意的是，SDS 并不等同 char *，它还包括一个 header 结构，共有 5 中类型的 header，源码如下：</p><pre><code>struct __attribute__ ((__packed__)) sdshdr5 { // 已弃用    unsigned char flags; /* 3 lsb of type, and 5 msb of string length */    char buf[];};struct __attribute__ ((__packed__)) sdshdr8 { // 长度小于 2^8 的字符串类型    uint8_t len;         // SDS 所保存的字符串长度    uint8_t alloc;       // SDS 分配的长度    unsigned char flags; // 标记位，占 1 字节，使用低 3 位存储 SDS 的 type，高 5 位不使用    char buf[];          // 存储的真实字符串数据};struct __attribute__ ((__packed__)) sdshdr16 { // 长度小于 2^16 的字符串类型    uint16_t len; /* used */    uint16_t alloc; /* excluding the header and null terminator */    unsigned char flags; /* 3 lsb of type, 5 unused bits */    char buf[];};struct __attribute__ ((__packed__)) sdshdr32 { // 长度小于 2^32 的字符串类型    uint32_t len; /* used */    uint32_t alloc; /* excluding the header and null terminator */    unsigned char flags; /* 3 lsb of type, 5 unused bits */    char buf[];};struct __attribute__ ((__packed__)) sdshdr64 { // 长度小于 2^64 的字符串类型    uint64_t len; /* used */    uint64_t alloc; /* excluding the header and null terminator */    unsigned char flags; /* 3 lsb of type, 5 unused bits */    char buf[];};</code></pre><p>之所以会有 5 种类型的 header，是为了能让不同长度的字符串使用对应大小的 header，提高内存利用率。</p><p>一个 SDS 的完整结构，由内存地址上前后相邻的两部分组成：</p><ul><li>header：包括字符串的长度（len），最大容量（alloc）和 flags（不包含 sdshdr5）。</li><li>buf[]：一个字符串数组。这个数组的长度等于最大容量加 1，存储着真正的字符串数据。</li></ul><p>图 1-1 展示了一个 SDS 示例：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190715201325861_514.png" alt="图 1-1：SDS 示例"></p><p>示例中，各字段说明如下：</p><ul><li>alloca：SDS 分配的空间大小。图中表示分配的空间大小为 10。</li><li>len：SDS 保存字符串大小。图中表示保存了 5 个字节的字符串。</li><li>buf[]：这个数组的长度等于最大容量加 1，存储着真正的字符串数据。图中表示数字的前 5 个字节分别保存了 ‘H’、’e’、’l’、’l’、’o’ 五个字符，而最后一个字节则保存了空字符串 ‘\0’。</li></ul><p>SDS 遵循 C 字符串以空字符结尾的惯例，保存空字符的大小不计算在 SDS 的 len 属性中。此外，添加空字符串到字符串末尾等操作，都是由 SDS 函数（sds.c 文件中的相关函数）自动完成的。</p><p>而且，遵循空字符结尾的惯例，还可以直接重用一部分 C 字符串函数库中的函数。</p><p>例如，我们可以直接使用 <code>printf()</code> 函数打印 <code>s-&gt;buf</code>：<br><code>printf("%s", s-&gt;buf);</code><br>这样，我们可以直接使用 C 函数来打印字符串 “Redis”，无需为 SDS 编写转码的打印函数。</p><h3 id="2-SDS-对比-C-字符串有哪些优势"><a href="#2-SDS-对比-C-字符串有哪些优势" class="headerlink" title="2 SDS 对比 C 字符串有哪些优势"></a>2 SDS 对比 C 字符串有哪些优势</h3><p>在 C 语言中，使用长度为 N+1 的字符数组来表示长度为 N 的字符串，并且字符数组的最后一个元素总是空字符 “\0”。</p><p>C 语言使用的这种字符串表示方式，并不能满足 Redis 对字符串再安全性、效率及功能方面的要求。因此，Redis 设计出了 SDS，来满足自己的相关需求。接下来，我们从以下几方面来认识 SDS 对比 C 字符串的优势：</p><ol><li>获取字符串长度；</li><li>缓冲区溢出；</li><li>修改字符串时的内存重分配次数；</li><li>二进制安全；</li></ol><h4 id="2-1-常数复杂度获取字符串长度"><a href="#2-1-常数复杂度获取字符串长度" class="headerlink" title="2.1 常数复杂度获取字符串长度"></a>2.1 常数复杂度获取字符串长度</h4><p>由于 C 字符串并不记录自身的长度信息，所以在 C 语言中，为了获取一个 C 字符串的长度，程序必须遍历整个字符串，直到遇到代表字符串结尾的空字符为止，这个操作的复杂度为 O(N)。</p><p>这个复杂度对于 Redis 而言，一旦碰上非常长的字符串，使用 <code>STRLEN</code> 命令时，很容易对系统性能造成影响。</p><p>和 C 字符串不同的是，因为 SDS 在 len 属性中记录了 SDS 保存的字符串的长度，所以获取一个 SDS 长度的复杂度仅为 O(1)。</p><p>而且设置和更新 SDS 长度的工作都是由 SDS 的 API 在执行时自动完成的，所以使用 SDS 无需进行任何手动修改长度的工作。</p><p>通过使用 SDS，Redis 将获取字符串长度所需的复杂度从 O(N) 降低到了 O(1)，确保了获取字符串长度的工作不会成为 Redis 的性能瓶颈。</p><h4 id="2-2-杜绝缓冲区溢出"><a href="#2-2-杜绝缓冲区溢出" class="headerlink" title="2.2 杜绝缓冲区溢出"></a>2.2 杜绝缓冲区溢出</h4><p>C 字符串不记录自身长度，不仅使得获取字符串长度的复杂度较高，还<strong>容易造成缓冲区溢出（buffer overflow）</strong>。</p><p>C 语言中的 <code>strcat()</code> 函数可以将 src 字符串中的内容拼接到 dest 字符串的末尾：</p><pre><code>char *strcat(char *dest, const char *src);</code></pre><p>因为 C 字符串不记录自身的长度，所以 strcat 函数执行时，假定用户已经为 dest 分配了足够多的内存，可以容纳 src 字符串中的所有内容。而一旦这个假定不成立，就会产生缓冲区溢出。</p><p>举个例子，假设程序里有两个在内存中紧邻着的 C 字符串 s1 和 s2，其中 s1 保存了字符串 “redis”，s2 保存了字符串 “mysql”，存储结构如图 2-1 所示：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190715204554675_14062.png" alt="图 2-1：在内存中紧邻的两个 C 字符串"></p><p>如果我们执行下面语句：</p><pre><code>strcat(s1, " 666");</code></pre><p>将 s1 的内容修改为 “redis 666”，但却没有在执行 <code>strcat()</code> 之前为 s1 分配足够的空间，那么在执行 <code>strcat()</code> 之后，s1 的数据将移除到 s2 所在的空间，导致 s2 保存的内容被意外修改，如图 2-2 所示：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190715205526189_9537.png" alt="图 2-2：s1 的内容溢出到了 s2 的空间中"></p><p>与 C 字符串不同的是，SDS 的空间分配策略完全杜绝了发生缓冲区溢出的可能性：当 SDS 的 API 需要对 SDS 进行修改时，API 会先检查 SDS 的空间十分满足修改所需的要求，如果不满足的话，API 会自动将 SDS 的空间扩展至执行修改所需的大小，然后再执行实际的修改操作，所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现前面所说的缓冲区溢出问题。</p><h4 id="2-3-减少内存重分配次数"><a href="#2-3-减少内存重分配次数" class="headerlink" title="2.3 减少内存重分配次数"></a>2.3 减少内存重分配次数</h4><p>由于 C 字符串的长度 slen 和底层数组的长度 salen 总存在着下述关系：</p><blockquote><p>salen = slen + 1; // 1 是空字符的长度</p></blockquote><p>因此，每次增长或缩短一个 C 字符串，总要对 C 字符串的数组进行一次内存重分配操作：</p><ul><li><strong>增长字符串</strong>。程序需要通过内存重分配来<strong>扩展</strong>底层数组的空间的大小，如果漏了这步，就可能会产生缓冲区溢出。</li><li><strong>缩短字符串</strong>。程序需要通过内存重分配来<strong>释放</strong>底层数组不再使用的空间，如果漏了这步，就可能会产生内存泄漏。</li></ul><p>而内存重分配涉及复杂的算法，并且可能需要执行系统调用，所以<strong>内存重分配是一个较为耗时的过程</strong>。</p><p>对于 Redis 而言，一切耗时的操作都要优化。基于此，SDS 对于字符串的增长和缩短操作，通过<strong>空间预分配</strong>和<strong>惰性空间释放</strong>两种方式来优化。</p><h5 id="2-3-1-空间预分配"><a href="#2-3-1-空间预分配" class="headerlink" title="2.3.1 空间预分配"></a>2.3.1 空间预分配</h5><p>空间预分配是指：<strong>在需要对 SDS 的空间进行扩展时，程序不是仅仅分配所必需的的空间，还会为 SDS 分配额外的未使用空间</strong>。</p><p>关于 SDS 的空间扩展，源码如下：</p><pre><code># sds.c/sdsMakeRoomFor()...newlen = (len+addlen); // SDS 最新长度if (newlen &lt; SDS_MAX_PREALLOC) // 预分配最大值 SDS_MAX_PREALLOC 在 sds.h 中定义，值为 1024*1024    newlen *= 2;else    newlen += SDS_MAX_PREALLOC;...</code></pre><p>由源码可以看出，空间扩展分为两种情况：</p><ul><li>新长度<strong>小于</strong>预分配最大值。此时，程序将直接为 SDS 新增最新长度大小的未使用空间。举个栗子，现有一个长度为 10 字节的字符串 s1，当给 s1 追加字符串 “redis”，那么，程序将除了分配足够 s1 使用的空间，还会为 s1 再分配最新长度大小的预使用空间。所以，s1 的实际长度就变为： <code>15 + 15 + 1 = 31</code> 个字节。</li><li>新长度<strong>大于</strong>预分配最大值。此时，由于最新字符串较大，程序不会预分配这么多空间，只会给预分配最大值的空间。举个栗子，现有长度为 3M 的字符串 s2，当给 s1 追加一个 2M 大小的字符串，那么程序除了新增 2M 来存储新增的长度，还会为 s2 再分配 1M（SDS_MAX_PREALLOC）的预使用空间。所以，s2 的实际长度就变为：<code>3M + 2M +1M + 1byte</code>。</li></ul><p>正是通过预分配的策略，Redis 减少了执行字符串增长操作所需的内存重分配次数，保证了 Redis 不会因字符串增长操作损耗性能。</p><h5 id="2-3-2-惰性空间释放"><a href="#2-3-2-惰性空间释放" class="headerlink" title="2.3.2 惰性空间释放"></a>2.3.2 惰性空间释放</h5><p>预分配对应字符串的增长操作，而空间释放则对应字符串的缩短操作。</p><p>惰性空间释放是指：<strong>在对 SDS 进行缩短操作时，程序不立即回收缩短后多出来的字节，等待将来使用</strong>。</p><p>举个栗子，我们使用 <code>sdstrim()</code> 函数，移除下图 SDS 中所有指定的字符：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190717093746736_25282.png" alt="图 2-3：进行缩短操作的 SDS"></p><p>对上图 SDS，执行：<br><code>sdstrim(s, "l"); // 移除 SDS 字符串中所有的 'l'</code></p><p>会将 SDS 修改为图 2-4 所示：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190717094220874_4943.png" alt="图2-4：移除所有'l'后的SDS"></p><p>可以看到，执行 <code>sdstrim()</code> 之后的 SDS 并没有释放多出来的 3 字节空间，而是将这 3 字节空间作为未使用空间保留在了 SDS 里面，以待备用。</p><p>正是通过<strong>惰性空间释放策略</strong>，SDS 避免了缩短字符串时所需的内存重分配操作，并为将来可能的增长操作提供了优化。</p><p>此外，SDS 也提供了相应的 API，让我们在有需要时，真正的释放 SDS 的未使用空间，避免造成内存浪费。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>Redis 只会使用 C 字符串作为字面量，大多数情况下，使用 SDS 作为字符串表示。</li><li>SDS 对比 C 字符串，有几大优点：<strong>常数复杂度获取字符串长度</strong>、<strong>杜绝缓冲区溢出</strong>、<strong>减少修改字符串时所需的内存重分配次数</strong>。</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 源码 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 简单动态字符串 </tag>
            
            <tag> SDS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟着大彬读源码 - Redis 6 - 对象和数据类型（下）</title>
      <link href="/7/redis/yuanma/ck0669dsd003jagaa62malse5/"/>
      <url>/7/redis/yuanma/ck0669dsd003jagaa62malse5/</url>
      
        <content type="html"><![CDATA[<p>继续撸我们的对象和数据类型。</p><p>上节我们一起认识了字符串和列表，接下来还有哈希、集合和有序集合。</p><h3 id="1-哈希对象"><a href="#1-哈希对象" class="headerlink" title="1 哈希对象"></a>1 哈希对象</h3><p>哈希对象的可选编码分别是：ziplist 和 hashtable。</p><h4 id="1-1-ziplist-编码的哈希对象"><a href="#1-1-ziplist-编码的哈希对象" class="headerlink" title="1.1 ziplist 编码的哈希对象"></a>1.1 ziplist 编码的哈希对象</h4><p>ziplist 编码的哈希对象使用压缩列表作为底层实现。每当有新的键值对要加入到哈希对象时，程序会先将保存了<strong>键</strong>的压缩列表节点推入到表尾，然后再将保存了<strong>值</strong>的压缩列表节点推入到表尾。因此：</p><ul><li>保存了键值对的两个节点总是紧挨在一起，保存键的节点在前，保存值的节点在后；</li><li>先添加到哈希对象中的键值对会被仿造压缩列表的表头方向，后添加的键值对会被放在压缩列表的表尾方向。</li></ul><p>执行以下 HSET 命令，服务器将创建一个如图 9 所示的列表对象作为 profile 键的值：</p><pre><code>127.0.0.1:6379&gt; HSET profile name "Tom"(integer) 1127.0.0.1:6379&gt; HSET profile age "25"(integer) 1127.0.0.1:6379&gt; HSET profile career "Programer"(integer) 1127.0.0.1:6379&gt; OBJECT ENCODING profile"ziplist"</code></pre><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190524123000055_32164.png" alt="图 9 - ziplist 编码的哈希对象"></p><p>其中对象所使用的压缩列表如图 10 所示：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190524123202076_12872.png" alt="图 10 - ziplist 编码的哈希对象中压缩列表结构"></p><h4 id="1-2-hashtable-编码的"><a href="#1-2-hashtable-编码的" class="headerlink" title="1.2 hashtable 编码的"></a>1.2 hashtable 编码的</h4><p>hashtable 编码的哈希对象使用字典作为底层实现。哈希对象中的每个键值对都使用一个字典键值对来保存：</p><ul><li>字典中的每个键都是一个字符串对象，对象中保存了键值对的键；</li><li>字典中的每个值都是一个字符串对象，对象中保存了键值对的值。</li></ul><p>如果前面的 profile 键使用的是 hashtable 编码的哈希对象，那么这个哈希对象应该如图 11 所示：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190524124313495_9362.png" alt="图 11 - hashtable 编码的哈希对象"></p><h4 id="1-3-编码转换"><a href="#1-3-编码转换" class="headerlink" title="1.3 编码转换"></a>1.3 编码转换</h4><p>当哈希对象同时符合下面两个条件时，将使用 ziplist 编码：</p><ol><li>哈希对象保存的所有键值对中，键和值的字符串长度都小于 64 个字节；</li><li>哈希对象保存的键值对数量小于 512 个。</li></ol><p>上述条件中的临界值对应 redis.conf 文件中的配置：<code>hash-max-ziplist-value</code> 和 <code>hash-max-ziplist-entries</code>。</p><p>在 3.2 版本中，新增一个哈希键值对时，实际上总是先创建一个 ziplist 编码的哈希对象，然后再进行转换检查。<br>关于何时进行编码转换，有两种情况发生：</p><ol><li>更新或新增键值对时，如果<strong>值的字节数</strong>大于 <code>hash-max-ziplist-value</code>，将从 ziplist 编码转成 hashtable 编码；</li><li>新增键值对时，如果哈希中的<strong>键值对数量</strong>大于 <code>hash-max-ziplist-entries</code>，将从 ziplist 编码转成 hashtable 编码。</li></ol><p>要注意的是，上述发生转换的情况，都不会出现从 hashtable 转成 ziplist 的情况，即使符合条件。</p><p>关于哈希编码转换的函数，可以参考 t_hash.c/hashTypeConvert，源码如下：</p><pre><code># o 是原始对象，enc 是目标编码。void hashTypeConvert(robj *o, int enc) {    if (o-&gt;encoding == OBJ_ENCODING_ZIPLIST) { // 原始编码是 OBJ_ENCODING_ZIPLIST 才进行转换        hashTypeConvertZiplist(o, enc);    } else if (o-&gt;encoding == OBJ_ENCODING_HT) {        serverPanic("Not implemented");    } else {        serverPanic("Unknown hash encoding");    }}</code></pre><h3 id="2-集合对象"><a href="#2-集合对象" class="headerlink" title="2 集合对象"></a>2 集合对象</h3><p>集合对象的可选编码有：intset 和 hashtable。</p><h4 id="2-1-intset-编码的集合对象"><a href="#2-1-intset-编码的集合对象" class="headerlink" title="2.1 intset 编码的集合对象"></a>2.1 intset 编码的集合对象</h4><p>intset 编码的集合对象使用整数集合作为底层实现，集合对象包含的所有元素都被保存在整数集合里面。</p><p>执行以下 SADD 命令，将创建一个如图 12 所示的 intset 编码的集合对象：</p><pre><code>127.0.0.1:6379&gt; SADD numbers 1 3 5(integer) 3127.0.0.1:6379&gt; OBJECT ENCODING numbers"intset"</code></pre><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190524131821117_3903.png" alt="图 12 - intset 编码的集合对象"></p><h4 id="2-2-hashtable-编码的集合对象"><a href="#2-2-hashtable-编码的集合对象" class="headerlink" title="2.2 hashtable 编码的集合对象"></a>2.2 hashtable 编码的集合对象</h4><p>hashtable 编码的集合对象使用字典作为底层实现，字典的每个键都是一个字符串对象，每个字符串对象中又包含了一个集合元素，而字典的值则全部设置为 NULL。</p><p>执行以下 SADD 命令，将创建一个如图 13 所示的 hashtable 编码的集合对象：</p><pre><code>127.0.0.1:6379&gt; SADD fruits "apple" "banana" "cherry"(integer) 3127.0.0.1:6379&gt; OBJECT ENCODING fruits"hashtable"</code></pre><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190524131844230_29702.png" alt="图 13 - hashtable 编码的集合对象"></p><h4 id="2-3-编码转换"><a href="#2-3-编码转换" class="headerlink" title="2.3 编码转换"></a>2.3 编码转换</h4><p>当集合对象同时满足以下两个条件时，对象使用 intset 编码：</p><ol><li>集合对象保存的所有元素都是可以被 long double 表示整数值；</li><li>集合对象保存的元素数量不超过 512 个。</li></ol><p>上述条件中的临界值对应 redis.conf 文件中的配置：<code>set-max-intset-entries</code>。</p><p>对于集合对象，在新增第一个键值对时，就会对键值对中的值进行检查，如果是符合条件的整数值，就会创建一个 intset 编码的集合对象，否则，则创建 hashtable 编码的集合对象。</p><p>关于何时进行编码转换，有两种情况发生：</p><ol><li>更新或新增键值对时，如果<strong>值</strong>不能用 long double 表示，将从 intset 编码转成 hashtable 编码；</li><li>新增键值对时，如果集合中的<strong>键值对数量</strong>大于 <code>set-max-intset-entries</code>，将从 intset 编码转成 hashtable 编码。</li></ol><p>同样，上述发生转换的情况，都不会出现从 hashtable 转成 intset 的情况，即使符合条件。</p><p>关于哈希编码转换的函数，可以参考 t_set.c/setTypeConvert，源码如下：</p><pre><code># setobj 是原始对象，enc 是目标编码。hvoid setTypeConvert(robj *setobj, int enc) {    setTypeIterator *si;    serverAssertWithInfo(NULL,setobj,setobj-&gt;type == OBJ_SET &amp;&amp; setobj-&gt;encoding == OBJ_ENCODING_INTSET);    if (enc == OBJ_ENCODING_HT) { // 只能转成 OBJ_ENCODING_HT 编码        int64_t intele;        dict *d = dictCreate(&amp;setDictType,NULL);        robj *element;        /* Presize the dict to avoid rehashing */        dictExpand(d,intsetLen(setobj-&gt;ptr));        /* To add the elements we extract integers and create redis objects */        si = setTypeInitIterator(setobj);        while (setTypeNext(si,&amp;element,&amp;intele) != -1) {            element = createStringObjectFromLongLong(intele);            serverAssertWithInfo(NULL,element,                                dictAdd(d,element,NULL) == DICT_OK);        }        setTypeReleaseIterator(si);        setobj-&gt;encoding = OBJ_ENCODING_HT;        zfree(setobj-&gt;ptr);        setobj-&gt;ptr = d;    } else {        serverPanic("Unsupported set conversion");    }}</code></pre><h3 id="3-有序集合对象"><a href="#3-有序集合对象" class="headerlink" title="3 有序集合对象"></a>3 有序集合对象</h3><p>有序集合对象的可选编码有：ziplist 和 skiplist。</p><h4 id="3-1-ziplist-编码的有序集合对象"><a href="#3-1-ziplist-编码的有序集合对象" class="headerlink" title="3.1 ziplist 编码的有序集合对象"></a>3.1 ziplist 编码的有序集合对象</h4><p>intset 编码的集合对象使用压缩列表作为底层实现。每个集合元素使用两个紧挨在一起的压缩列表节点来保存。第一个节点保存元素的成员（member），第二个成员保存元素的分值（score）。</p><p>压缩列表内的集合元素按分值从小到大排序，分值较小的元素被放置在表头的方向，而分值较大的元素则被放置在靠近表尾的方向。</p><p>执行以下 SADD 命令，将创建一个如图 14 所示的 ziplist 编码的集合对象：</p><pre><code>127.0.0.1:6379&gt; ZADD price 8.5 apple 5.0 banana 6.0 cherry(integer) 3127.0.0.1:6379&gt; OBJECT ENCODING price"ziplist"</code></pre><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190527122407446_19652.png" alt="图 14 - ziplist 编码的有序集合对象"></p><p>底层结构 ziplist 如图 15 所示：<br><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190527122602034_6298.png" alt="图 15 - ziplist 编码的有序集合，数据在压缩列表中按分值从小到大排列"></p><h4 id="3-2-skiplist-编码的集合对象"><a href="#3-2-skiplist-编码的集合对象" class="headerlink" title="3.2 skiplist 编码的集合对象"></a>3.2 skiplist 编码的集合对象</h4><p>skiplist 编码的集合对象使用 zset 作为底层实现。一个 zset 结构同时包含一个字典和一个跳跃表。结构源码如下：</p><pre><code># server.htypedef struct zset {    dict *dict;    zskiplist *zsl;} zset;</code></pre><p>zset 结构中的 zsl 跳跃表按分值从小到大保存了所有集合元素，每个跳跃表节点都保存了一个集合元素。</p><p>跳跃表节点的 object 属性保存了元素的成员，而跳跃表节点的 score 属性则保存了元素的分支。**程序通过这个跳跃表，对有序集合进行范围型操作。比如 ZRANK、ZRANGE 等命令就是基于跳跃表 API 来实现的。</p><p>除此之外，zset 结构中的 dict 字典为有序集合创建了一个从成员到分值的映射。字典中的每个键值对都保存了一个集合元素：字典中的键保存了元素的成员，而字典的值则保存了元素的分值。通过这个字典，程序用 O(1) 复杂度查找给定成员的分值。</p><p>有序集合每个元素的成员都是一个字符串对象，而每个元素的分值都是一个 double 类型的浮点数。值得一提的是，虽然 zset 结构同时使用跳跃表和字典保存了有序集合的元素，但这两种数据结构都会通过指针来共享相同元素的成员和分值，所以不会产生任何重复成员和分值，也不会因此而浪费额外的内存。</p><p>如果前面 price 键创建的不是 ziplist 编码的有序集合对象，而是 skiplist 编码，那么这个有序集合对象将会如图 16 所示，而对象所使用的 zset 结果将会如图 17 所示：<br><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190527124054221_23339.png" alt="图 16 - skiplist 编码的有序集合对象"></p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190527124127930_234.png" alt="图 17 - 有序集合元素同时被存放在字典和跳跃表中"></p><p>图 17 中，为了展示方便，重复展示了各个元素的成员和分值。实际上，它们是共享元素的成员和分值。</p><h4 id="3-3-编码转换"><a href="#3-3-编码转换" class="headerlink" title="3.3 编码转换"></a>3.3 编码转换</h4><p>当有序集合对象同时满足以下两个条件时，对象使用 ziplist 编码：</p><ol><li>有序集合对象保存的元素数量不超过 128 个。</li><li>有序集合中保存的所有元素成员的长度都小于 64 个字节。</li></ol><p>上述条件中的临界值对应 redis.conf 文件中的配置：<code>zset-max-ziplist-entries</code> 和 <code>zset-max-ziplist-value</code>。</p><p>对于集合对象，在新增键值对时，就会对集合元素以及键值对中的值进行检查，如果是符合条件，就会创建一个 ziplist 编码的集合对象，否则，则创建 skiplist 编码的集合对象。对应源码如下：</p><pre><code># t_zset.c/zaddGenericCommand...zobj = lookupKeyWrite(c-&gt;db,key);if (zobj == NULL) {    if (xx) goto reply_to_client; /* No key + XX option: nothing to do. */    if (server.zset_max_ziplist_entries == 0 ||        server.zset_max_ziplist_value &lt; sdslen(c-&gt;argv[scoreidx+1]-&gt;ptr))    {        # 对象元素数量为 0，或者        zobj = createZsetObject();    } else {        zobj = createZsetZiplistObject();    }    dbAdd(c-&gt;db,key,zobj);} else {    if (zobj-&gt;type != OBJ_ZSET) {        addReply(c,shared.wrongtypeerr);        goto cleanup;    }}</code></pre><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>哈希对象有 <strong>ziplist</strong> 和 <strong>hashtable</strong> 编码。</li><li>集合对象有 <strong>intset</strong> 和 <strong>hashtable</strong> 编码。</li><li>有序集合对象有 <strong>ziplist</strong> 和 <strong>skiplist</strong> 编码。</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 源码 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 对象和数据类型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟着大彬读源码 - Redis 5 - 对象和数据类型（上）</title>
      <link href="/7/redis/yuanma/ck0669ds8003fagaa5g5lyu2t/"/>
      <url>/7/redis/yuanma/ck0669ds8003fagaa5g5lyu2t/</url>
      
        <content type="html"><![CDATA[<p>相信很多人应该都知道 Redis 有五种数据类型：字符串、列表、哈希、集合和有序集合。但这五种数据类型是什么含义？Redis 的数据又是怎样存储的？今天我们一起来认识下 Redis 这五种数据结构的含义及其底层实现。</p><p>首先要明确的是，Redis 并没有直接使用这五种数据结构来实现键值对数据库，而是基于这些数据结构创建了一套对象系统，我们常说的数据类型，准确来说，是 Redis 对象系统的类型。</p><h3 id="1-对象"><a href="#1-对象" class="headerlink" title="1 对象"></a>1 对象</h3><p>对于 Redis 而言，所有键值对的存储，都是将数据存储在对象结构中。所不同的是，<strong>键总是一个字符串对象，值可以是任意类型的对象</strong>。<br>对象源码结构如下：</p><pre><code>typedef struct redisObject {    unsigned type:4;       // 对象类型    unsigned encoding:4;   // 对象编码    unsigned lru:LRU_BITS; // LRU    int refcount;          // 引用统计    void *ptr;             // 指向底层实现数据结构的指针} robj;</code></pre><ul><li>type 字段：对象类型，就是我们常说的。string、list、hash、set、zset。</li><li>encoding：对象编码。也就是我们上面说的底层数据结构。</li><li>LRU：键值对的 LRU。</li><li>refcount：键值对对象的引用统计。当此值为 0 时，回收对象。</li><li>*ptr：指向底层实现数据结构的指针。就是实际存放数据的地址。</li></ul><h4 id="1-2-对象类型"><a href="#1-2-对象类型" class="headerlink" title="1.2 对象类型"></a>1.2 对象类型</h4><p>对象有五种数据类型，就是我们上面提过的：</p><ol><li>字符串类型</li><li>列表类型</li><li>哈希类型</li><li>集合类型</li><li>有序集合类型</li></ol><p>结合我们上面提到的键值对存储类型的差别，可以了解到，我们常说的“一个列表键或一个哈希键”，本质上指的是：<strong>一个 key 对应的 value 是列表对象或哈希对象</strong>。</p><p>对于 type 字段，我们可以使用 <code>TYPE</code> 命令来查看指定 key 对应 value 值的对象类型。<br><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190522130037441_6914.png" alt="图 2 - 设置不同类型的 key"><br><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190522130140504_20872.png" alt="图 3 - TYPE 命令对不同类型的 key 的输出"></p><h4 id="1-3-对象编码"><a href="#1-3-对象编码" class="headerlink" title="1.3 对象编码"></a>1.3 对象编码</h4><p>按道理讲，已经有了 type，为什么还要搞个编码呢？</p><p>想想看，通过 encoding 属性，我们是不是使用不同编码的对象？这种使用方式可以根据不同的使用场景来为一个对象设置不同的编码，从而优化在某一场景下的效率，极大的提升了 Redis 的灵活性和效率。</p><p>举个栗子，在列表对象包含的元素比较少时，Redis 使用压缩列表作为列表对象的底层实现：</p><ul><li>压缩列表比快速链表更节约内存，并且在元素数量较少时，在内存中以连续块方式报错的压缩列表比起快速列表可以更快的载入到缓存中；</li><li>随着列表对象包含的元素越来越多，使用压缩列表保存元素的优势消失时，对象就会将底层实现从压缩列表转为功能更强、也更适合保存大量元素的快速链表。</li></ul><p>后面介绍完编码类型后，我们会详细认识不同类型对应的各个编码方式。</p><p>encoding 属性有以下取值：</p><ol><li>OBJ_ENCODING_RAW</li><li>OBJ_ENCODING_INT</li><li>OBJ_ENCODING_HT</li><li>OBJ_ENCODING_QUICKLIST</li><li>OBJ_ENCODING_ZIPLIST</li><li>OBJ_ENCODING_INTSET</li><li>OBJ_ENCODING_SKIPLIST</li><li>OBJ_ENCODING_EMBSTR</li></ol><p>对象的编码类型可以由 <code>OBJECT ENCODING</code> 命令获取。</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190522131136463_24618.png" alt="图 4 - 获取 key 的编码"></p><p><code>OBJECT ENCODING</code> 命令对应源码如下：</p><pre><code># src/object.cchar *strEncoding(int encoding) {    switch(encoding) {    case OBJ_ENCODING_RAW: return "raw";    case OBJ_ENCODING_INT: return "int";    case OBJ_ENCODING_HT: return "hashtable";    case OBJ_ENCODING_QUICKLIST: return "quicklist";    case OBJ_ENCODING_ZIPLIST: return "ziplist";    case OBJ_ENCODING_INTSET: return "intset";    case OBJ_ENCODING_SKIPLIST: return "skiplist";    case OBJ_ENCODING_EMBSTR: return "embstr";    default: return "unknown";    }}</code></pre><p><code>OBJECT ENCODING</code> 命令输出值与 encoding 属性取值对应关系如下：<br>| 对象使用的底层数据结构    | 编码常量    |  OBJECT ENCODING 输出    |<br>| :-: | :-: | :-: |<br>|  简单动态字符串   |OBJ_ENCODING_RAW     |”raw”     |<br>|  整数   |OBJ_ENCODING_INT     |”int”     |<br>|  embstr 编码的简单动态字符串   |OBJ_ENCODING_EMBSTR     |”embstr”     |<br>|  字典   |OBJ_ENCODING_HT     |”hashtable”     |<br>|  压缩列表   |OBJ_ENCODING_ZIPLIST     |”ziplist”     |<br>|  快速列表   |OBJ_ENCODING_QUICKLIST     |”quicklist”     |<br>|  整数集合   |OBJ_ENCODING_INTSET     |”intset”     |<br>|  跳跃表   |OBJ_ENCODING_SKIPLIST     |”skiplist”     |</p><p>总结来看，如下图：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190521202055424_22716.png" alt="图 5 - 11 种不同编码的数据对象"></p><p>十一种不同编码的对象分别是：</p><ol><li>使用双端或快速列表实现的列表对象</li><li>使用压缩列表实现的列表对象</li><li>使用字典实现的哈希对象</li><li>使用压缩列表实现的哈希对象</li><li>使用字典实现的集合对象</li><li>使用整数集合实现的集合对象</li><li>使用压缩列表实现的有序集合对象</li><li>使用跳跃表实现的有序集合对象</li><li>使用普通 SDS 实现的字符串对象</li><li>使用 embstr 编码的 SDS 实现的字符串对象</li><li>使用整数值实现的字符串对象</li></ol><p>接下来，我们将对上述十一种对象一一介绍。之后再一一认识对象编码。</p><h3 id="2-字符串对象"><a href="#2-字符串对象" class="headerlink" title="2 字符串对象"></a>2 字符串对象</h3><p>字符串对象的可选编码分别是：int、raw 或者 embstr。</p><h4 id="2-1-int-编码的字符串对象"><a href="#2-1-int-编码的字符串对象" class="headerlink" title="2.1 int 编码的字符串对象"></a>2.1 int 编码的字符串对象</h4><p>如果一个字符串对象保存的是整数值，并且这个整数值可以用 long 类型表示，那么字符串对象会将整数值保存在字符串对象结构的 ptr 属性中，并将字符串对象的编码设置为 int。</p><p>我们执行以下 SET 命令，服务器将创建一个如下图所示的 int 编码的字符串对象作为 num 键的值：</p><pre><code># redis-cli127.0.0.1:6380&gt; set num 12345OK127.0.0.1:6380&gt; OBJECT ENCODING num"int"</code></pre><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190523074125624_16057.png" alt="图 6 - int 编码的字符串对象"></p><h4 id="2-2-raw-编码的字符串对象"><a href="#2-2-raw-编码的字符串对象" class="headerlink" title="2.2 raw 编码的字符串对象"></a>2.2 raw 编码的字符串对象</h4><p>如果字符串对象保存的是一个字符串值，并且这个字符串值的<strong>长度大于 44 字节</strong>（根据版本的不同，这个值会有差异。详见 object.c 文件中的 OBJ_ENCODING_EMBSTR_SIZE_LIMIT 常量），那么字符串对象将使用**简单动态字符串（SDS）来保存这个字符串值，并将对象的编码设置为 raw。</p><p>我们执行下面的 SET 命令，服务器将创建一个图 7 所示的 raw 编码的字符串对象作为 k1 键的值（45 字节）：</p><pre><code>127.0.0.1:7379&gt; set story 'k01234567890123456789012345678901234567890123'OK127.0.0.1:7379&gt; OBJECT ENCODING k4"raw"</code></pre><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190523195558662_31098.png" alt="图 7 - raw 编码的字符串对象"></p><h4 id="2-3-embstr-编码的字符串对象"><a href="#2-3-embstr-编码的字符串对象" class="headerlink" title="2.3 embstr 编码的字符串对象"></a>2.3 embstr 编码的字符串对象</h4><p>如果字符串保存的是一个字符串值，并且这个字符串值的长度小于等于 44 字节（根据版本的不同，这个值会有差异。详见 object.c 文件中的 OBJ_ENCODING_EMBSTR_SIZE_LIMIT 常量），那么字符串对象将使用 embstr 编码的方式来保存这个字符串。</p><p>embstr 编码是专门用于保存段字符串的一种优化编码方式，这种编码和 raw 编码一样，都使用 redisObject 和 sdshdr 结构来表示字符串对象。但和 raw 编码的字符串对象不同的是：</p><ul><li>raw 编码会调用两次内存分配函数来分别创建 redisObject 和 sdshdr 结构</li><li>embstr 编码通过一次内存分配函数分配一块连续的空间，空间中依次包含 redisObject 和 sdsHdr 两个结构。</li></ul><p>相对应的，释放内存时，embstr 编码的对象也只需调用一次内存释放函数。</p><p>因此，使用 embstr 编码的字符串对象来保存短字符串值有以下好处：</p><ul><li>创建字符串对象时，内存分配次数从两次降低为一次。</li><li>释放 embstr 编码的字符串对象时，调用内存释放函数的次数从两次降低为一次。</li><li>更好地利用缓存优势。embstr 编码的字符串对象的所有数据都保存在一块连续的内存中 ，这种方式比 raw 编码的字符串对象能够更好的利用缓存带来的优势。</li></ul><p>以下命令创建了一个 embstr 编码的字符串对象作为 msg 键的值，值对象结构如图 8。</p><pre><code>127.0.0.1:6380&gt; SET msg helloOK127.0.0.1:6380&gt; OBJECT ENCODING msg"embstr"</code></pre><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190523081623054_27949.png" alt="图 8 - embstr 编码的字符串对象"></p><h4 id="2-4-浮点数编码"><a href="#2-4-浮点数编码" class="headerlink" title="2.4 浮点数编码"></a>2.4 浮点数编码</h4><p>Redis 中，long double 类型的浮点数也是作为字符串值来保存的。</p><p>我们要保存一个浮点数到字符串对象中，程序会先将这个浮点数转换成字符串值，然后再保存转换所得的字符串值。</p><p>执行以下代码，将创建一个包含 3.14 的字符串表示 “3.14” 的字符串对象：</p><pre><code>127.0.0.1:6380&gt; SET pi 3.14OK127.0.0.1:6380&gt; OBJECT ENCODING pi"embstr"</code></pre><p>在有需要的时候，程序会将保存在字符串对象里的字符串值转换成浮点数值，执行某些操作，然后将所得的浮点数值转换回字符串值，继续保存在字符串对象中。</p><p>比如，我们对 pi 键执行以下操作：</p><pre><code>127.0.0.1:6380&gt; INCRBYFLOAT pi 2.0"5.14"127.0.0.1:6380&gt; OBJECT ENCODING pi"embstr"</code></pre><p>执行 <code>INCRBYFLOAT</code> 命令过程中，实际上就会出现字符串与浮点数值互相转换的情况。</p><h4 id="2-5-编码转换"><a href="#2-5-编码转换" class="headerlink" title="2.5 编码转换"></a>2.5 编码转换</h4><p>int 编码的字符串对象和 embstr 编码的字符串对象在满足某些条件的情况下，会被转换为 raw 编码的字符串对象。</p><p>对于 int 编码的字符串对象来说，如果我们在执行命令后，使得这个对象保存的不再是整数值，而是一个字符串，那么字符串对象就会从 int 变为 raw。比如 <code>APPEND</code> 命令等。</p><p>另外，对于 embstr 编码的字符串，由于 Redis 没有为其编写任何相应的修改程序，所以 embstr 编码的字符串对象实际上是只读的。当我们对 embstr 编码的字符串对象执行任何修改命令时，程序都会先将对象的编码从 embstr 转换成 raw。也就是说，<strong>embstr 编码的字符串一旦修改，一定会转换成 raw 编码的字符串对象</strong>。</p><h4 id="2-6-值与编码对应关系"><a href="#2-6-值与编码对应关系" class="headerlink" title="2.6 值与编码对应关系"></a>2.6 值与编码对应关系</h4><p>对于字符串对象各个编码的情况，总结如下：<br>| 值    | 编码|<br>| :– | :– |<br>| 可以用 long 表示的整数值    |  int   |<br>| 可以用 long double 保存的浮点数    |  raw 或 embstr   |<br>| 不可以用 long 或 long double 表示的整数或小数值    |  raw 或 embstr   |<br>|  大于 44 字节的字符串   |  raw   |<br>|  小于或等于 44 字节的字符串   |  embstr   |</p><h3 id="3-列表对象"><a href="#3-列表对象" class="headerlink" title="3 列表对象"></a>3 列表对象</h3><p>列表对象的可选编码分别是：quicklist（3.2 版本前是 ziplist 和 linkedlist）。</p><h4 id="3-1-quicklist-编码的列表对象"><a href="#3-1-quicklist-编码的列表对象" class="headerlink" title="3.1 quicklist 编码的列表对象"></a>3.1 quicklist 编码的列表对象</h4><p>3.2 版本引入了 quicklist 编码，此编码结合了 ziplist 和 linkedlist，使用双向链表的形式，在每个节点上存储一个 ziplist，而每个 ziplist 又可以存储多个键值对。也就是说，quicklist 每个节点上存储的不是一个数据，而是一片数据。</p><p>执行以下命令，服务器将会创建一个列表对象，quicklist 结构如图 8 所示：</p><pre><code>127.0.0.1:7379&gt; RPUSH animal 'dog' 'cat' 'pig'(integer) 3(5.12s)127.0.0.1:7379&gt; OBJECT ENCODING animal"quicklist"</code></pre><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190529085723132_9190.png" alt="图 8 - quicklist 编码的列表对象"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>Redis 自己实现了一套<strong>对象系统</strong>来实现所有功能。</li><li>对象有<strong>对象类型</strong>和<strong>对象编码</strong>。</li><li>对象类型对应<strong>字符串、列表、哈希、集合、有序集合五种</strong>。</li><li>对象编码对应<strong>跳跃表、压缩列表、集合、动态字符串等八种底层数据结构</strong>。</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 源码 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 对象和数据类型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟着大彬读源码 - Redis 4 - 服务器的事件驱动有什么含义？</title>
      <link href="/7/redis/yuanma/ck0669dxt007lagaacxuuc28n/"/>
      <url>/7/redis/yuanma/ck0669dxt007lagaacxuuc28n/</url>
      
        <content type="html"><![CDATA[<p>众所周知，Redis 服务器是一个事件驱动程序。那么事件驱动对于 Redis 而言有什么含义？源码中又是如何实现事件驱动的呢？今天，我们一起来认识下 Redis 服务器的事件驱动。</p><p>对于 Redis 而言，服务器需要处理以下两类事件：</p><ul><li><strong>文件事件（file event）</strong>：Redis 服务器通过套接字与客户端进行连接，而文件事件就是服务器对套接字操作的抽象。服务器与客户端的通信会产生相应的文件事件，而服务器则通过监听并处理这些事件来完成一系列的网络通信操作。</li><li><strong>时间时间（time event）</strong>：Redis 服务器中的一些操作（比如 serverCron 函数）需要在给定的时间点执行，而时间事件就是服务器对这类定时操作的抽象。</li></ul><p>接下来，我们先来认识下文件事件。</p><h3 id="1-文件事件"><a href="#1-文件事件" class="headerlink" title="1 文件事件"></a>1 文件事件</h3><p>Redis 基于 Reactor 模式开发了自己的网络事件处理器，这个处理器被称为<strong>文件事件处理器（file event handler）</strong>：</p><ul><li>文件事件处理器使用 IO 多路复用程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。</li><li>当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。</li></ul><p>虽然文件处理器以单线程方式运行，但通过 IO 多路复用程序监听多个套接字，既实现了高性能的网络通信模型，又可以很好的与 Redis 服务器中其它同样以单线程运行的模块进行对接，保持了 Redis 内部单线程设计的简洁。</p><h4 id="1-1-文件事件处理器的构成"><a href="#1-1-文件事件处理器的构成" class="headerlink" title="1.1 文件事件处理器的构成"></a>1.1 文件事件处理器的构成</h4><p>图 1 展示了文件事件处理器的四个组成部分：</p><ul><li>套接字；</li><li>IO 多路复用程序；</li><li>文件事件分派器（dispatcher）；</li><li>事件处理器；</li></ul><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190613124505742_9741.png" alt="文件事件处理器的四个组成部分"></p><p>文件事件是对套接字的抽象。每当一个套接字准备好执行连接应答（accept）、写入、读取、关闭等操作时，就好产生一个文件事件。因为一个服务器通常会连接多个套接字，所以多个文件事件有可能会并发的出现。</p><p>而 IO 多了复用程序负责监听多个套接字，并向文件事件分派器分发那些产生事件的套接字。</p><p>尽管多个文件事件可能会并发的出现，但 IO 多路复用程序总是会将所有产生事件的套接字都放到一个队列里面，然后通过这个队列，以<strong>有序、同步</strong>的方式，把每一个套接字传输给文件事件分派器。当上一个套接字产生的事件被处理完毕之后（即，该套接字为事件所关联的事件处理器执行完毕），IO 多路复用程序才会继续向文件事件分派器传送下一个套接字。如图 2 所示：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190613125101059_19351.png" alt="图 2 - IO 多路复用程序通过队列向文件事件分派器传送套接字"></p><p>文件事件分派器接收 IO 多路复用程序传来的套接字，并根据套接字产生的事件类型，调用相应的事件处理器。</p><p>服务器会为执行不同任务的套接字关联不同的事件处理器。<strong>这些处理器本质上就是一个个函数</strong>。它们定义了某个事件发生时，服务器应该执行的动作。</p><h4 id="1-2-IO-多路复用程序的实现"><a href="#1-2-IO-多路复用程序的实现" class="headerlink" title="1.2 IO 多路复用程序的实现"></a>1.2 IO 多路复用程序的实现</h4><p>Redis 的 IO 多路复用程序的所有功能都是通过包装常见的 <strong>select、epoll、evport 和 kqueue</strong> 这些 IO 多路复用函数库来实现的。每个 IO 多路复用函数库在 Redis 源码中都对应一个单独的文件，比如 ae_select.c、ae_poll.c、ae_kqueue.c 等。</p><p>由于 Redis 为每个 IO 多路复用函数库都实现了相同的 API，所以 IO 多路复用程序的底层实现是可以互换的，如图 3 所示：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190613125627879_24040.png" alt="图 3 - Redis 的 IO 多路复用程序有多个 IO 多路复用库实现可选"></p><p>Redis 在 IO 多路复用程序的实现源码中用 <code>#include</code> 宏定义了相应的规则，**程序会在编译时自动选择系统中性能最高的 IO 多路复用函数库来作为 Redis 的 IO 多路复用程序的底层实现，这保证了 Redis 在各个平台的兼容性和高性能。对应源码如下：</p><pre><code>/* Include the best multiplexing layer supported by this system. * The following should be ordered by performances, descending. */#ifdef HAVE_EVPORT#include "ae_evport.c"#else    #ifdef HAVE_EPOLL    #include "ae_epoll.c"    #else        #ifdef HAVE_KQUEUE        #include "ae_kqueue.c"        #else        #include "ae_select.c"        #endif    #endif#endif</code></pre><h4 id="1-3-事件的类型"><a href="#1-3-事件的类型" class="headerlink" title="1.3 事件的类型"></a>1.3 事件的类型</h4><p>IO 多路复用程序可以监听多个套接字的 <code>ae.h/AE_READABLE</code> 和 <code>ae.h/AE_WRITABLE</code> 事件，这两类事件和套接字操作之间有以下对应关系：</p><ul><li><strong>当服务器套接字变得可读时，套接字会产生 AE_READABLE 事件</strong>。此处的套接字可读，是指客户端对套接字执行 write、close 操作，或者有新的可应答（acceptable）套接字出现时（客户端对服务器的监听套接字执行 connect 操作），套接字会产生 AE_READABLE 事件。</li><li><strong>当服务器套接字变得可写时，套接字会产生 AE_WRITABLE 事件。</strong></li></ul><p>IO 多路复用程序允许服务器同时监听套接字的 AR_READABLE 事件和 AE_WRITABLE 事件。如果一个套接字同时产生了两个事件，那么文件分派器会优先处理 AE_READABLE 事件，然后再处理 AE_WRITABLE 事件。简单来说，如果一个套接字既可读又可写，那么服务器将先读套接字，后写套接字。</p><h4 id="1-4-文件事件处理器"><a href="#1-4-文件事件处理器" class="headerlink" title="1.4 文件事件处理器"></a>1.4 文件事件处理器</h4><p>Redis 为文件事件编写了多个处理器，这些事件处理器分别用于实现不同的网络通信需求。比如说：</p><ul><li>为了对连接服务器的各个客户端进行应答，服务器要<strong>为监听套接字关联连接应答处理器</strong>。</li><li>为了接收客户端传了的命令请求，服务器要<strong>为客户端套接字关联命令请求处理器</strong>。</li><li>为了向客户端返回命令执行结果，服务器要<strong>为客户端套接字关联命令回复处理器</strong>。</li><li>当主服务器和从服务器进行复制操作时，<strong>主从服务器都需要关联复制处理器</strong>。</li></ul><p>在这些事件处理器中，服务器最常用的是<strong>与客户端进行通信的连接应答处理器、命令请求处理器和命令回复处理器</strong>。</p><p><strong>1）连接应答处理器</strong></p><p><code>networking.c/acceptTcpHandle</code> 函数是 Redis 的连接应答处理器，这个处理器用于对连接服务器监听套接字的客户端进行应答，具体实现为 <code>sys/socket.h/accept</code> 函数的包装。</p><p>当 Redis 服务器进行初始化的时候，程序会将这个连接应答处理器和服务器监听套接字的 AE_READABLE 事件关联。对应源码如下</p><pre><code># server.c/initServer.../* Create an event handler for accepting new connections in TCP and Unix * domain sockets. */for (j = 0; j &lt; server.ipfd_count; j++) {    if (aeCreateFileEvent(server.el, server.ipfd[j], AE_READABLE,        acceptTcpHandler,NULL) == AE_ERR)        {            serverPanic(                "Unrecoverable error creating server.ipfd file event.");        }}...</code></pre><p>当有客户端用 <code>sys/scoket.h/connect</code> 函数连接服务器监听套接字时，套接字就会产生 AE_READABLE 事件，引发连接应答处理器执行，并执行相应的套接字应答操作。如图 4 所示：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190614123503033_20651.png" alt="图 4 - 服务器对客户端的连接请求进行应答"></p><p><strong>2）命令请求处理器</strong><br><code>networking.c/readQueryFromClient</code> 函数是 Redis 的命令请求处理器，这个处理器负责从套接字中读入客户端发送的命令请求内容，具体实现为 <code>unistd.h/read</code> 函数的包装。</p><p>当一个客户端通过连接应答处理器成功连接到服务器之后，服务器会将客户端套接字的 AE_READABLE 事件和命令请求处理器关联起来（<code>networking.c/acceptCommonHandler</code> 函数）。</p><p>当客户端向服务器发送命令请求的时候，套接字就会产生 AR_READABLE 事件，引发命令请求处理器执行，并执行相应的套接字读入操作，如图 5 所示：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190614124918037_1589.png" alt="图 5 - 服务器接收客户端发来的命令请求"></p><p>在客户端连接服务器的整个过程中，服务器都会一直为客户端套接字的 AE_READABLE 事件关联命令请求处理器。</p><p><strong>3）命令回复处理器</strong><br><code>networking.c/sendReplToClient</code> 函数是 Redis 的命令回复处理器，这个处理器负责将服务器执行命令后得到的命令回复通过套接字返回给客户端。</p><p>当服务器有命令回复需要发给客户端时，服务器会将客户端套接字的 AE_WRITABLE 事件和命令回复处理器关联（<code>networking.c/handleClientsWithPendingWrites</code> 函数）。</p><p>当客户端准备好接收服务器传回的命令回复时，就会产生 AE_WRITABLE 事件，引发命令回复处理器执行，并执行相应的套接字写入操作。如图 6 所示：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190614125858054_14856.png" alt="图 6 - 服务器向客户端发送命令回复"></p><p>当命令回复发送完毕之后，服务器就会解除命令回复处理器与客户端套接字的 AE_WRITABLE 事件的关联。对应源码如下：</p><pre><code># networking.c/writeToClient...if (!clientHasPendingReplies(c)) {    c-&gt;sentlen = 0;    # buffer 缓冲区命令回复已发送，删除套接字和事件的关联    if (handler_installed) aeDeleteFileEvent(server.el,c-&gt;fd,AE_WRITABLE);    /* Close connection after entire reply has been sent. */    if (c-&gt;flags &amp; CLIENT_CLOSE_AFTER_REPLY) {        freeClient(c);        return C_ERR;    }}...</code></pre><h4 id="1-5-客户端与服务器连接事件"><a href="#1-5-客户端与服务器连接事件" class="headerlink" title="1.5 客户端与服务器连接事件"></a>1.5 客户端与服务器连接事件</h4><p>之前我们通过 debug 的形式大致认识了客户端与服务器的连接过程。现在，我们站在文件事件的角度，再一次来追踪 Redis 客户端与服务器进行连接并发送命令的整个过程，看看在过程中会产生什么事件，这些事件又是如何被处理的。</p><p>先来看客户端与服务器建立连接的过程：</p><ol><li>先启动我们的 Redis 服务器（127.0.0.1-8379）。成功启动后，服务器套接字（127.0.0.1-8379） AE_READABLE 事件正处于被监听状态，而该事件对应连接应答处理器。（<code>server.c/initServer()</code>）。</li><li>使用 redis-cli 连接服务器。这是，服务器套接字（127.0.0.1-8379）将产生 AR_READABLE 事件，触发连接应答处理器执行（<code>networking.c/acceptTcpHandler()</code>）。</li><li>对客户端的连接请求进行应答，创建客户端套接字，保存客户端状态信息，并将客户端套接字的 AE_READABLE 事件与命令请求处理器（<code>networking.c/acceptCommonHandler()</code>）进行关联，使得服务器可以接收该客户端发来的命令请求。 </li></ol><p>此时，客户端已成功与服务器建立连接了。上述过程，我们仍然可以用 gdb 调试，查看函数的执行过程。具体调试过程如下：</p><pre><code>gdb ./src/redis-server(gdb) b acceptCommonHandler    # 给 acceptCommonHandler 函数设置断点(gdb) r redis-conf --port 8379 # 启动服务器</code></pre><p>另外开一个窗口，使用 redis-cli 连接服务器：<code>redis-cli -p 8379</code></p><p>回到服务器窗口，我们会看到已进入 gdb 调试模式，输入：<code>info stack</code>，可以看到如图 6 所示的堆栈信息。</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190614133035004_12904.png" alt="图 6 - gdb 调试显示客户端连接时服务器的堆栈信息"></p><p>现在，我们再来认识命令的执行过程：</p><ol start="2"><li>客户端向服务器发送一个命令请求，客户端套接字产生 AE_READABLE 事件，引发命令请求处理器（readQueryFromClient）执行，读取客户端的命令内容；</li><li>根据客户端发送命令内容，格式化客户端 argc、argv 等相关值属性值；</li><li>根据命令名称查找对应函数。<code>server.c/processCommad()</code> 中 <code>lookupCommand</code> 函数调用；</li><li>执行与命令名关联的函数，获得返回结果，客户端套接字产生 。<code>server.c/processCommad()</code> 中 <code>call</code> 函数调用。</li><li>返回命令回复，删除客户端套接字与 AE_WRITABLE 事件的关联。<code>network.c/writeToClient()</code> 函数。</li></ol><p>图 7 展示了命令执行过程的堆栈信息。图 8 则展示了命令回复过程的堆栈信息。<br><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190614180606647_15447.png" alt="图 7 - 服务器执行命令的堆栈信息"></p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190617195653689_22592.png" alt="图 8 - 命令回复的堆栈信息"></p><p>上一节我们一起认识了文件事件。接下来，让我们再来认识下时间事件。</p><h3 id="2-时间事件"><a href="#2-时间事件" class="headerlink" title="2 时间事件"></a>2 时间事件</h3><p>Redis 的时间时间分为以下两类：</p><ul><li><strong>定时时间</strong>：让一段程序在指定的时间之后执行一次。比如，让程序 M 在当前时间的 60 毫秒后执行一次。</li><li><strong>周期性事件</strong>：让一段程序每隔指定时间就执行一次。比如，让程序 N 每隔 30 毫秒执行一次。</li></ul><p>对于时间事件，数据结构源码（ae.h/aeTimeEvent）：</p><pre><code>/* Time event structure */typedef struct aeTimeEvent {    long long id; /* time event identifier. */    long when_sec; /* seconds */    long when_ms; /* milliseconds */    aeTimeProc *timeProc;    aeEventFinalizerProc *finalizerProc;    void *clientData;    struct aeTimeEvent *next;} aeTimeEvent;</code></pre><p>主要属性说明：</p><ul><li>id：服务器为时间事件创建的全局唯一 ID。ID 号按从小到大的顺序递增。</li><li>when_sec：秒精度的 UNIX 时间戳，记录了时间事件的到达时间。</li><li>when_ms：毫秒精度的 UNIX 时间戳，记录了时间事件的到达时间。</li><li>timeProc：时间事件处理器，对应一个函数。当时间事件发生时，服务器就会调用相应的处理器来处理事件。</li></ul><p>时间事件进程执行的函数为 <code>ae.c/processTimeEvents()</code>。</p><p>此外，对于时间事件的类型区分，取决于时间事件处理器的返回值：</p><ul><li>返回值是 <code>ae.h/AE_NOMORE</code>，为<strong>定时事件</strong>。该事件在到达一次后就会被删除；</li><li>返回值不是 <code>ae.h/AE_NOMORE</code>，为<strong>周期事件</strong>。当一个周期时间事件到达后，服务器会根据事件处理器返回的值，对时间事件的 when_sec 和 when_ms 属性进行更新，让这个事件在一段时间之后再次到达，并以这种方式一致更新运行。比如，如果一个时间事件处理器返回 30，那么服务器应该对这个时间事件进行更新，让这个事件在 30 毫秒后再次执行。</li></ul><h4 id="2-1-时间事件之-serverCron-函数"><a href="#2-1-时间事件之-serverCron-函数" class="headerlink" title="2.1 时间事件之 serverCron 函数"></a>2.1 时间事件之 serverCron 函数</h4><p>持续运行的 Redis 服务器需要定期对自身的资源和状态进行检查和调整，从而确保服务可以长期、稳定的运行。这些定期操作由 <code>server.c/serverCron()</code> 函数负责执行。主要操作包括：</p><ul><li>更新服务器的各类统计信息。比如时间、内存占用、数据库占用情况等。</li><li>清理数据库中的过期键值对。</li><li>关闭和清理连接失效的客户端。</li><li>尝试进行 AOF 或 RDB 持久化操作。</li><li>如果服务器是主服务器，对从 服务器进行定期同步。</li><li>如果处于集群模式，对集群进行定期同步和连接测试。</li></ul><p>Redis 服务器以周期性事件的方式来运行 serverCron 函数，在服务器运行期间，每隔一段时间，serverCron 就会执行一次，直到服务器关闭为止。</p><p>关于执行次数，可参见 <code>redis.conf</code> 文件中的 <strong>hz</strong> 选项。默认为 10，表示每秒运行 10 次。</p><h3 id="3-事件调度与执行"><a href="#3-事件调度与执行" class="headerlink" title="3 事件调度与执行"></a>3 事件调度与执行</h3><p>由于服务器同时存在文件事件和时间事件，所以服务器必须对这两种事件进行调度，来决定何时处理文件事件，何时处理时间事件，以及花多少时间来处理它们等等。</p><p>事件的调度和执行有 <code>ae.c/aeProcessEvents()</code> 函数负责。源码如下：</p><pre><code>int aeProcessEvents(aeEventLoop *eventLoop, int flags){    int processed = 0, numevents;    /* Nothing to do? return ASAP */    if (!(flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_FILE_EVENTS)) return 0;    /* 首先判断是否存在需要监听的文件事件，如果存在需要监听的文件事件，那么通过IO多路复用程序获取     * 准备就绪的文件事件，至于IO多路复用程序是否等待以及等待多久的时间，依发生时间距离现在最近的时间事件确定;     * 如果eventLoop-&gt;maxfd == -1表示没有需要监听的文件事件，但是时间事件肯定是存在的(serverCron())，     * 如果此时没有设置 AE_DONT_WAIT 标志位，此时调用IO多路复用，其目的不是为了监听文件事件是否准备就绪，     * 而是为了使线程休眠到发生时间距离现在最近的时间事件的发生时间(作用类似于unix中的sleep函数),     * 这种休眠操作的目的是为了避免线程一直不停的遍历时间事件形成的无序链表，造成不必要的资源浪费 */    if (eventLoop-&gt;maxfd != -1 ||        ((flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_DONT_WAIT))) {        int j;        aeTimeEvent *shortest = NULL;        struct timeval tv, *tvp;        /* 寻找发生时间距离现在最近的时间事件,该时间事件的发生时间与当前时间之差就是IO多路复用程序应该等待的时间 */        if (flags &amp; AE_TIME_EVENTS &amp;&amp; !(flags &amp; AE_DONT_WAIT))            shortest = aeSearchNearestTimer(eventLoop);        if (shortest) {            long now_sec, now_ms;            // 创建 timeval 结构            aeGetTime(&amp;now_sec, &amp;now_ms);            tvp = &amp;tv;            /* How many milliseconds we need to wait for the next             * time event to fire? */            long long ms =                (shortest-&gt;when_sec - now_sec)*1000 +                shortest-&gt;when_ms - now_ms;            /* 如果时间之差大于0，说明时间事件到时时间未到,则等待对应的时间;             * 如果时间间隔小于0，说明时间事件已经到时，此时如果没有             * 文件事件准备就绪，那么IO多路复用程序应该立即返回，以免             * 耽误处理时间事件*/            if (ms &gt; 0) {                tvp-&gt;tv_sec = ms/1000;                tvp-&gt;tv_usec = (ms % 1000)*1000;            } else {                tvp-&gt;tv_sec = 0;                tvp-&gt;tv_usec = 0;            }        } else {            /* If we have to check for events but need to return             * ASAP because of AE_DONT_WAIT we need to set the timeout             * to zero */            if (flags &amp; AE_DONT_WAIT) {                tv.tv_sec = tv.tv_usec = 0;                tvp = &amp;tv;            } else {                /* Otherwise we can block */                tvp = NULL; /* wait forever */            }        }        // 阻塞并等等文件事件产生，最大阻塞事件由 timeval 结构决定        numevents = aeApiPoll(eventLoop, tvp);        for (j = 0; j &lt; numevents; j++) {            // 处理所有已产生的文件事件            aeFileEvent *fe = &amp;eventLoop-&gt;events[eventLoop-&gt;fired[j].fd];            int mask = eventLoop-&gt;fired[j].mask;            int fd = eventLoop-&gt;fired[j].fd;            int fired = 0; /* Number of events fired for current fd. */            int invert = fe-&gt;mask &amp; AE_BARRIER;            if (!invert &amp;&amp; fe-&gt;mask &amp; mask &amp; AE_READABLE) {                fe-&gt;rfileProc(eventLoop,fd,fe-&gt;clientData,mask);                fired++;            }            /* Fire the writable event. */            if (fe-&gt;mask &amp; mask &amp; AE_WRITABLE) {                if (!fired || fe-&gt;wfileProc != fe-&gt;rfileProc) {                    fe-&gt;wfileProc(eventLoop,fd,fe-&gt;clientData,mask);                    fired++;                }            }            /* If we have to invert the call, fire the readable event now             * after the writable one. */            if (invert &amp;&amp; fe-&gt;mask &amp; mask &amp; AE_READABLE) {                if (!fired || fe-&gt;wfileProc != fe-&gt;rfileProc) {                    fe-&gt;rfileProc(eventLoop,fd,fe-&gt;clientData,mask);                    fired++;                }            }            processed++;        }    }    /* Check time events */    if (flags &amp; AE_TIME_EVENTS)        // 处理所有已到达的时间事件        processed += processTimeEvents(eventLoop);    return processed; /* return the number of processed file/time events */}</code></pre><p>将 <code>aeProcessEvents</code> 函数置于一个循环里面，加上初始化和清理函数，就构成了 Redis 服务器的主函数 <code>server.c/main()</code>。以下是主函数的伪代码：</p><pre><code>def main():    // 初始化服务器    init_server();    // 一直处理事件，直到服务器关闭为止    while server_is_not_shutdown():        aeProcessEvents();    // 服务器关闭，执行清理操作    clear_server()</code></pre><p>从事件处理的角度来看，Redis 服务器的运行流程可以用流程图 1 来概括：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190706151711050_31836.png" alt="图 1：事件处理角度下的服务器运行流程"></p><p>以下是事件的调度和执行规则：</p><ol><li>aeApiPoll 函数的最大阻塞事件由到达时间最接近当前时间的时间事件决定。这个方法既可以避免服务器对时间事件进行频繁的轮询，也可以确保 aeApiPoll 函数不会阻塞过长时间。</li><li>因为文件事件是随机出现的，如果等待并处理完一次文件事件之后，仍未有任何时间事件到达，那么服务器将再次等待并处理文件事件。随着文件事件的不断执行，时间会逐渐向时间事件所设置的到达时间逼近，并最终来到，这时服务器就可以开始处理到达的时间事件了。</li><li>对文件事件和时间事件的处理都是<strong>同步、有序、原子</strong>地执行。服务器不会中途中断事件处理，也不会对事件进行抢占。因此，不管是文件事件的处理器，还是时间事件的处理器，它们斗殴尽可能的减少程序的阻塞事件，并在有需要时主动让出执行权，从而降低事件饥饿的可能性。举个栗子，在命令回复处理器将一个命令回复写入到客户端套接字时，如果写入字节数超过了一个预设常量，命令回复处理器就会主动用 break 跳出写入循环，将余下的数据留到下次再写。另外，时间事件也会将非常耗时的持久化操作放到子线程或者子进程中执行。</li><li>因为时间事件在文件事件之后执行，并且事件之间不会出现抢占，所以时间事件的实际处理时间，通常会比时间事件设定的时间稍晚一些。</li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>Redis 服务器是一个事件驱动程序，服务器处理的事件分为<strong>时间事件</strong>和<strong>文件事件</strong>两类。</li><li>文件事件是对套接字操作的抽象。**每次套接字变得可应答（acceptable）、可写（writable）或者可读（readable）时，相应的文件事件就会产生。</li><li>文件事件分为 AE_READABLE 事件（读事件）和 AE_WRITABLE 事件（写事件）两类。</li><li>时间事件分为定时事件和周期事件。定时事件只在指定时间执行一次，而周期事件则每隔指定时间执行一次。</li><li>服务器一般情况下只执行 serverCron 函数这一个周期性时间事件。</li><li>时间事件和文件事件之间是合作关系。服务器会轮流处理这两种事件，并且处理事件的过程中不会进行抢占。</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 源码 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 事件驱动 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟着大彬读源码 - Redis 3 - 服务器如何响应客户端请求？（下）</title>
      <link href="/7/redis/yuanma/ck0669ds2003cagaa7h6qucgs/"/>
      <url>/7/redis/yuanma/ck0669ds2003cagaa7h6qucgs/</url>
      
        <content type="html"><![CDATA[<p>继续我们上一节的讨论。服务器启动了，客户端也发送命令了。接下来，就要到服务器“表演”的时刻了。</p><h3 id="1-服务器处理"><a href="#1-服务器处理" class="headerlink" title="1 服务器处理"></a>1 服务器处理</h3><p>服务器读取到命令请求后，会进行一系列的处理。</p><h4 id="1-1-读取命令请求"><a href="#1-1-读取命令请求" class="headerlink" title="1.1 读取命令请求"></a>1.1 读取命令请求</h4><p>当客户端与服务器之间的套接字因客户端的写入变得可读时，服务器将调用命令请求处理器执行以下操作：</p><ol><li>读取套接字中的命令请求，并将其保存到客户端状态的输入缓冲区。</li><li>对输入缓冲区的命令请求进行分析，提取出命令请求中包含的命令参数及参数个数，然后分别将参数和参数个数保存到客户端状态的 argv 属性和 argc 属性里。</li><li>调用命令执行器，执行客户端指定的命令。</li></ol><p>上面的 <code>SET</code> 命令保存到客户端状态的输入缓存区之后，客户端状态如图 4。</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190605220440144_29575.png" alt="图 4 - 客户端状态中的命令请求"></p><p>之后，分析程序将对输入缓冲区中的协议进行分析，并将得出的结果保存的客户端的 argv 和 argc 属性中，如图 5 所示：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190605220637329_1161.png" alt="图 5 - 客户端状态中的 argv 和 argc 属性"></p><p>之后，服务器将通过调用<strong>命令执行器</strong>来完成执行命令的余下步骤。</p><h4 id="1-2-查找命令实现"><a href="#1-2-查找命令实现" class="headerlink" title="1.2 查找命令实现"></a>1.2 查找命令实现</h4><p>命令执行器要做的第一件事就是根据 argv[0] 参数，在命令表（commandtable）中查找参数所指定的命令，并将找到的命令保存到 cmd 属性中。</p><p>命令表是一个字典，字典的键是一个个命令名称，比如 “SET”、”GET” 等。而字典的值则是一个个 redisCommand 结构，每个 redisCommand 结构记录了 Redis 命令的实现信息。源码如下：</p><pre><code># server.h/redisCommandstruct redisCommand {    char *name;   // 命令名称。如 "SET"    redisCommandProc *proc; // 对应函数指针，指向命令的实现函数。比如 SET 对应的 setCommand 函数    int arity;    // 命令参数的格个数。用来检查命令请求的格式是否合法。                        // 要注意的命令的名称也是一个参数。像我们上面的 SET KEY VALUE 命令，实际上有三个参数。    char *sflags; // 字符串形式的标识值。记录了命令的属性。    int flags;    // 对 sflags 标识分析得出的二进制标识，由程序自动生成。检查命令时，实际上使用的是此字段    redisGetKeysProc *getkeys_proc; // 指针函数，通过此方法来指定 key 的位置。    int firstkey; // 第一个 key 的位置    int lastkey;  // 最后一个 key 的位置    int keystep;  // key 之间的间距    long long microseconds, calls; // 命令的总调用时间及调用次数};</code></pre><p>另外，对于 sflags 属性，可使用的标识值及含义如下表：</p><table><thead><tr><th align="center">标识</th><th>意义</th><th>带有此标识的命令</th></tr></thead><tbody><tr><td align="center">w</td><td>这是一个写入命令，可能会修改数据库</td><td>SET、RPUSH、DEL 等</td></tr><tr><td align="center">r</td><td>这是一个只读命令，不会修改数据库</td><td>GET、STRLEN 等</td></tr><tr><td align="center">m</td><td>此命令可能会占用大量内存，执行器需先检查内存使用情况，如果内存紧缺就禁止执行此命令</td><td>SET、APPEND、RPUSH、SADD 等</td></tr><tr><td align="center">a</td><td>这是一个管理命令</td><td>SAVE、BGSAVE 等</td></tr><tr><td align="center">p</td><td>这是一个发布与订阅功能的命令</td><td>PUBLISH、SUBSRIBE 等</td></tr><tr><td align="center">s</td><td>这个命令不可以在 lua 脚步中使用</td><td>BPOP、BLPOP 等</td></tr><tr><td align="center">R</td><td>这是一个随机命令。对于相同的数据集和相同的参数，返回结果可能不同</td><td>SPOP、SRANDMEMBER 等</td></tr><tr><td align="center">S</td><td>当在 lua 脚步中使用此命令时，对返回结果进行排序，使得结果有序</td><td>SINTER、SUNION 等</td></tr><tr><td align="center">l</td><td>这个命令可以在服务器载入数据的过程中使用</td><td>INFO、PUBLISH 等</td></tr><tr><td align="center">t</td><td>这个命令允许在从库有过期数据时使用</td><td>SLAVEOF、PING 等</td></tr><tr><td align="center">M</td><td>这个命令在监视模式下，不会被自动传播</td><td>EXEC</td></tr><tr><td align="center">k</td><td>集群模式下，如果对应槽点标记位“导入”，则接受此命令</td><td>restore-asking</td></tr><tr><td align="center">F</td><td>这个命令在程序执行时应该立刻执行</td><td>SETNX、GET 等</td></tr></tbody></table><p>命令表结构如图 6：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190606123755943_21138.png" alt="图 6 - 命令表"></p><p>对于我们上面的 <code>SET KEY VALUE</code> 命令，当程序以图 5 中的 argv[0] 作为输入，在命令表中进行查找时，命令表返回 “set” 键对于的 redisCommand 结构，客户端状态的 cmd 指针会指向这个 redisCommand 结构。如图 7 所示：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190606124028494_23495.png" alt="图 7 - 设置客户端状态的 cmd 指针"></p><p>要注意的是，对于 Redis 而言，<strong>命令名字的大小写不影响命令表的查找结果</strong>，也就是命令名称不区分大小写。执行 SET 和 set、Set 将获得相同结果。</p><h4 id="1-3-执行预备操作"><a href="#1-3-执行预备操作" class="headerlink" title="1.3 执行预备操作"></a>1.3 执行预备操作</h4><p>到目前为止，服务器已经将执行命令所需要的命令实现函数（客户端 cmd 属性）、参数（客户端 argv 属性）、参数个数（客户端 argc 属性）都初始化完毕。但在真正执行命令之前，程序还会进行一些预备操作，保证命令可以正确、顺利的被执行。预备操作包括：</p><ol><li>检查客户端的 cmd 指针是否指向 NULL，如果是的话，说明用户输入的命令名称没有对应的函数，服务器将不再执行后续操作，并向客户端返回一个错误。</li><li>根据客户端 cmd 属性指向的 redisCommand 结果的 arity 属性，检查命令请求所给定的<strong>参数个数</strong>是否正确。</li><li>检查客户端是否已经通过了身份验证。未通过身份验证的客户端只能执行 <code>AUTH</code> 命令。否则，将会向客户端返回一个错误。</li><li>如果服务器打开了 maxmemory 功能，在执行命令之前，会先检查服务器的内存占用情况，并在有需要时进行内存回收，从而使得接下来的命令可以顺利执行。如果内存回收失败，将不再执行后续步骤，向客户端返回一个错误。</li><li>如果服务器上一次执行 <code>BGSAVE</code> 命令时出错，并且服务器打开了 <em>stop-writes-on-bgsave-error</em> 功能，而将要执行的命令是一个写命令，那么服务器将拒绝执行这个鞋命令，并向客户端返回一个错误。</li><li>如果客户端正在用 <code>SUBSCRIBE</code> 和 <code>PSUBSCRIBE</code> 命令订阅频道或模式，那么服务器只会执行客户端发来的 <code>SUBSCRIBE</code>、<code>PSUBSCRIBE</code>、<code>UNSUBSCRIBE</code>、<code>PUNSUBSCRIBE</code> 四个命令，其它命令都会被拒绝。</li><li>如果服务器正在进行数据载入，那么客户端发送是命令必须带有 <code>l</code> 标识才会被服务器执行。</li><li>如果客户端正在执行事务，那么服务器只会执行 <code>EXEC</code>、<code>DISCARD</code>、<code>MULTI</code>、<code>WATCH</code> 四个命令，其他命令都会被放进事务队列中。</li><li>如果服务器打开了监视器功能，那么服务器会将要执行的命令和参数等信息发送给监视器。</li></ol><p>当完成了以上预备操作之后，服务器就开始真正的执行命令了。</p><p>要注意的是，上面列出的预备操作只是服务器在单机模式下的检查操作。如果在复制或者集群模式下，预备操作还会更多。</p><h4 id="1-4-调用命令的实现函数"><a href="#1-4-调用命令的实现函数" class="headerlink" title="1.4 调用命令的实现函数"></a>1.4 调用命令的实现函数</h4><p>在前面的操作中 ，服务器已经将要执行的命令实现、参数、参数个数保存在客户端结构中。</p><p>对于我们上面的 <code>SET KEY VALUE</code> 命令，图 8 包含了命令实现、参数和参数个数结构：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190606130340397_25001.png" alt="图 8 - 客户端状态"></p><p>当服务器决定要执行命令时，只要执行以下语句即可：</p><pre><code>// client 是指向客户端状态的指针。server.c/call()client-&gt;cmd-&gt;proc(client);</code></pre><p>上面的执行语句实际上就是调用 <code>setCommand</code> 函数（t_string.c）。</p><p>被调用的命令实现函数会执行指定的操作，并产生相应的命令回复，这些回复会被保存在客户端状态的输出缓冲区中（bug 属性 和 reply 属性），之后实现函数会为客户端的套接字关联命令回复处理器，由命令回复处理器返回给客户端。</p><p>回到我们的示例，<code>setCommand(client)</code> 将产生一个 “+OK\r\n” 回复，这个回复被保存在客户端的 buf 属性中。如图 9 所示：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190606130904312_21491.png" alt="图 9 - 保存了命令回复的客户端状态"></p><h4 id="1-5-执行后续工作"><a href="#1-5-执行后续工作" class="headerlink" title="1.5 执行后续工作"></a>1.5 执行后续工作</h4><p>实现函数执行完后，服务器还会执行一些后续工作，主要包括：</p><ol><li>如果服务器开启了 slow-log 功能，那么慢查询日志模块将会检查是否需要将刚执行的命令添加到慢查询日志。</li><li>更新 <code>redisCommand</code> 结构的 milliseconds 和 calls 属性。</li><li>如果服务器开启了 AOF 持久化功能，那么 AOF 持久化模块会将刚刚执行的命令请求写入到 AOF 缓冲区中。</li><li>如果有其它服务器正在复制当前这个服务器，那么服务器将会把刚刚执行的命令传播给所有从服务器。</li></ol><p>以上后续操作执行完毕后，一条执行命令也就执行完成了。服务器可以继续处理后续的命令。</p><h4 id="1-6-将命令回复发送给客户端"><a href="#1-6-将命令回复发送给客户端" class="headerlink" title="1.6 将命令回复发送给客户端"></a>1.6 将命令回复发送给客户端</h4><p>上面过程中，命令实现函数会将命令回复保存到客户端的输出缓冲区中，并为客户端的套接字关联命令回复处理器。当客户端套接字变为可写状态时，服务器就会执行命令回复处理器，将命令回复发送给客户端。</p><p>当命令回复发送完毕后，回复处理器会情况客户端的输出缓冲区，为处理下一个命令请求做好准备。</p><p>以图 9 所示的客户端状态为例，当客户端的套接字变为可写状态时，命令回复处理器会将协议格式的命令回复 “+OK\r\n” 发送给客户端。</p><h4 id="1-7-源码解读"><a href="#1-7-源码解读" class="headerlink" title="1.7 源码解读"></a>1.7 源码解读</h4><p>命令处理请求，函数调用堆栈信息如图 3-7-1：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190614180606647_15447.png" alt="图 3-7-1：命令执行过程函数堆栈信息"></p><p>命令回复，函数调用堆栈信息如图 3-7-2：<br><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190617195653689_22592.png" alt="图 3-7-2：命令回复函数堆栈信息"></p><h3 id="2-客户端接收并打印回复"><a href="#2-客户端接收并打印回复" class="headerlink" title="2 客户端接收并打印回复"></a>2 客户端接收并打印回复</h3><p>客户端接收到命令回复之后，会将回复转换成我们可读的格式，并打印在屏幕上（对于 redis-cli 客户端），如图 10 所示。</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190612080448952_13253.png" alt="图 10 客户端接收并打印命令回复的过程"></p><p>至此，我们走完了从发起一个命令请求，到收到回复的所有过程。对于我们最开始提的问题，服务器如何响应客户端请求，你有答案了吗？</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>服务器通过 <code>networking.c/readQueryFromClient()</code> 读取和执行对应命令。</li><li>服务器通过 <code>networking.c/writeToClient()</code> 将命令回复发送给客户端。</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 源码 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 服务器响应客户端请求 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟着大彬读源码 - Redis 2 - 服务器如何响应客户端请求？（上）</title>
      <link href="/7/redis/yuanma/ck0669det000gagaayekwotzx/"/>
      <url>/7/redis/yuanma/ck0669det000gagaayekwotzx/</url>
      
        <content type="html"><![CDATA[<p>上次我们通过问题“启动服务器，程序都干了什么？”，跟着源码，深入了解了 Redis 服务器的启动过程。</p><p>既然启动了 Redis 服务器，那我们就要连上 Redis 服务干些事情。这里我们可以通过 redis-cli 测试。</p><p>现在客户端和服务器都准备好了，那么<strong>Redis 客户端和服务器如何建立连接？服务器又是如何响应客户端的请求呢？</strong></p><h3 id="1-连接服务器"><a href="#1-连接服务器" class="headerlink" title="1 连接服务器"></a>1 连接服务器</h3><p>客户端和服务器进行通讯，首先应该就是建立连接。接下来，我们来看下 redis-cli 与服务器的连接过程。</p><p>还记得我们上次使用 <code>gdb</code> 调试程序的步骤吗？让我们对 redis-cli 再来一次，看看源码的执行步骤。在开始之前，记得在编辑器打开 <code>redis-cli.c</code>，定位到 <code>main</code> 函数的位置，毕竟 gdb 看代码没有编辑器看着舒服。</p><p>debug 步骤如下：</p><pre><code># bashcd /opt/redis-3.2.13// 启动 Redis 服务。Ctrl+c 可推出服务器启动页，同时保持服务器运行./src/redis-server --port 8379 &amp;// 调试 redis-clligdb ./src/redis-cli# gdb (gdb) b main(gdb) r -p 8379(gdb) layout src(gdb) focus cmd</code></pre><p>执行完上述步骤，我们会进入如下界面：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190604195940724_8956.png" alt="图 1 - 进入 redis-cli main 函数"></p><p>这时候我们就可以回到编辑器页，看看对 <code>main</code> 函数中哪一行比较感兴趣，就停下来研究研究。到了 2618 行，我们会看到有执行 <code>parseOptions</code> 这个函数，看名字，好像是初始化一些可选项。那就进去看看呗。</p><h4 id="1-1-初始化客户端配置"><a href="#1-1-初始化客户端配置" class="headerlink" title="1.1 初始化客户端配置"></a>1.1 初始化客户端配置</h4><p>函数执行步骤：<code>main</code> -&gt; <code>parseOptions</code> -&gt; <code>main</code>。</p><p>我们会看到，在执行 <code>redis-cli</code> 时携带的参数都是在这个函数中解析，比如我们启动的时候带着的 <code>-p</code> 参数，会在 996 行被解析到，同时赋值给客户端的 hostport 配置项。如下图：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190604200701003_6835.png" alt="图 2 - 启动 redis-cli 携带的 -p 参数被赋值给 hostport 配置项"></p><h4 id="1-2-客户端启动模式"><a href="#1-2-客户端启动模式" class="headerlink" title="1.2 客户端启动模式"></a>1.2 客户端启动模式</h4><p>函数执行步骤：<code>main</code>。</p><p>回到 <code>main</code> 函数，会看到后面的代码会出现很多 <code>cliConnect</code> 函数。要注意的是，这里并不表示 redis-cli 会执行多次 <code>cliConnect</code> 函数。实际上，每一个 <code>if</code> 语句块，都代表着客户端的一种连接模式，3.2.13 版本支持以下模式：</p><ol><li>Latency mode：延迟模式。<code>redis-cli --latency -p 8379</code> 用来测试客户端与服务器连接的延迟。还有 <code>--history</code> 和 <code>--dist</code> 可选项，用来展示不同的形式。</li><li>Slave mode：模拟从节点模式。</li><li>Get RDB mode：生成并发送 RDB 持久化文件，保存在本地。</li><li>Pipe mode：管道模式。将命令封装成指定数据格式，批量发送给 redis 服务器执行。</li><li>Find big keys：统计 bigkey 的分布。</li><li>Stat mode：统计模式。实时展示服务器的统计信息。</li><li>Scan mode：扫描指定模式的键，相当于 scan 模式。</li><li>LRU test mode：实时测试 LRU 算法的命中情况。</li></ol><h4 id="1-3-连接服务器"><a href="#1-3-连接服务器" class="headerlink" title="1.3 连接服务器"></a>1.3 连接服务器</h4><p>函数执行步骤：<code>main</code> -&gt; <code>cliConnect</code> -&gt; <code>redisConnect</code> -&gt; <code>redisContextInit</code> -&gt; <code>redisContextConnectTcp</code> -&gt; <code>_redisContextConnectTcp</code> -&gt;  <code>cliConnect</code>。</p><p>我们上面没有使用特殊模式启动，因此，我们会看到在 2687 行真正的去调用 <code>cliConnect</code> 函数。跟踪进去，让我们看看究竟是如何和服务器进行连接的。</p><p>在  <code>cliConnect</code> 函数中，我们看到，根据 <code>hostsocket</code> 的配置项，会使用不同的连接模式。从名字上，我们大概可以猜出，一个是 TCP Socket 连接，另一个是本机 Unix Socket 连接。</p><p>如果想要使用 Unix Socket 连接，只需按格式配置 <code>hostscoket</code> 即可：<code>./src/redis-cli -s /tmp/redis.sock</code>。</p><p>我们这里使用 TCP Scoket 连接，使用 <code>redisConnect</code> 函数建立连接。</p><p>不断追踪，我们会看到上面所示的函数执行步骤，在 <code>_redisContextConnectTcp</code> 函数中会看到 <code>getaddrinfo</code> 和 <code>connect</code> 函数的调用，这里就是建立 TCP 连接的地方。</p><h4 id="1-4-校验权限及选择数据库"><a href="#1-4-校验权限及选择数据库" class="headerlink" title="1.4 校验权限及选择数据库"></a>1.4 校验权限及选择数据库</h4><p>函数执行步骤：<code>cliConnect</code> -&gt; <code>anetKeepAlive</code> -&gt; <code>cliAuth</code> -&gt; <code>cliSelect</code> -&gt; <code>main</code>。</p><p>回到  <code>cliConnect</code> 函数，如果正常连接上服务器后，还会将我们上面创建的 TCP 连接设置为长连接，然后校验权限，选择连接数据库。</p><pre><code>.../* Set aggressive KEEP_ALIVE socket option in the Redis context socket * in order to prevent timeouts caused by the execution of long * commands. At the same time this improves the detection of real * errors. */anetKeepAlive(NULL, context-&gt;fd, REDIS_CLI_KEEPALIVE_INTERVAL);/* Do AUTH and select the right DB. */if (cliAuth() != REDIS_OK)    return REDIS_ERR;if (cliSelect() != REDIS_OK)    return REDIS_ERR;...</code></pre><p>至此，我们已经跑完客户端与服务器建立连接的全过程。感兴趣的小伙伴可以尝试连接不存在的 IP 或 端口，观察程序抛出异常的时机，熟悉整个连接过程。</p><p>客户端与 服务器建立连接后，就可以使用相关命令操作数据库中的 key 了。下面我们以 <code>SET KEY VALUE</code> 命令为例，来看看命令的执行过程。</p><h3 id="2-发送命令请求"><a href="#2-发送命令请求" class="headerlink" title="2 发送命令请求"></a>2 发送命令请求</h3><p>当用户在客户端键入一个命令请求时，客户端会将这个命令请求按协议格式转换，然后通过连接到服务器的套接字，将转换后的命令请求发送给服务器，如图 3 所示：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190605200620062_13527.png" alt="图 3 - 客户端接收并发送命令请求的过程"></p><p>因此，对于我们上面的命令请求，客户端会转成：</p><pre><code>"*3\r\n$3\r\nSET\r\n$3\r\nKEY\r\n$5\r\nVALUE\r\n"</code></pre><p>然后发给服务器。</p><p>以上是客户端发送命令给服务器的过程，在下一节中，我们再来认识服务器是如何响应客户端请的。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 源码 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 服务器响应客户端请求 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟着大彬读源码 - Redis 1 - 启动服务，程序都干了什么？</title>
      <link href="/7/redis/yuanma/ck0669dro0036agaaqrw92ccz/"/>
      <url>/7/redis/yuanma/ck0669dro0036agaaqrw92ccz/</url>
      
        <content type="html"><![CDATA[<p>一直很羡慕那些能读 Redis 源码的童鞋，也一直想自己解读一遍，但迫于 C 大魔王的压力，解读日期遥遥无期。</p><p>相信很多小伙伴应该也都对或曾对源码感兴趣，但一来觉得自己不会 C 语言，二来也不知从何入手，结果就和博主一样，一拖再拖。</p><p>但正所谓，种一棵树的最好时间是十年前，其次就是<strong>现在</strong>。如果你真的想了解 Redis 源码，又有缘看到了这系列博文，何不跟着博主一起解读 Redis 源码，做个同行人呢？接下来，就让我们一起走入 Redis 的源码世界吧。</p><p>决定要读了，下一步就是如何读。从 github 上克隆下来源码，一看 src 目录，望天，104 个文件，我该从哪个文件开始呢？一个个文件看？不行不行，这样对我毫无诱惑力，没有诱惑力，怎么能战胜游戏、小说对我的吸引呢？苦苦思考，不得其解。然后突然想起来 HTTP 协议的那个经典面试题：从浏览器输入网址，到页面展示，这个过程发生了什么？</p><p>把这个面试题换成 Redis：输入开启 Redis 服务的命令，回车，到成功启动 Redis 服务，这个过程发生了什么？</p><p>很好，这个问题成功吸引到我了。就让我们从源码中找出这个问题的答案吧。后续的所有文章我们都尝试通过提出问题，解答问题的步骤，来深入了解 Redis。</p><p>要了解 Redis 命令的执行过程，首先要安装 Redis 服务，搭建 debug 环境。如果我们能一行行的看到命令在代码中的执行过程，解读源码也就没任何阻碍了。</p><p>后续所有文章均基于 redis3.2.13 版本。</p><h3 id="1-搭建-debug-环境"><a href="#1-搭建-debug-环境" class="headerlink" title="1 搭建 debug 环境"></a>1 搭建 debug 环境</h3><p><strong>1、下载编译文件</strong><br>在 linux 上，下载源码文件，编译，使用 gdb（cgdb） 进行 debug。</p><pre><code># bashwget https://github.com/antirez/redis/archive/3.2.13.tar.gztar -zxvf 3.2.13.tar.gzmv redis-3.2.13 /opt/cd redis-3.2.13make                 # 编译文件，得到可执行文件 redis-server、redis-cli 等</code></pre><p><strong>2、开启 debug</strong></p><pre><code># bashgdb src/redis-server # 在 redis 安装目录，进入 gdb 调试环境</code></pre><p>按我们平时调试的习惯，找到一个函数设置断点，然后一步步运行调试。对于 Redis 也一样，我们找到 server.c 文件，服务器运行的 main 函数就在此文件中。我们对 main 函数设置断点：</p><pre><code># gdb(gdb) b mainBreakpoint 1 at 0x42ed05: file server.c, line 3962.</code></pre><p>页面会提示我们在 server.c 文件的 3962 行设置了断点，也就是我们指定的 main 函数的位置。</p><p>设置好断点，下一步就是启动服务：</p><pre><code>// 启动服务(gdb) r ./redis.confStarting program: /opt/redis-3.2.13/src/redis-server ./redis.conf[Thread debugging using libthread_db enabled]Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".Breakpoint 1, main (argc=2, argv=0x7fffffffe5a8) at server.c:39623962    int main(int argc, char **argv) {</code></pre><p>通过页面输出信息，我们会发现程序已经运行到我们设置的断点了。但是我们看不到运行处的代码，这可不行，看不到源码的调试，没法接受使用以下命令”召唤“源码：</p><pre><code>(gdb) layout src</code></pre><p>出现下图所示的界面：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190530130922292_10690.png" alt="图 1 - gdb 的 src 和 cmd 并存"></p><p>到了这一步，我们已经正式开始踏上 Redis 源码解读之路了。</p><h3 id="2-初始化服务"><a href="#2-初始化服务" class="headerlink" title="2 初始化服务"></a>2 初始化服务</h3><p>继续往下走，使用  <code>n</code> 命令，执行下一步，然后不断回车、回车、回车，好像每一行都看不懂什么意思。不管了，继续走。咦，好像发现个能看懂的 <code>initServerConfig()</code>。没看错的话，这个应该是初始化服务器配置的，让我们进到这个函数里确认下：</p><pre><code>(gdb) s</code></pre><p>回车，走你。然后我们就看到了下面这个界面：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190530131828651_24415.png" alt="图 2 - 进入初始化服务器配置函数"></p><p>提示我们进入了 server.c 1464 行的 <code>initServerConfig</code> 函数中。 <code>n</code> 命令，继续走。我们会发现在这个函数里对服务器的各种基础参数进行初始化。这里的参数详见 server.h/redisServer 结构体。</p><p>回到 main 函数后，我们继续前进，还会发现一个 <code>initServer()</code> 的函数。这个函数是进行驱动事件的注册，以及绑定回调函数等。</p><p>继续走，直到执行 <code>aeMain()</code>，如下图：</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190530192740390_18685.png" alt="图 3 - Redis 服务已开启"></p><p>程序执行到 4133 行时，Redis 服务已成功开启了。此时服务器处于休眠状态，并使用 <code>aeMain()</code> 进行事件轮询，等待监听事件的发生。</p><p>上述整个过程，我们只是跟着程序的运行，大概看了一遍执行流程。下面，我们来详细解读上面叙述的关键步骤：<strong>初始化基础配置</strong>和<strong>初始化服务器数据结构</strong>。</p><h3 id="3-初始化详细解读"><a href="#3-初始化详细解读" class="headerlink" title="3 初始化详细解读"></a>3 初始化详细解读</h3><h4 id="3-1-初始化基础配置"><a href="#3-1-初始化基础配置" class="headerlink" title="3.1 初始化基础配置"></a>3.1 初始化基础配置</h4><p>初始化服务器的第一步就是创建一个 ````redisServer``` 类型的实例变量 server 作为服务器的状态，并为结构中的各个属性设置默认值。</p><pre><code>void initServerConfig(void) {    int j;    // 设置服务器运行 ID    getRandomHexChars(server.runid,CONFIG_RUN_ID_SIZE);    // 为运行 ID 加上结尾字符    server.runid[CONFIG_RUN_ID_SIZE] = '\0';    // 设置服务器默认运行架构    server.arch_bits = (sizeof(long) == 8) ? 64 : 32;    // 设置服务器默认配置文件路径    server.configfile = NULL;    // 设置服务器默认运行频率    server.hz = CONFIG_DEFAULT_HZ;    // 设置服务器默认端口    server.port = CONFIG_DEFAULT_SERVER_PORT;    // ...}</code></pre><p>对于 <code>initServerConfig</code> 函数来说，它主要完成以下主要工作：</p><ul><li>设置服务器的运行 ID。</li><li>设置服务器的默认运行频率。</li><li>设置服务器的默认配置文件路径。</li><li>设置服务器的运行架构。</li><li>设置服务器的默认端口号</li></ul><p>initServerConfig 函数设置的服务器状态属性基本上都是一些整数、浮点数或者字符串属性。除了命令吧之外，initServerConfig 函数没有创建服务器状态的其它数据结构。像数据库、慢查询日志、Lua 环境、共享对象等这些数据结构是在之后的步骤中创建的。</p><p>当初始化基础配置参数后，下一步就要开始<strong>载入配置选项</strong>。</p><h4 id="3-2-载入配置选项"><a href="#3-2-载入配置选项" class="headerlink" title="3.2 载入配置选项"></a>3.2 载入配置选项</h4><p>在启动服务器时，用户可以通过给定配置参数或者知道配置文件来修改服务器的默认配置。就像我们可以在启动服务时指定端口：</p><pre><code># bash./src/redis-server --port 7379</code></pre><p>通过给定配置参数的方式，修改了服务器的运行端口号。</p><p>除了给定配置参数的方式，我们可以通过指定配置文件的形式启动服务：</p><pre><code># bash./src/redis-server ./redis.conf</code></pre><p>通过指定配置文件的形式启动服务时，我们实际上就是通过配置文件的形式修改了服务器的数据库配置。</p><p>服务器在用 <code>initServerConfig</code> 函数初始完 <code>server</code> 变量后，就会开始载入用户给定的配置参数和配置文件，并根据用户设定的配置，对 <code>server</code> 变量相关属性进行修改。</p><p>关于命令行指定配置、配置文件配置、默认配置，这三种配置中：</p><ul><li>如果有指定配置，服务器就是有用户指定的值来更新对应的属性。</li><li>如果没有指定值，则沿用 <code>initServerConfig</code> 函数设置的默认值。</li></ul><h4 id="3-3-初始化服务器数据结构"><a href="#3-3-初始化服务器数据结构" class="headerlink" title="3.3 初始化服务器数据结构"></a>3.3 初始化服务器数据结构</h4><p>在执行 <code>initServerConfig</code> 函数初始化配置时，程序只创建了命令表一个数据结构，而服务器除了命令表还包括其他数据结构，比如：</p><ul><li><strong>server.clients 链表</strong>。这个链表记录了所有与服务器相连的客户端的状态结构。链表的每个节点都包含了一个 <code>RedisClient</code> 结构实例。</li><li><strong>server.db 数组</strong>。数组中包含了服务器所有的数据库。</li><li><strong>server.pubsub_channels 字典</strong>。字典中保存频道订阅信息。</li><li><strong>server.pubsub_patterna 链表</strong>。链表中保存模式订阅信息。</li><li><strong>server.lua 属性</strong>。用来执行 Lua 脚本。</li><li><strong>server.slowlog 属性</strong>。用来保存慢日志。</li></ul><p>上述这些数据结构会在 <code>initServer</code> 函数为其分配内存，并在有需要时为这些数据结构设置或关联初始化值。</p><p>之所以在载入用户配置之后才初始化数据结构，就是因为服务器要先载入用户的配置选项，才能根据选项正确的对数据结构进行初始化。避免再根据用户配置修改数据结构相关属性。</p><p>所以，我们可以看出，服务器对状态的初始化分为两步进行：</p><ol><li><code>initServerConfig</code> 函数是初始化一般属性。</li><li><code>initServer</code> 初始化数据结构。</li></ol><p>除了初始化数据结构之外，<code>initServer</code> 还进行了一些非常重要的设置操作，包括：</p><ul><li>为服务器设置进程信号处理器。</li><li>创建共享对象。这些对象包含 Redis 服务器常用到的一些只，比如包含 “OK” 回复的字符串对象，包含 “ERR” 回复的字符串对象，包含整数 1 到 10000 的字符串对象等等。服务器正是通过重用这些共享对象来避免反复创建相同的对象，节约内存。</li><li>打开服务器的监听端口，并为监听套接字关联应答事件处理器，等待服务器正式运行时接受客户端的连接。</li><li>为服务器创建时间事件，等待服务器正是运行时执行 serverCron 函数。</li><li>如果开启了 AOF 持久化功能，打开现有的 AOF 文件。如果 AOF 文件不存在，就创建并打开新的 AOF 文件，为 AOF 写入做好准备。</li><li>初始化服务器的后台 IO 模块，为 IO 操作做好准备。</li></ul><p>当 <code>initServer</code> 函数执行完毕之后，服务器将用 ASCII 字符在日志中打印出我们常见到的 Redis 图标，以及 Redis 的版本号信息等。</p><p><img src="https://raw.githubusercontent.com/zibinli/blog/master/Redis/_v_images/20190531131316405_24966.png" alt="图 4 - 服务器启动后打印的 Redis 图标和版本信息等"></p><h3 id="4-其它操作"><a href="#4-其它操作" class="headerlink" title="4 其它操作"></a>4 其它操作</h3><h4 id="4-1-还原数据库"><a href="#4-1-还原数据库" class="headerlink" title="4.1 还原数据库"></a>4.1 还原数据库</h4><p>在完成了对服务器状态 <code>server</code> 变量的初始化之后，服务器需要载入 RDB 文件或者 AOF 文件（数据持久化保存文件），并根据文件记录的内容来还原服务器的数据库状态。</p><p>还原过程中，服务器会判断是否启用了 AOF 持久化功能：</p><ul><li>如果启用了 AOF 持久化功能，服务器将使用 AOF 文件来还原数据库状态。</li><li>如果没有启用 AOF，服务器使用 RDB 文件来还原数据库状态。</li></ul><p>当服务器完成数据库状态还原工作之后，会在日志中打印出载入文件和还原数据库状态所耗费的时长。</p><blockquote><p>8189:M 31 May 13:12:47.971 * DB loaded from disk: 0.000 seconds</p></blockquote><h4 id="4-2-执行事件循环"><a href="#4-2-执行事件循环" class="headerlink" title="4.2 执行事件循环"></a>4.2 执行事件循环</h4><p>在初始化的最后一步，服务器将打印出以下日志：</p><blockquote><p>8189:M 31 May 13:12:47.971 * The server is now ready to accept connections on port 8379</p></blockquote><p>并开始执行服务器的事件循环。</p><p>至此，服务器的初始化工作全部完成。</p><h3 id="5-gdb-基础使用"><a href="#5-gdb-基础使用" class="headerlink" title="5 gdb 基础使用"></a>5 gdb 基础使用</h3><table><thead><tr><th>命令</th><th>解释</th><th>示例</th></tr></thead><tbody><tr><td>gdb file</td><td>加载被调试的可执行程序文件</td><td>gdb src/redis-server</td></tr><tr><td>r</td><td>Run 的缩写，运行被调试的程序。</td><td>r ./redis.conf</td></tr><tr><td>c</td><td>Continue 的缩写。继续执行被调试程序，直至下一个断点或程序结束</td><td>c</td></tr><tr><td>b</td><td>Breakpoint 缩写。设置断点。可以使用 行号、函数名称、执行地址等方式指定断点位置</td><td>b main</td></tr><tr><td>s/n</td><td>s 相当于“单步跟踪并进入”，也就是说进入到执行的函数内部。n 相当于“单步跟踪”，不进入到执行函数内部</td><td>s/n</td></tr><tr><td>p 变量名称</td><td>Print 缩写。显示指定变量的值。</td><td>p server</td></tr></tbody></table><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>搭建环境三步走：下载、编译、gdb。</li><li>服务启动包括：初始化基础配置、数据结构、对外提供服务的准备工作、还原数据库、执行事件循环等。</li><li>gdb 基础命令：r c b n p。</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 源码 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 服务器启动过程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL - 高可用性：少宕机即高可用？</title>
      <link href="/4/mysql/keyongxing/ck0669dko0017agaafginehh9/"/>
      <url>/4/mysql/keyongxing/ck0669dko0017agaafginehh9/</url>
      
        <content type="html"><![CDATA[<p>我们之前了解了复制、扩展性，接下来就让我们来了解可用性。归根到底，高可用性就意味着 “更少的宕机时间”。</p><p>老规矩，讨论一个名词，首先要给它下个定义，那么什么是可用性？</p><h3 id="1-什么是可用性"><a href="#1-什么是可用性" class="headerlink" title="1 什么是可用性"></a>1 什么是可用性</h3><p>我们常见的可用性通常以百分比表示，这本身就有其隐藏的意味：<strong>高可用性不是绝对的</strong>。换句话说，100% 的可用性是不可能达到的。没错，这里可以这么肯定的说。</p><p>我们一般用 “9” 的个数来描述可用性。X个9表示在数据中心运行1年时间的使用过程中，各系统可以正常使用时间与总时间（1年）之比。例如：“5 个 9” 表示 99.999%，那么应用宕机时间 t：</p><blockquote><p>(1-99.999%) * 3600 * 24 * 365 = 315.36s = 5.256m</p></blockquote><p>因此，我们可以说，“5 个 9” 表示应用每年只允许 5.256 分钟的宕机时间。同样的计算，我们可以得出 3 个 9 每年宕机时间为 8.76 小时，4 个 9 的是 52.6 分钟。</p><p>实际上，5 个 9 对于大多数应用来说已经是很难做到的，但是对于一些大型公司，肯定还会去尝试获得更多的 “9”，已尽量减少应用的宕机时间，降低宕机成本。</p><p>每个应用对可用性的需求各不相同。在设定一个目标值之前，一定要考虑清楚是不是确实需要达到这个目标。可用性的效果和开销对应的比例并不是线性增长的，每提高一点可用性，所花费的成本都会远超之前。</p><p>因此，对于可用性，我们可以遵循这样一个原则：</p><blockquote><p><strong>能够承担多少宕机成本，就保证相应的可用时间</strong>。</p></blockquote><p>说起来可能有点绕，简单来说：对于有 10W 用户的应用，<br>假设实现 5 个 9 需要 100W，每年应用即使宕机 9 小时，总损失也才 50W，你说这个应用有必要去实现 5 个 9 的可用性吗？</p><p>另外，我们上面给可用性定义成了 “宕机时间”，但实际上可用性还应该<strong>包括应用是否能以足够好的性能处理请求</strong>。对于一个大型服务器而言，重启 MySQL 后，可能需要几个小时才能预热数据以保证请求的响应时间。这里的几个小时也应该包括在宕机时间内。</p><p>到此为止，我们应该有个大致的印象，可用性与应用宕机有关系。接下来，让我们再深入一步，了解下应用宕机的原因。</p><h3 id="2-导致宕机的原因"><a href="#2-导致宕机的原因" class="headerlink" title="2 导致宕机的原因"></a>2 导致宕机的原因</h3><p>我们最常听到的数据库宕机原因可能是** SQL 性能很差**。但实际上并非如此，按表现方式导致宕机的原因分为以下几类：</p><table><thead><tr><th>宕机事件表现形式</th><th>占比</th><th>导致宕机的原因</th></tr></thead><tbody><tr><td>运行环境</td><td>35%</td><td>磁盘空间耗尽</td></tr><tr><td>性能问题</td><td>35%</td><td>1. 低性能 SQL；2. 服务器 BUG；3. 糟糕的表结构设计和索引设计</td></tr><tr><td>复制</td><td>20%</td><td>主备数据不一致</td></tr><tr><td>数据丢失或损坏</td><td>10%</td><td>误操作删除数据，缺少备份</td></tr></tbody></table><p>运行环境通常可以看作是支持数据库服务器运行的系统资源集合，包括操作系统、硬盘以及网络等。</p><p>另外，我们虽然经常用复制来提高可用时间，但它也是导致宕机的重要 “元凶” 之一。这也说明了一个普遍的情况：</p><blockquote><p>许多高可用策略可能会产生反作用</p></blockquote><p>了解了可用性的定义及其降低可用性的因素，我们就要来考虑如何提高系统的可用性了。</p><h3 id="3-如何实现高可用性"><a href="#3-如何实现高可用性" class="headerlink" title="3 如何实现高可用性"></a>3 如何实现高可用性</h3><p>通过上面的分析，也许你已经发现了，我们可用性取决于两个时间：</p><ul><li><strong>应用的平均失效时间</strong></li><li><strong>应用的平均恢复时间</strong></li></ul><p>因此，提高可用性也可以从这两个方面入手。首先，可以尽量避免应用宕机来减少宕机时间。实际上，通过适当的配置、监控，以及规范或安全保障措施，很多导致宕机的问题很容易可以避免。</p><p>其次，尽量保证在发生宕机时，能够快速恢复。最常见的策略是在系统中制造冗余，并且保证系统的故障转移能力。</p><p>接下来，让我们一起来了解具体针对性措施。</p><h4 id="3-1-降低平均失效时间"><a href="#3-1-降低平均失效时间" class="headerlink" title="3.1 降低平均失效时间"></a>3.1 降低平均失效时间</h4><p><strong>我们对系统变更缺少管理</strong>是所有导致宕机事件中最普遍的原因。典型的错误包括粗心的升级导致升级失败并碰到一些 bug，或是尚未测试就将数据表结构或查询语句的更改直接在线上运行，或者是没有为一些失败的情况制定对应计划，例如达到了磁盘容量限制等。</p><p>另外一个导致宕机的主要原因是缺少严格的评估。例如因为疏忽没有确认备份是否是可恢复的。</p><p>还有就是可能没有准确的监控 MySQL 的相关信息。例如缓存命中率报警可能只是误报，并不能说明出现问题，致使我们认为监控系统没有用，就忽略了真正出现问题的报警。导致 boss 问你，为什么磁盘满了没有收到报警信息时，你一脸无辜的看着他。</p><p>因此，只要我们多做些针对性的工作，就可以避免很多宕机时间。具体可以从以下措施着手：</p><ul><li>测试恢复工具和流程，包括从备份中恢复数据。</li><li>遵从最小权限原则。</li><li>保持系统干净、整洁。</li><li>使用好的命名和组织约定来避免产生混乱。例如服务器是用于开发还是生产环境。</li><li>谨慎安排升级数据库服务器。</li><li>在升级前，使用诸如 Percona Toolkit 中的 pt-upgrade 之类的工具仔细检查系统。</li><li>使用 InnoDB 并进行适当的配置，确保 InnoDB 是默认存储引擎。如果存储引擎被禁止，服务器就无法启动。</li><li>确认基本的服务器配置是正确的。</li><li>通过 skip_name_resolve 禁止 DNS。</li><li>在未明确查询缓存有用的情况下，应该禁用查询缓存。</li><li>尽量避免使用复杂的特性，除非确实需要。例如复制过滤、触发器等。</li><li>监控重要的组件和功能。<strong>特别是像磁盘空间和 RAID 卷状态这样的关键项目</strong>。</li><li>尽可能久的记录服务器的状态和性能指标。</li><li>定期检查复制完整性。</li><li>将被刻意设置为只读，不要让复制自动启动。</li><li>定期进行查询语句审查。</li><li>归档并清理不需要的数据。</li><li>为文件系统保留部分空闲空间；</li><li>养成评估和管理系统的改变、状态和性能信息的习惯。</li></ul><h4 id="3-2-降低平均恢复时间"><a href="#3-2-降低平均恢复时间" class="headerlink" title="3.2 降低平均恢复时间"></a>3.2 降低平均恢复时间</h4><p>对于恢复时间，我们可以从三方面入手：</p><ul><li>为系统建立冗余，保证系统的故障转移能力，避免单点失效。</li><li>为人员制定一个完善的恢复流程规范。</li><li>为人员组织事后复盘，避免未来发生相似的错误。</li></ul><p>接下来，我们来讨论下具体措施。</p><p><strong>1) 如何避免单点失效？</strong></p><p>对于单点失效，我们首先要做的是找到它，然后针对性解决它。</p><p>一个系统中，每个单点都有可能失效。可能是一个硬盘驱动器、一台服务器或者是一台交换机、路由器，甚至某个机架的电源等等单点。</p><p>在进行相关措施前，我们要明白，单点失效并不能完全消除。我们可能引入新的的技术来解决单点失效问题，但引入的新技术可能导致更多的宕机时间。因此，我们应该按影响级别对失效单点进行排序，按照排序针对性解决单点失效问题。</p><p>具体到增加冗余的相关措施，有两种方案：<strong>增加空余容量</strong>和<strong>重复组件</strong>。</p><p>增加空余容量比较简单。可以创建一个集群或服务器池，使用负载均衡方案。这样在一台服务器失效时，其它服务器可以接管失效服务器的负载。</p><p>另外，处于很多方面的考虑可能会需要冗余组件，可以主要组件失效时，能有一个备件来随时替换。可冗余的组件可以是空闲的网卡、路由器或者硬盘驱动器等。</p><p>此外，最重要的是，要完全冗余 MySQL 服务器。这意味着我们必须确保备用服务器能够获得主服务器上的数据。可以从以下措施着手：</p><ul><li>共享存储或磁盘复制</li><li>MySQL 同步复制</li></ul><p><strong>2) 如何保证系统的故障转移和恢复能力？</strong></p><p>在开始这个话题之前，我们先来认识下什么是 “故障转移”。有些人用 “回退” 表示，也有人会使用 “切换”，以表明一次计划中的切换而不是故障后的应对措施。</p><p>我们在这里使用 “故障恢复” 来表示故障转移的反面。如果系统拥有故障恢复能力，那么，故障转移就是一个双向过程：</p><blockquote><p>当服务器 A 失效，服务器 B 代替它，在修复 A 服务器后可以再替换回来。</p></blockquote><p>故障转移最重要的部分就是故障恢复。如果服务器间不能自由切换，故障转移就是一个死胡同，只能延缓宕机时间而已。因此，使用复制时，可以使用对称复制布局，如双主结构。因为配置是对等的，故障转移和故障恢复就是在相反方向上的相同操作。</p><p>接下来我们就认识一些比较普遍的故障转移技术。</p><p><strong>提升备库或切换角色</strong></p><p>提升一台备库为主库，或者在一个 主-主复制结构中调换主动和被动角色，这些都是许多 MySQL 故障转移策略中很重要的一部分。详情参见<a href="https://www.cnblogs.com/BeiGuo-FengGuang/p/10706782.html" target="_blank" rel="noopener">MySQL 复制 - 性能与扩展性的基石 4：主备库切换</a></p><p><strong>虚拟 IP 地址或 IP 接管</strong></p><p>可以为需要提供特点服务的 MySQL 实例指定一个逻辑 IP 地址。当 MySQL 实例失效时，将 IP 地址转移到另一台 MySQL 服务器上。这里的解决方案本质上负载均衡里的虚拟 IP 技术是一样的，不同的是现在是用于故障转移。</p><p>这种方法的好处是对应用透明。它会中断已有的连接，但不用修改配置。</p><p>当然，它也有一些不足之处：</p><ul><li>需要把所有的 IP 地址定义在同一网段，或者使用网络桥接。</li><li>有时候还需要更新 ARP 缓存。部分网络设备可能会把 ARP 信息保存太久，导致无法即时将一个 IP 地址切换到另一个 MAC 地址上。</li><li>需要确定网络硬件是否支持快速 IP 接管。有些硬件需要克隆 MAC 地址后才能工作。</li></ul><p><strong>3) 团队人员如何提高系统恢复时间？</strong></p><p>由于团队内每个人对于宕机恢复的熟练度和对应能力各有不同，因此我们还需要一个对应人员的流程规范，来帮助大家都能在宕机时参与进来，降低系统的恢复时间。</p><p>系统恢复后，我们就要组织大家对对宕机时间进行评估，这里要注意的是，不要对此类的 “事后反思” 期望太高。导致宕机的原因通常是多方面的的，我们很难去回顾问题当时所处的状况，也很难找到真正的原因。因此，我们在事后反思得到的结论应该有所保留。</p><h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4 总结"></a>4 总结</h3><ol><li>可用性用宕机时间 n 个 9 来衡量。</li><li>实现可用性从<strong>平均失效时间</strong>和<strong>平均恢复时间入手</strong>。</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
          <category> 可用性 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高可用性 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL - 扩展性 3 负载均衡：眼花缭乱迷人眼</title>
      <link href="/4/mysql/kuozhanxing/ck0669dm7001jagaalk5kpbs3/"/>
      <url>/4/mysql/kuozhanxing/ck0669dm7001jagaalk5kpbs3/</url>
      
        <content type="html"><![CDATA[<p>负载均衡的基本思路很简单：</p><blockquote><p>在一个服务器集群中尽可能地的平均负载量。</p></blockquote><p>基于这个思路，我们通常的做法是在服务器前端设置一个<strong>负载均衡器</strong>。负载均衡器的作用是将请求的连接路由到最空闲的可用服务器上。如图 1，显示了一个大型网站负载均衡设置。其中一个负责 HTTP 流量，另一个用于 MySQL 访问。<br><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190411195348068-186371226.png" alt="图 1 典型的读密集型网站负载均衡架构"></p><p>负载均衡有五个常见目的：</p><ol><li><strong>可扩展性</strong>。负载均衡对某些扩展很有帮助，比如读写分离时从备库读数据。</li><li><strong>高效性</strong>。负载均衡因为能够控制请求被路由到何处，因此有助于更有效的使用资源。</li><li><strong>可用性</strong>。灵活的负载均衡方案能够大幅提高服务的可用性。</li><li><strong>透明性</strong>。客户端无需知道是否存在负载均衡器，也不需要关系在负载均衡器的背后有多少机器。呈现给客户端看到的就是一个透明的服务器。</li><li><strong>一致性</strong>。如果应用是有状态的（数据库事务、网站会话等），那么负载均衡器就可以将相关的查询指向同一个服务器，以防止状态丢失。</li></ol><p>而对于负载均衡的实现，一般有两种方式：<strong>直接连接</strong>和<strong>引入中间件</strong>。</p><h3 id="1-直接连接"><a href="#1-直接连接" class="headerlink" title="1 直接连接"></a>1 直接连接</h3><p>有些人认为负载均衡就是配置在应用和 MySQL 服务器直接东西，但实际上这并不是唯一的负载均衡方法。接下来我们就讨论一下常见的应用直连的方法，及其相关注意事项。</p><h4 id="1-1-复制的读写分离"><a href="#1-1-复制的读写分离" class="headerlink" title="1.1 复制的读写分离"></a>1.1 复制的读写分离</h4><p>此种方式下，容易出现一个最大的问题：<strong>脏数据</strong>。一个典型的例子是，当用户评论了一篇博文，然后重新加载页面，却没有看到新增的评论。</p><p>当然，我们也不能因为脏数据的问题，就将读写分离弃之不用。实际上，对于很多应用，可能对脏数据的容忍度比较高，此时就可以大胆的引入此种方式。</p><p>那么对于脏数据的容忍度比较低的应用，如何进行读写分离呢？接下来，我们对读写分离再进一步区分，相信你总能找到适合自己的一款策略。</p><p><strong>1) 基于查询分离</strong></p><p>如果应用只有少数数据不能容忍脏数据，我们可以将所有不能容忍脏数据的读和写都分配到 master 上。其它的读查询分配的 slave 上。该策略很容易实现，但如果容忍脏数据的查询比较少，很可能会出现不能有效使用备库的情况。</p><p><strong>2) 基于脏数据分离</strong></p><p>这是对基于查询分离策略的小改进。需要做一些额外的工作，比如让应用检查复制延迟，以确定备库数据是否最新。许多报表类应用都可以使用这个策略：只需要晚上加载的数据复制到备库接口，并不关心是不是完全跟上了主库。</p><p><strong>3) 基于会话分离</strong></p><p>这个策略比脏数据分离策略更深入 一些。它是判断用户是否修改了数据，用户不需要看到其他用户的最新数据，只需要看到自己的更新。</p><p>具体可以在会话层设置一个标记位，表明用户是否做了更新，用户一旦做了更新，就将该用户的查询在一段时间内指向主库。</p><p>这种策略在简单和有效性之间做了很好的妥协，是一种较为推荐的策略。</p><p>当然，如果你的想法够多，可以把基于会话的分离策略和复制延迟监控策略结合起来。如果用户在 10 秒前更新了数据，而所有备库延迟在 5 秒内，就可以大胆的从备库中读取数据。要注意的是，记得为整个会话选择同个备库，否则一旦多个备库的延迟不一致，就会给用户造成困扰。</p><p><strong>4) 基于全局版本 / 会话分离</strong></p><p>通过记录主库日志坐标和备库已复制的坐标对比，确认备库是否更新数据。当应用指向写操作时，在提交事务后，执行一次 SHOW MASTER STATUS 操作，然后将主库日志坐标存储在缓存中，作为被修改对象或者会话的版本号。当应用连接到备库时，执行 SHOW SLAVE STATUS，并将备库上的坐标和缓存中的版本号对比。如果备库比主库记录点更新，就表明备库已更新对应数据，可放心的使用。</p><p>实际上，很多读写分离策略都需要<strong>监控复制延迟</strong>来决定读查询的分配。不过要注意的是，SHOW SLAVE STATUS 得到的 Seconds_behind_master 列的值并不能精确的表示延迟。我们可以使用 Percona Toolkit 中的 pt-heartbeat 工具更好的监控延迟。</p><h4 id="1-2-修改-DNS-名"><a href="#1-2-修改-DNS-名" class="headerlink" title="1.2 修改 DNS 名"></a>1.2 修改 DNS 名</h4><p>对于一些比较简单的应用，可以为不同目的创建 DNS。最简单的方法是只读服务器拥有一个 DNS 名(read.mysql-db.com),给负责写操作的服务器起另外一个 DNS 名(write.mysql-db.com)。如果备库能够跟得上主库，就把只读 DNS 名指向到备库，否则，就指向到主库。</p><p>这种策略非常容易实现，但有个很大的问题是：无法完全控制 DNS。</p><ul><li>修改 DNS 并不是立刻生效的，也不是原子性的。将 DNS 的变化传递到整个网络或者网络间传播都需要比较长的时间。</li><li>DNS 数据会在各个地方缓存下，它的过期时间是建议性质，而非强制的。</li><li>可能需要应用或服务器重启才能使修改后的 DNS 完全生效。</li></ul><p>这种策略较为危险，即使可以通过修改 /etc/hosts 文件来避免 DNS 无法完全控制的问题，但仍不失理想策略。</p><h4 id="1-3-转移-IP-地址"><a href="#1-3-转移-IP-地址" class="headerlink" title="1.3 转移 IP 地址"></a>1.3 转移 IP 地址</h4><p>通过在服务器间转移虚拟地址，来实现负载均衡。是不是感觉和修改 DNS 很像？但实际上完全是两码事。转移 IP 地址允许 DNS 名保持不变，我们可以通过 ARP 命令(不了解 ARP，<a href="https://www.cnblogs.com/BeiGuo-FengGuang/p/9923983.html" target="_blank" rel="noopener">看这里</a>)强制使 IP 地址的更改快速而且原子性的通知到局域网络上。</p><p>一个比较方便的技术是为每个物理服务器分配一个固定的 IP 地址。该 IP 地址固定在服务器上，不再改变。然后可以为每个逻辑上的 “服务”(可以理解为容器)使用一个虚拟 IP 地址。</p><p>这样，IP 就能够很方便的在服务器间转移，无需重新配置应用，实现也更加容易。</p><h3 id="2-引入中间件"><a href="#2-引入中间件" class="headerlink" title="2 引入中间件"></a>2 引入中间件</h3><p>上面的策略都是假定应用是和 MySQL 服务器之间连接的，但是许多负载均衡都会引入一个中间件，作为网络通信的代理。它一边接受所有的通信，另一边将这些请求分发的指定服务器上，并将执行结果发送回请求机器。图 2 展示了此种架构。<br><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190411195413684-1377640058.png" alt="图 1：作为中间件的负载均衡器"></p><h4 id="2-1-负载均衡器"><a href="#2-1-负载均衡器" class="headerlink" title="2.1 负载均衡器"></a>2.1 负载均衡器</h4><p>现在有许多负载均衡硬件和软件，但很少有专门为 MySQL 服务器设计的。Web 服务器通常更需要负载均衡，因此许多多用途的负载均衡设备都会支持 HTTP，而对其他用途则只有一些很少的基本特性。</p><p>MySQL 连接只是正常的 TCP/IP 连接，所以可以在 MySQL 上使用多用途负载均衡器。但由于缺少 MySQL 专有的特性，因此会多一些限制：</p><ul><li>分发请求是可能无法做到很好的负载均衡。</li><li>对 MySQL 会话支持不足，可能不知道如何把所有从单个 HTTP 会话发送的连接请求 “固定” 到一个 MySQL 服务器上。</li><li>连接池和长连接可能会阻碍负载均衡器分发连接请求。</li><li>不能很好的对 MySQL 服务器做健康和负载检查。</li></ul><h4 id="2-2-负载均衡算法"><a href="#2-2-负载均衡算法" class="headerlink" title="2.2 负载均衡算法"></a>2.2 负载均衡算法</h4><p>有很多算法用来决定哪个服务器接受下一个连接。每个厂商都有各自不同的算法，有以下常用方法：</p><ol><li><strong>随机分配</strong>。从可用的服务器池中随机选择一个服务器来处理请求。</li><li><strong>轮询</strong>。以循环顺序发送请求到服务器，例如：A、B、C、A、B、C。</li><li><strong>哈希</strong>。通过连接的源 IP 地址进行哈希，将其映射到池中的同一个服务器上。</li><li><strong>最快响应</strong>。将连接分配给能够最快处理请求的服务器上。</li><li><strong>最少连接数</strong>。将连接分配给拥有最少活跃连接的服务器上。</li><li><strong>权重</strong>。根据机器的性能等条件，给不同机器配置不同的权重，以便让高性能的机器能处理更多的连接。</li></ol><p>上述各种方法没有最好，只有最适合的，这取决于具体的工作负载。</p><p>另外，我们只描述了即时处理的算法。但有时候使用排队算法可能会更有效。例如，一个算法可能只维护给定的数据库服务器并发数量，同一时刻只允许不超过 N 个活跃事务。如果有太多的活跃事务，就将新的请求放到一个队列里，然后让可用服务器列表来处理。</p><h4 id="2-3-一主多备间的负载均衡"><a href="#2-3-一主多备间的负载均衡" class="headerlink" title="2.3 一主多备间的负载均衡"></a>2.3 一主多备间的负载均衡</h4><p>最常见的复制结构就是<strong>一个主库加多个备库</strong>。这种架构的扩展性较差，但我们可以通过一些方法结合负载均衡来获得更好的效果。</p><ul><li><strong>功能分区</strong>。对于厂家的功能包括报表、分析、数据仓库以及全文索引，配置一个或一组备库来扩展单个功能的容量。</li><li><strong>保证备库跟上主库</strong>。备库存在的问题就是脏数据。对于此，我们可以使用函数 MASTER_POS_WAIT() 阻塞主库的操作，直到备库赶上了设置的主库同步点。另外，我们还可以使用复制心跳来检查延迟情况。</li></ul><p>我们不能也不应该在应用的开始就就想着把架构做成阿里那样的架构。最好的方式是<strong>实现应用当前所明确需要的，并为可能的快速增长做好预先规划</strong>。</p><p>另外，为可扩展性制定一个<strong>数字目标</strong>是很有意义的，就像我们为性能制定了一个精确目标，满足 10K 或 100K 并发一样。这样可以通过相关理论避免诸如序列化或交互操作的开销问题带入到我们的应用中。</p><p>在 MySQL 扩展策略方面，典型的的应用在增长到非常庞大时，通常先从单个服务器转移到向外扩展的拥有备库的架构，再到数据分片或按功能分区。这里要注意的是，我们不提倡诸如 “尽早分片，尽量分片” 的建议。实际上，分片很复杂，而且成本很高，最主要的是很多应用可能根本不需要。与其花大成本去分片，还不如先去看看新的硬件和新版本的 MySQL 有哪些变化，也许这些新变化会给你带来惊喜。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>直接连接重 “分离”，均衡器和算法有局限。</li><li>为扩展性量化指标。</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
          <category> 扩展性 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 负载均衡 </tag>
            
            <tag> 扩展方式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL - 扩展性 2 扩展策略：氪金氪脑任君选</title>
      <link href="/4/mysql/kuozhanxing/ck0669dan0001agaa2ykpz6hd/"/>
      <url>/4/mysql/kuozhanxing/ck0669dan0001agaa2ykpz6hd/</url>
      
        <content type="html"><![CDATA[<p>如果将应用的所有数据简单地放在一台 MySQL 服务器实例上，就不用谈什么扩展性了。但是业务能稳定持续的增长，那么应用肯定会碰到性能瓶颈。</p><p>对于很多类型的应用而言，购买更高性能的机器能解决一大部分性能问题，这也是我们常说的 “垂直扩展” 或者 “向上扩展”。</p><p>另一个与之相反的方法是将任务分配的多台机器上，这通常被称为 “水平扩展” 或者 “向外扩展”。</p><p>接下来，我们将讨论如何联合使用向上扩展和向外扩展，以及如何使用集群方案来进行扩展。</p><p>最后，大部分应用还会有一些很少或者从不需要的数据，这些数据可以被清理或归档，我们可以称这种方案为 “向内扩展”。</p><h3 id="1-向上扩展"><a href="#1-向上扩展" class="headerlink" title="1 向上扩展"></a>1 向上扩展</h3><p>向上扩展（也叫垂直扩展）意味着购买更多性能强悍的机器。这种策略有较多优点：</p><ul><li>更容易维护和开发，显著节约开销；</li><li>单台服务器备份和恢复较为简单，无需关心一致性；</li></ul><p>因此，从复杂性的成本来说，大多时候，向上扩展比向外扩展更简单。</p><p>另外，不要觉得向上扩展很快就走到“尽头”，要相信科技的进步速度。现在，拥有 0.5TB 内存、32 核（或者更多）CPU 以及更强悍 I/O 性能的商用服务器很容易获得。优秀的应用和数据库设计，再加上很好的性能优化技能，已经可以满足绝大多数商业应用。</p><p>不过遗憾的，虽然高性能服务器比较容易获得，但是 MySQL 并不能扩展到对应的规模。为了更好地在大型服务器上运行 MySQL，一定要尽量选择最新的版本。即使如此，当前合理的 “收益递减点” 的机器配置大约是：</p><ul><li>256G RAM</li><li>32 核 CPU</li><li>PCIe flash 驱动器</li></ul><p>如果继续提升硬件配置，MySQL 性能虽然还能有所提升，但性价比就会降低。</p><p>因此，我们建议，如果系统确实有可能碰到可规划性的天花板，并且会导致严重的业务问题，那就不要无限制的做向上扩展的规划。对于庞大的应用，可以短期内购买更优的服务器，但最终还是需要向外扩展的。</p><h3 id="2-向外扩展"><a href="#2-向外扩展" class="headerlink" title="2 向外扩展"></a>2 向外扩展</h3><p>向外扩展（也叫横向扩展或水平扩展）策略通常分为三个部分：复制、拆分和数据分片。</p><p>最常见的向外扩展就是<strong>读写分离</strong>。通过复制将数据分发到多个服务器上，然后将备库用于读查询。这种技术对于以读为主的应用很有效。</p><p>另一个比较常见的向外扩展方法是<strong>将工作负载分布到多个 “节点”</strong>。接下来我们要了解的主要是这种扩展方法。</p><p>在此之前，我们先明确下节点的概念。在 MySQL 架构中，一个节点就是一个功能部件。一般的，我们会将一台服务器作为一个几点。但如果我们考虑到节点的高可用性，那么一个节点通常可能是下面的几种：</p><ul><li>一个主 - 主 复制双机结构，拥有一个主动服务器和被动服务器。</li><li>一个主库和多个备库。</li><li>一个主动服务器，并使用分布式复制块设备（DRBD）作为备用服务器。</li><li>一个基于存储区域网络（SAN）的 “集群”。</li></ul><h4 id="2-1-按功能拆分"><a href="#2-1-按功能拆分" class="headerlink" title="2.1 按功能拆分"></a>2.1 按功能拆分</h4><p>按功能拆分，或者说按职责拆分，意味着不同的节点执行不同的任务。</p><p>例如，如果有一个网站，各个部分无需共享数据，那么可以按照网站的功能区域进行划分。像我们常见的门户网站，一般都是把不同栏目放在一起，但实际上可以将网站新闻、论坛、寻求支持等功能放到专用的 MySQL 服务器。如 图 1<br><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190410194939603-362772362.png" alt="图 1：一个门户网站以及专用于不同功能区域的节点"></p><h4 id="2-2-数据分片"><a href="#2-2-数据分片" class="headerlink" title="2.2 数据分片"></a>2.2 数据分片</h4><p>在目前用于扩展大型 MySQL 应用的方案中，数据分片是最通用且最成功的方法。它把数据分割成一小片，或者说一块，然后存储到不同的节点中。</p><p>在使用分片前，要牢记一个通用原则：<strong>如非必要，尽量不分片</strong>。</p><p>除此之前，对于分片，我们只会对需要的数据做分片。这里 “需要的数据” 通常是那些增长非常庞大的数据。而像对于用户信息这些全局数据，一般是存储在单个节点上，通常保存在类似 redis 这样的缓存中。</p><p>对于分片，我们通常要考虑下列问题：</p><ol><li>选择合适的分区键（partition key）。</li><li>是否需要多个分区键？</li><li>跨分片查询如何处理？</li><li>如何分片数据、分片和节点？</li><li>如何在节点上部署分片？</li><li>如何生成全局唯一 ID？</li></ol><h4 id="2-3-通过多实例扩展"><a href="#2-3-通过多实例扩展" class="headerlink" title="2.3 通过多实例扩展"></a>2.3 通过多实例扩展</h4><p>上面提到过，MySQL 不能完全发挥现代硬件的性能。当扩展到超过 24 个 CPU 核心时，MySQL 的性能开始趋于平缓，不再上升。当内存超过 128G 时也同样如此。对于此种情况，我们可以通过<strong>多实例策略</strong>充分发挥硬件的性能。</p><p>多实例策略的基本思路是：</p><ol><li>数据分片足够小，可以使得在每台机器上都能放置多个分片；</li><li>每台服务器运行多个实例；</li><li>给每个实例划分服务器的硬件资源；</li></ol><p>可以看出，这是一种向上扩展和向外扩展的组合方案。这种方案还可以通过<strong>将每个 MySQL 实例绑定到特定的 CPU 核心上</strong>来优化性能。这种优化，主要有两个好处：</p><ol><li>由于 MySQL 内部的可扩展性限制，当核心数较少时，能够在每个核心上获得更好的性能；</li><li>当实例在多个核心上运行线程时，由于需要在多核心上同步共享数据，因而会有额外的开销。</li></ol><p>而我们把实例和 CPU 核心绑定后，可以减少 CPU 核心直接的切换和交互。要注意的，将进程绑定到具有相同物理套接字的核心上可以获得最优的效果。</p><h3 id="3-向内扩展"><a href="#3-向内扩展" class="headerlink" title="3 向内扩展"></a>3 向内扩展</h3><p>对于不断增长的数据和负载，最简单的方法是对不再需要的数据进行归档和清理。这种操作可能会带来显著的效果。这种做法并不能代替其他策略，但可以作为争取时间的短期策略，也可以作为处理大数据量的长期计划之一。</p><p>在设计归档和清理策略时需要考虑如下几点：</p><ol><li><strong>对应用的影响</strong>。设计良好的归档系统能够在不影响事务处理的情况下，从一个高负债的 OLTP 服务器上移除数据。</li><li><strong>要归档的行</strong>。考虑清楚哪些数据可以清理或归档。</li><li><strong>维护数据一致性</strong>。数据间存在联系时，归档任务系统要能够保证数据的逻辑一致性。</li><li><strong>避免数据丢失</strong>。归档时要保证归档数据已经成功保存，再讲源数据删除。</li><li><strong>解除归档</strong>。考虑清楚归档系统中的解除归档策略。可以通过设置一些检查点让系统检查是否有需要归档的数据。</li></ol><p>如果不能及时的把老数据归档和清理时，我们也可以通过以下隔离冷热数据的方式来提高性能：</p><ol><li><strong>将表划分为几个部分</strong>。分割大表中的冷热数据，保证加载到内存中的数据中，热数据的比例；</li><li><strong>MySQL 分区</strong>。使用MySQL 自带的分区的功能，可以帮助我们把最近的数据留在内存中；</li><li><strong>基于时间的数据分区</strong>。如果应用不断有新数据尽量，一般新数据总是比旧数据更加活跃。因此，我们可以将新数据完整的保留在内存中，同时使用复制来保证主库失效时有一份可以的备份，而旧数据就而言放到别的地方。</li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>向上氪金，向外氪脑。三思而后行。</li><li>能不分片，就尽量不分片。</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
          <category> 扩展性 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 扩展策略 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL - 扩展性 1 概述：人多未必力量大</title>
      <link href="/4/mysql/kuozhanxing/ck0669dkd0015agaaqme04exy/"/>
      <url>/4/mysql/kuozhanxing/ck0669dkd0015agaaqme04exy/</url>
      
        <content type="html"><![CDATA[<p>我们应该接触过或者听说过数据库的性能瓶颈问题。对于一个单机应用而言，提升数据库性能的最快路径就是氪金 - 买更高性能的数据库服务器，只要钱到位，性能不是问题。</p><p>但是当系统性能增加到一定地步时，你会发现，原先花 3000 块提升了 50% 的性能，现在花 30000 块，才提升了不到 10%。</p><p>也就是说，我们花了钱，但没有得到等价的性能提升，这个时候，我们就要考虑数据库的可扩展性了。</p><p>要讨论 MySQL 的可扩展性，就要先明确可扩展性的定义。在此之前，我们先抛开 MySQL，专注于<strong>扩展性</strong>，搞清楚什么是扩展性，才能更有针对性的去提高 MySQL 的扩展性。</p><h3 id="1-什么是可扩展性"><a href="#1-什么是可扩展性" class="headerlink" title="1 什么是可扩展性"></a>1 什么是可扩展性</h3><p>我们常常把“可扩展性”、“高可用性”以及“性能”用作同义词，但事实上它们是完全不同的。简单来说，性能是<strong>响应时间</strong>，可用性是<strong>宕机时间</strong>，而扩展性表明了<strong>当需要增加资源以执行更多工作时，系统能够获得等价的性能提升的能力</strong>。换种说法，可扩展性就是我们能够尽可能的花费相同的资源提升等价的性能。而缺乏扩展能力的系统在达到收益递减的转折点后，将无法进一步增长。</p><p>容量是一个和可扩展性相关的概念。系统容量表示在一定时间内能够完成的工作量。</p><p>容量和可扩展性并不依赖于性能。以高速公路上的汽车来类比的话：</p><ul><li>性能是汽车的时速。</li><li>容量是车道乘以最大安全时速。</li><li>可扩展性就是在不减慢交通的情况下，能增加更多车和车道的程度。</li></ul><p>在上面这个类比中，可扩展性依赖多个条件：换道设计是否合理、路上有多少车抛锚或发生事故、汽车行驶速度不同以及是否频繁变换车道。但一般来说，和汽车的引擎是否强大无关。</p><p>这并不是说性能不重要，性能确实重要，只是要注意的是，即使系统性能不是很高的系统也可以具备可扩展性。</p><p>从较高层次看，可扩展性就是能够通过增加资源来提升容量的能力。</p><p>对于容量，我们可以简单的认为是处理负载的能力，而从不同的角度考虑负载对我们优化扩展性很有帮助。</p><p><strong>数据量</strong></p><p>应用所能累计的数据量是可扩展性最普遍的挑战，特别是对于现在的互联网应用而言，因为从不删除数据。</p><p><strong>用户量</strong></p><p>首先，即使每个用户只有少量的数据，但在累计到一定数量的用户后，数据量也会开始不成比例的增长，且速度快过用户数增长。其次，更多的用户意味着要处理更多的事务，并且事务数可能和用户数不成比例。最后，大量用户也意味着更多复杂的查询。</p><p><strong>用户活跃度</strong></p><p>不是所有的用户活跃度都相同，并且用户活跃度也不总是不变的。如果用户突然变得活跃，例如 github 给小团队免费开放了私有化仓库，那么其对应的负载可能会明显提升。要注意的是，用户活跃度不仅仅指页面浏览数（PV），即使同样的 PV，如果网站的某个需要执行大量查询工作的功能变得更受欢迎，也可能导致更多的工作。</p><p><strong>相关数据集的大小</strong></p><p>如果用户间存在关系，应用可能需要在整个相关联用户群体上执行查询和计算，这比处理一个个的用户和用户数据要复杂的多。</p><p>说了这么多，只是为了让我们更好的理解可扩展性的让我们用下面图表来更明确的表达可扩展性。</p><p>假设有一个只有一台服务器的系统，并且能够测量它的最大容量，如图 1 所示：<br><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190410193502321-1391206014.png" alt="图1：一个只有一台服务器的系统"></p><p>假设我们现在增加一台服务器，系统的能力加倍，如图 2 所示：<br><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190410193517043-1365794860.png" alt="图 2：一个线性扩展的系统增加一台服务器获得两倍容量"></p><p>图 2 就是线性扩展。我们增加了一倍的服务器，增加了一倍的容量。然而，理想是美好的，现实是骨感的。大部分系统并不是线性扩展的，而是如图 3 所示的扩展方式：<br><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190410193528465-1778088991.png" alt="图 3：一个非线性扩展的系统"></p><p>大部分系统都只能以比线性扩展略低的扩展系数进行扩展。这就导致，多数系统最终会达到一个最大吞吐量临界点，超过这个点后增加投入可能反而会降低系统的吞吐量。</p><p>到这一步，大家对扩展性应该已经有一个较为清晰的概念了。在此基础上，让我们再深入一步：Amdahl 扩展 和 USL 扩展。</p><p>简而言之，USL 说的是线下扩展的偏差可通过两个因素来建立模型：</p><ol><li>无法并发执行的一部分工作；</li><li>需要交互的另外一部分工作。</li></ol><p>在对第一个因素继续建模后，就有了著名的（听过这个著名吗？）阿姆达尔定律（Amdahl）。第一个因素最终会导致吞吐量趋于平缓。<strong>如果部分任务无法并行，那么不管你如果分而治之，该任务至少需要串行部分的时间</strong>。这句话很重要，让我们用一个栗子再简单阐述下：<br>假设大家都做过韭菜煎蛋这道菜，我们做这道菜时，有几个必要步骤：</p><ol><li>切韭菜，耗时 t1；</li><li>打蛋液，耗时 t2；</li><li>开煎，耗时 t3；</li></ol><p>就上面 3 个步骤而言，你可以在切韭菜的时候，让你女票帮你打蛋液，也就是说 1、2 是可以并行的，但是我们能边切菜边煎吗？或者边打蛋液边煎吗？显示是不行的。因此，步骤 3 和 1、2 是串行的。</p><p>这时候，我们就会发现，做韭菜煎蛋这个任务需要的时间 t 为：</p><blockquote><p>t = MAX(t1, t2) + t3;</p></blockquote><p>对第二个因素，需要交互的工作而言，交互就意味着<strong>内部节点间或者进程间的通信</strong>。这种通信的代价取决于通信信道的数量，而信道的数量将按照系统内工作者数量的二次方增长，所以最终开销比带来的收益增长的更快，这就是产生扩展性倒退的原因。由此和 Amdahl 定律，就得出了 USL。</p><p>图 4 阐明了目前讨论的三个概念：线性扩展、Amdahl 扩展以及 USL 扩展。而大多数真实系统看起来更像 USL 曲线。<br><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190411195842184-925806672.png" alt="图 4：线性扩展、Amdahl 扩展以及 USL 扩展定律"></p><p>至此，关于扩展性的概念描述告一段落。接下来，我们回到正题，看看 MySQL 的扩展性如何规划。</p><h3 id="2-规划可扩展性"><a href="#2-规划可扩展性" class="headerlink" title="2 规划可扩展性"></a>2 规划可扩展性</h3><p><strong>什么情况下需要扩展？</strong>，这是个值得我们牢记的问题。当我们提到系统的可扩展性时，一般只有两种情况：</p><ol><li>刚开始规划一个应用；</li><li>当前应用无法满足增加的负载；</li></ol><p>上述两种情况，大多数情况下我们碰到的应该都是后者。具体表现为：</p><ul><li>CPU 密集型变成 I/O 密集型；</li><li>并发查询竞争；</li><li>不断增大的延迟；</li></ul><p>如果是可扩展的应用，可以简单地增加更多的服务器来分担负载。但如果是可扩展性比较差的，你就会发现 - 只剩下提高可扩展性这一条路可走。</p><p>只有一条路，那就且行且 996 吧！</p><p>走上了提升扩展性这条路，接下来的问题就是，如何提高可扩展性？这里比较困难的部分是<strong>估算应用承担的负载到底有多少？</strong>这个值不一定非常精确，但必须在一定的数量级范围内。什么？你问为什么要在一定范围内？不清楚敌人的火力，咱们是准备用高射炮打蚊子还是用大刀对机枪呢？</p><p>除此之外，为了能帮助我们更好的规划可扩展性，咱们最好还能想清楚下面这个问题：</p><ul><li>应用的核心功能完成了多少？很多可扩展性方案可能会导致某些功能实现起来更加复杂。在核心功能没完成前，问问自己，真的要走提升扩展性这条路吗？换个说法，准备好迎接 996 了吗？</li></ul><h3 id="3-为扩展赢得时间"><a href="#3-为扩展赢得时间" class="headerlink" title="3 为扩展赢得时间"></a>3 为扩展赢得时间</h3><p>程序员们理想的开发环境应该是：计划先行、有足够能够一起战斗的同伴、有花不完的预算等等。但现实是：</p><ul><li>boss：诶，小九啊，咱们系统提升下性能要多久啊？三天应该差不多了吧，最多不能超过一周，上次提升性能，小六一天就搞定了的。</li><li>小九：。。。卒</li></ul><p>正常情况下，提升系统的扩展性的难度可能要比重构的难度还要大。因此，在你没有完全把系统摸熟悉，或对扩展性还模糊的时候，千万别给老板说要提升系统的扩展性。</p><p>在老板要求提升性能时，你要想尽一切办法满足他提升性能的需求，同时，要多想下如何提高系统的扩展性，为将来提升扩展性赢得时间。</p><p>可以通过以下工作先提升系统性能：</p><ul><li><strong>优化性能</strong>。很多时候可以通过一个简单的改动来获得明显的性能提升。例如为表建立正确的索引，或从 MyISAM 切换到 InnoDB。再进一步，可以通过慢日志来分析。</li><li><strong>购买性能更强的硬件</strong>。在应用早期，升级或增加服务器可以显著的提升系统性能，并且还能快速的完成。就像我们把服务器从 1 台增加到 3 台，可能就能让性能提升 100%，但是当我们的服务器已经到达 100 台时，再从 100 增加到 300，这时候的复杂度和成本可能已经让你心甘情愿走上提升系统扩展性的道路上了。</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>扩展性是当需要增加资源以执行更多工作时，系统能够获得等价的性能提升的能力。</li><li>不准确评估应用负载的扩展，都是耍流氓。</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
          <category> 扩展性 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 扩展性概述 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 复制 - 性能与扩展性的基石 4：主备切换</title>
      <link href="/4/mysql/fuzhi/ck0669dlr001hagaad4mjbagg/"/>
      <url>/4/mysql/fuzhi/ck0669dlr001hagaad4mjbagg/</url>
      
        <content type="html"><![CDATA[<p>一旦使用 MySQL 的复制功能，就很大可能会碰到主备切换的情况。也许是为了迭代升级服务器，或者是主库出现问题时，将一台备库转换成主库，或者只是希望重新分配容量。不过出于什么原因，都需要将新主库的信息告诉其它备库。</p><p>对于主备切换，如果是计划内的操作，较为容易（至少比紧急情况下容易）。只需在备库简单的使用 CHANGE MASTER TO 命令，并指定合适的值即可。而且大多数的值是可选的，只要指定需要改变的配置项接口。</p><p>备库将抛弃之前的配置和中继日志，并从新的主库开始复制。同时，新的参数会被更新到 master.info 文件中，这样就算重启，备库配置信息也不会丢失。</p><p>整个过程中最难的是<strong>获取新主库上合适的二进制日志位置</strong>。这样备库才可以从老主库相同的逻辑位置开始复制。</p><p>把备库提升为主库要较为麻烦，我们把备库提升主库分为<strong>计划内切换</strong>和<strong>计划外切换</strong>两种场景。</p><h3 id="1-计划内切换"><a href="#1-计划内切换" class="headerlink" title="1 计划内切换"></a>1 计划内切换</h3><p>备库提升为主库，简单来说，有以下步骤：</p><ol><li>停止向老主库写入。</li><li>让备库追赶上主库（可选，可以简化后续的步骤）。</li><li>将一台备库配置为新主库。</li><li>将备库和写操作指向新主库，然后开启主库写入。</li></ol><p>但上面的过程中还因此着很多细节。一些场景可能依赖于复制的拓扑结构。更深入一点，下面是大多数配置需要的步骤：</p><ol><li>停止当前主库上的所有写操作。如果可以，最好能将所有的客户端程序关闭（除了复制连接）。</li><li>通过 FLUSH TABLE WITH READ LOCK 命令在主库上停止所有活跃的写入。也可以在主库上设置 read_only 选项。意味着从这一刻起，禁止向老主库做任何写入操作。因为一旦切换的新主库，老主库的写入就意味着数据丢失。要注意的是，即使设置了 read_only 也不会阻止当前已存在的事务继续提交。因此，可以 kill 所有打开的事务，真正的结束所有写入。</li><li>选择一个备库作为新的主库，并确保它已经完全跟上主库（例如，让它执行完所有从主库获得的中继日志）。</li><li>确保新主库和老主库数据一致。</li><li>在新主库上执行 STOP SLAVE。</li><li>在新主库上执行 CHANGE MASTER TO MASTER_HOST=’’，然后再执行 RESET SLAVE，使其断开与老主库的连接，并丢弃 master.info 里记录的信息（如果连接信息记录在 my.cnf 里，会无法正常工作，因此我们建议不要把复制连接信息写到配置文件里）。</li><li>执行 SHOW MASTER STATUS 记录新主库的二进制日志坐标。</li><li>确保其它备库已经追赶上老主库。</li><li>关闭老主库。</li><li>将客户端连接到新主库。</li><li>在每台备库上执行 CHANGE MASTER TO 语句，使用之前获得的二进制日志坐标，指向新的主库。</li></ol><h3 id="2-计划外切换"><a href="#2-计划外切换" class="headerlink" title="2 计划外切换"></a>2 计划外切换</h3><p>当主库崩溃时，需要将一台备库提升为主库。这个过程就比较麻烦。如果只有一台备库，可以直接使用这台备库。但如果有超过一台的备库，就需要做一些额外的工作。</p><p>另外，还有潜在的丢失复制事件的问题。可能有主库上已发生的修改还没有更新到它任何一台备库上的情况。甚至可能一条语句在主库上执行了回滚，但在备库上没有回滚，这样备库可能就超过主库的逻辑复制位置。如果能在某一点恢复主库的数据，也许就可以取得丢失语句，并手动执行他们。</p><p>在以下描述中，需要确保在服务器中使用 Master_Log_File 和 Read_Master_Log_Pos 的值。</p><h4 id="2-1-主备结构之备库提升"><a href="#2-1-主备结构之备库提升" class="headerlink" title="2.1 主备结构之备库提升"></a>2.1 主备结构之备库提升</h4><ol><li>确定哪台备库的数据最新。检查每台备库上 SHOW_SLAVE_STATUS 命令的输出，选择其中 Master_Log_File 和 Read_Master_Log_Pos 的值最新的那个。</li><li>让所有备库执行完所有从老主库崩溃前获得的中继日志。</li><li>在新主库上执行 STOP SLAVE。</li><li>在新主库上执行 CHANGE MASTER TO MASTER_HOST=’’，然后再执行 RESET SLAVE，使其断开与老主库的连接，并丢弃 master.info 里记录的信息。</li><li>执行 SHOW MASTER STATUS 记录新主库的二进制日志坐标。</li><li>比较每台备库和新主库上的 Master_Log_File 和 Read_Master_Log_Pos 的值。</li><li>将客户端连接到新主库。</li><li>在每台备库上执行 CHANGE MASTER TO 语句，使用之前获得的二进制日志坐标，指向新的主库。</li></ol><p>如果已经在所有备库上开启了 log_bin 和 log_slave_updates，就可以将所有备库恢复到一个一致的时间点，如果没有开启这两个选项，则很难做到这一点。</p><p>上面过程中比较重要的一点是确定日志位置。接下来，我们就来看看如何却。</p><h3 id="3-确定日志位置"><a href="#3-确定日志位置" class="headerlink" title="3 确定日志位置"></a>3 确定日志位置</h3><p>如果有备库和新主库的位置不相同，则需要找到该备库最后一条执行的事件在新主库的二进制日志中对应的位置，然后再执行 CHANGE MASTER TO。可以通过 mysqlbinlog 工具来找到备库执行的最后一条查询，然后再主库上找到同样的查询，进行简单的计算即可得到。</p><p>为了便于描述，假设每个日志事件都有一个自增数字 ID。新主库在老主库崩溃时获得了编号为 100 的事件，另外两条备库：R2 和 R3。R2 已结获取了 99 号事件，R3 获取了 98 号事件。</p><p>如果把 R2 和 R3 都指向新主库的同一个二进制日志位置，它们将从 101 号事件开始复制，从而导致数据不同步。但只要新主库的二进制日志已结通过 log_slave_updates 打开，就可以在新主库的二进制日志中找到 99 号 和 100 号事件，从而将备库恢复到一致的状态。</p><p>由于服务器重启，不同的配置，日志轮转或者 FLUSH LOGS 命令，同一个事件在不同的服务器上可能有不同的偏移量。我们可以通过 mysqlbinlog 从二进制日志或中继日志中解析出每台备库上执行的最后一个事件，并还有该命令解析新主库上的二进制文件，找到相同的查询，mysqlbinlog 会打印出该事件的偏移量，在 CHANGE MASTER TO 命令中使用这个值。</p><p>更快的方法是把新主库和停止的备库上的字节偏移量相减，它显示了字节位置的差异。然后把这个值和新主库当前二进制日志的位置相减，就可以得到期望的查询位置。</p><p>一起来看个栗子。</p><p>假设 s1 是 s2 和 s3 的主库。其中 s1 已经崩溃。根据 SHOW SLAVE STATUS 获得 Master_Log_File 和 Read_Master_Log_Pos 的值，s2 已结执行完了 s1 上所有的二进制日志，但 s3 还没有。如图 1：</p><p><img src="https://github.com/zibinli/blog/blob/master/MySQL/image/1-1.png?raw=true" alt="图 1：s1 崩溃，s2 已追赶上，s3 落后"></p><p>我们可以肯定 s2 已经执行完了主库上的所有二进制日志，因为 Master_log_File 和 Read_Master_Log_Pos 的值和 s1 上最后的日志位置相吻合。因此，我们可以将 s2 提升为新主库，并将 s3 设置为 s2 的备库。</p><p>应该在 s3 上为需要执行的 CHANGE MASTER TO 语句赋予什么参数呢？这里需要做一点计算。</p><p>s3 在偏移量 1493 处停止，比 s2 执行的最后一条语句的偏移量 1582 要小 89 字节。</p><p>s2 正在向偏移量为 8167 的二进制日志写入，因此，理论上我们应该将 s3 指向 s2 日志的偏移量为 8167-89=8078 的位置。</p><p>最后在 s2 日志中的 8078 位置，确定该位置上是否是正确的日志事件。</p><p>如果验证没问题，可以通过下面命令将 s3 切换为 s2 的备库：</p><blockquote><p>CHANGE MASTER TO MASTER_HOST=”s2 host”, MASTER_LOG_FILE=”mysql-bin.000009”, MASTER_LOG_POS=8078;</p></blockquote><p>如果服务器在它崩溃时已经执行完成并记录了一个事件 a。因为 s2 仅仅读取并执行到了 1582，因此可能会失去事件 a。但是如果老主库的磁盘没有损坏，仍然可以通过 mysqlbinlog 或者从日志服务器的二进制日志中找到丢失的事件。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>备库提升区分计划内和计划外场景。</li><li>备库提升，找到新主库准确的二进制日志位置是关键。</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
          <category> 复制 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 主备切换 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 复制 - 性能与扩展性的基石 3：常见问题及解决方案</title>
      <link href="/4/mysql/fuzhi/ck0669dlh001dagaajtvz8jak/"/>
      <url>/4/mysql/fuzhi/ck0669dlh001dagaajtvz8jak/</url>
      
        <content type="html"><![CDATA[<p>主备复制过程中有很大可能会出现各种问题，接下来我们就讨论一些比较普遍的问题，以及当遇到这些问题时，如何解决或者预防问题发生。</p><h3 id="1-数据损坏或丢失"><a href="#1-数据损坏或丢失" class="headerlink" title="1 数据损坏或丢失"></a>1 数据损坏或丢失</h3><p>问题描述：服务器崩溃、断电、磁盘损坏、内存或网络错误等问题，导致数据损坏或丢失。<br>问题原因：非正常关机导致没有把数据及时的写入硬盘。</p><p>这种问题，一般可以分为几种情况导致：</p><h4 id="1-1-主库意外关闭"><a href="#1-1-主库意外关闭" class="headerlink" title="1.1 主库意外关闭"></a>1.1 主库意外关闭</h4><p><strong>问题未发生，避免方案</strong>：设置主库的 sync_binlog 选项为 1。此选项表示 MySQL 是否控制 binlog 的刷新。当设置为 1 时，表示每次事务提交，MySQL 都会把 binlog 刷下去，是<strong>最安全，性能损耗也最大的设置</strong>。<br><strong>问题已发生，解决方案</strong>：指定备库从下一个二进制日志的开头重新读日志。但是一些日志事件将永久性丢失。可以使用 Percona Toolkit 中的 pt-table-checksum 工具来检查主备一致性，以便于修复。</p><h4 id="1-2-备库意外关闭"><a href="#1-2-备库意外关闭" class="headerlink" title="1.2 备库意外关闭"></a>1.2 备库意外关闭</h4><p>备库意外关闭重启时，会去读 master.info 文件以找到上次停止复制的位置。但是在意外关闭的情况下，这个文件存储的信息可能是错误的。此外，备库也可能会尝试重新执行一些二进制文件，这可能会导致唯一索引错误。我们可以通过 Percona Toolkit 中的 pt-slave-restart 工具，帮助备库重新执行日志文件。</p><p>如果使用的是 InnoDB 表，可以在重启后观察 MySQL 的错误日志。InnoDB 在恢复过程中会打印出恢复点的二进制日志坐标，可以使用这个值来决定备库指向主库的偏移量。</p><h4 id="1-3-主库二进制日志损坏"><a href="#1-3-主库二进制日志损坏" class="headerlink" title="1.3 主库二进制日志损坏"></a>1.3 主库二进制日志损坏</h4><p>如果主库上的二进制日志损坏，除了忽略损坏的位置外，别无选择。在忽略存货位置后，我们可以通过 FLUSH LOGS 命令在主库开始一个新的日志文件，然后将备库指向该文件的开始位置。</p><h4 id="1-4-备库中继日志损坏"><a href="#1-4-备库中继日志损坏" class="headerlink" title="1.4 备库中继日志损坏"></a>1.4 备库中继日志损坏</h4><p>如果主库上的日志是完好的，有两种解决方案：<br><strong>1) 手工处理</strong>。找到 master  binlog 日志的 pos 点，然后重新同步。</p><p><strong>2) 自动处理</strong>。mysql5.5 考虑到 slave 宕机中继日志损坏这一问题，只要在 slave 的的配置文件 my.cnf 里增加一个参数 relay_log_recovery=1 即可。</p><h4 id="1-5-二进制日志与-InnoDB-事务日志不同步"><a href="#1-5-二进制日志与-InnoDB-事务日志不同步" class="headerlink" title="1.5 二进制日志与 InnoDB 事务日志不同步"></a>1.5 二进制日志与 InnoDB 事务日志不同步</h4><p>由于各种各样的原因，MySQL 的复制碰到服务器崩溃、断电、磁盘损坏、内存或网络错误时，很难恢复当时丢失的数据。几乎都需要从某个点开始重启复制。</p><h3 id="2-未定义的服务器-ID"><a href="#2-未定义的服务器-ID" class="headerlink" title="2 未定义的服务器 ID"></a>2 未定义的服务器 ID</h3><p>如果没有再 my.cnf 里定义服务器 ID，虽然可以通过 CHANGE MASTER TO 来设置备库，但在启动复制时会遇到：</p><pre><code>mysql&gt; START SLAVE;ERROR 1200 (HY000): The server us bit configured as slave; fix in config file or with CHANGE MASTER TO</code></pre><p>这个报错可能会让人困惑。因为我们可能已经通过 CHANGE MASTER TO 设置了备库，并且通过 SHOW MASTER STATUS 也确认了，为什么还会有这样的报错呢？我们通过 SELECT @@server_id 可以获得一个值，要注意的是，这个值只是默认值，我们必须为备库显式地设置服务器 ID。也就是在 my.cnf 里显示的设置服务器 ID。</p><h3 id="3-对未复制数据的依赖性"><a href="#3-对未复制数据的依赖性" class="headerlink" title="3 对未复制数据的依赖性"></a>3 对未复制数据的依赖性</h3><blockquote><p>如果在主库上有备库上不存在的数据库或数据表，复制就很容易中断，反之亦然。<br>对于前者，假设在主库上有一个 single_master 表，备库没有。在主库上对此表进行操作后，备库在尝试回放这些操作时就会出现问题，导致复制中断。</p></blockquote><p>对于后者，假设备库上有一个 single_slave 表，主库没有。在主库上执行创建 single_slave 表的语句时，备库在回放该建表语句时就会出现问题。</p><p>对于此问题，我们能做的就是做好预防：</p><ol><li>主备切换时，尽量在切换后对比数据，查清楚是否有不一致的表或库。</li><li>一定不要在备库执行写操作。</li></ol><h3 id="4-丢失的临时表"><a href="#4-丢失的临时表" class="headerlink" title="4 丢失的临时表"></a>4 丢失的临时表</h3><p>临时表和基于语句的复制方式不相容。如果备库崩溃或者正常关闭，任何复制线程拥有的临时表都会丢失。重启备库后，所有依赖于该临时表的语句都会失败。</p><p>复制时出现找不到临时表的异常时，可以做：</p><ol><li>直接跳过错误，或者手动地创建一个名字和结构相同的表来代替消失的的临时表。</li></ol><p>临时表的特性：</p><ol><li>只对创建临时表的连接可见。不会和其他拥有相同名字的临时表的连接起冲突；</li><li>随着连接关闭而消失，无须显式的移除它们。</li></ol><h4 id="4-1-更好使用临时表的方式"><a href="#4-1-更好使用临时表的方式" class="headerlink" title="4.1 更好使用临时表的方式"></a>4.1 更好使用临时表的方式</h4><p>保留一个专用的数据库，在其中创建持久表，把它们作为伪临时表，以模拟临时表特性。只需要通过 CONNETCTION_ID() 的返回值，给临时表创建唯一的名字。</p><p>伪临时表的优劣势<br>优势：</p><ol><li>更容易调试应用程序。可以通过别的连接来查看应用正在维护的数据；</li></ol><p>劣势：</p><ol><li>比临时表多一些开销。创建较慢伪临时表会较慢，因为表的 .frm 文件需要刷新到磁盘。</li></ol><h3 id="5-InnoDB-加锁读导致主备数据不一致"><a href="#5-InnoDB-加锁读导致主备数据不一致" class="headerlink" title="5 InnoDB 加锁读导致主备数据不一致"></a>5 InnoDB 加锁读导致主备数据不一致</h3><p>使用共享锁，串行化更新，保证备库复制时数据一致。</p><p>某些情况下，加锁读可以防止混乱。假设有两张表：tab1 没有数据，tab2 只有一行数据，值为 99。此时，有两个事务更新数据。事务 1 将 tab2 的数据插入到 tab1，事务 2 更新 tab2。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190408100226421-1095843051.png" alt="两个事务更新数据，使用共享锁串行化更新"></p><ol><li>事务 1 使用获取 tab2 数据时，加入共享锁，并插入 tab1；</li><li>同时，事务 2 更新 tab2 数据时，由于写操作的排它锁机制，无法获取 tab2 的锁，等待；</li><li>事务 1 插入数据后，删除共享锁，提交事务，写入 binlog（此时 tab1 和 tab2 的记录值 都是 99）；</li><li>事务 2 获取到锁，更新数据，提交事务，写入 binlog（此时 tab1 的记录值为 99，tab2 的记录值为 100）。</li></ol><p>上述过程中，第二步非常重要。事务 2 尝试去更新 tab2 表，这需要在更新的行上加<strong>排他锁（写锁）</strong>。排他锁与其他锁不相容，包括事务 1 在行记录上加的共享锁。因此事务 2 需要等待事务 1 完成。备库在根据 binlog 进行复制时，会按同样的顺序先执行事务 1，再执行事务 2。主备数据一致。</p><p>同样的过程，如果事务 1 在第一步时没有加共享锁，流程就变成：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190408100241551-397342289.png" alt="两个事务更新数据，未使用共享锁串行化更新"></p><ol><li>事务 1 无锁读取 tab2 数据，并插入 tab1（此时 tab1 和 tab2 的记录值 都是 99）；</li><li>同时，事务 2 更新 tab2 数据，先与事务 1 提交事务，写入 binlog（此时 tab1 的记录值为 99，tab2 的记录值为 100）；</li><li>事务 1 提交事务，写入 binlog（此时记录值无变化）；<blockquote><p>mysqldump –single-transaction –all-databases –master-data=1 –host=server1 | mysql –host=server2<br>要注意的是，上述过程中，事务 2 先提交，先写入 binlog。在备库复制时，同样先执行事务 2，将 tab2 的记录值更新为 100。然后执行事务 1，读取 tab2 数据，插入 tab1，所以最终的结果是，tab1 的记录值和 tab2 的记录值都是 100。很明显，数据和主库有差异。</p></blockquote></li></ol><p>建议在大多数情况下将 innodb_unsafe_for_binlog 的值设置为 0。基于行的复制由于记录了数据的变化而非语句，因此不会存在这个问题。</p><h3 id="6-复制延迟过大"><a href="#6-复制延迟过大" class="headerlink" title="6 复制延迟过大"></a>6 复制延迟过大</h3><p><strong>产生延迟的两种方式</strong></p><ol><li>突然产生延迟，然后再跟上；</li><li>稳定的延迟增大</li></ol><p>前者通常是由于一条执行时间过长的 SQL 导致，而后者即使在没有慢语句也会出现。</p><p>对于前者，我们可以通过备库上的慢查询日志来进行优化。在备库上开启 log_slow_slave_statement 选项，可以在慢查询日志中记录复制线程执行的语句。</p><p>而对于后者，没有针对性的解决方案，只能通过各种方式提高备库的复制效率。而当我们想去对备库做优化时，会发现，除了购买更快的磁盘和 CPU，并没有太多的调优空间。只能通过 MySQL 选项禁止某些额外的工作以减少备库的复制。可以通过下面几种方式：</p><ol><li>使用 InnoDB 引擎时，设置 innodb_flush_log_at_trx_commit 值为 2，来使备库不要频繁的刷新磁盘，以提高事务提交效率。</li><li>禁止二进制日志记录。把 innodb_locks_unsafe_for_binlog 设置为 1，并把 MyISAM 的 delay_key_write 设置为 ALL。要注意的是，这些设置是以安全换取速度，在将备库提升为主库时，记得把这些选项设置回安全的值。</li><li>拆分效率较低的复制 SQL，分离复杂语句中的 SELECT 和 UPDATE 语句，降低复制消耗，提高效率。</li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>复制问题要分清楚是 master 的问题，还是 slave 的问题。</li><li>master 问题找 binlog，slave 问题找 relaylog。</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
          <category> 复制 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 常见问题及解决方案 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 复制 - 性能与扩展性的基石 2：部署及其配置</title>
      <link href="/4/mysql/fuzhi/ck0669dl3001aagaajvte042j/"/>
      <url>/4/mysql/fuzhi/ck0669dl3001aagaajvte042j/</url>
      
        <content type="html"><![CDATA[<p><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190402210204568-2120449484.png" alt=""></p><p>正所谓理论造航母，现实小帆船。单有理论，不动手实践，学到的知识犹如空中楼阁。接下来，我们一起来看下如何一步步进行 MySQL Replication 的配置。</p><p>为 MySQL 服务器配置复制非常简单。但由于场景不同，基本的步骤还是有所差异。最基本的场景是新安装主库和备库，总得来说分为以下几步：</p><ol><li>在每台服务器上创建复制账号。</li><li>配置主库和备库。</li><li>通知备库连接到主库并从主库复制数据。</li></ol><p>此外，由于主备部署需要多台服务器，但是这种要求对大多数人来说并不怎么友好，毕竟没有必要为了学习部署主备结构，多买个云服务器。因此，为了测试方便，我们通过 docker 容器技术在同台机器上部署多个容器，从而实现在一台机器上部署主备结构。</p><p>这里我们先假定大部分配置采用默认值，在主库和备库都是全新安装并且拥有同样的数据。接下来，我们将展示如何通过 docker 技术一步步进行复制配置。</p><p>此外，我们将推荐一些“安全配置”，以便在不清楚如何配置时，确保数据的安全。</p><h3 id="1-部署-docker-环境"><a href="#1-部署-docker-环境" class="headerlink" title="1 部署 docker 环境"></a>1 部署 docker 环境</h3><p><strong>1) 部署 docker</strong></p><p>什么？docker 还没部署？<a href="http://www.runoob.com/docker/ubuntu-docker-install.html" target="_blank" rel="noopener">赶紧参考这里配一个</a>，docker 都没玩，怎么和面试官吹水呀！</p><p><strong>2) 拉取 MySQL 镜像</strong></p><pre><code>docker pull mysql:5.7</code></pre><p><strong>3) 使用 mysql 镜像启动容器</strong></p><pre><code>docker run -p 3339:3306 --name mysql-master -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 # 启动 master 容器docker run -p 3340:3306 --name mysql-slave -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 # 启动 slave 容器</code></pre><p>master 对外的端口是 3339，slave 对外的端口是 3340，我们在使用客户端连接要使用对应的端口连接对应 mysql。</p><p><strong>4) 使用命令查看正在运行的容器</strong></p><pre><code>docker ps</code></pre><p><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190402203055411-1191098668.png" alt="docker-ps"></p><p><strong>5) 使用客户端连接工具测试丽连接 mysql</strong><br><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190402203154396-1276802816.png" alt="接测试"></p><h3 id="2-配置-Master-和-Slave"><a href="#2-配置-Master-和-Slave" class="headerlink" title="2 配置 Master 和 Slave"></a>2 配置 Master 和 Slave</h3><p><strong>1) 配置 master</strong><br>通过以下命令进入容器内部</p><pre><code>docker exec -it mysql-master /bin/bash</code></pre><p>a) 更新 apt-get 源</p><pre><code>apt-get update</code></pre><p>b) 安装 vim</p><pre><code>apt-get install vim</code></pre><p>c) 配置 my.cnf</p><pre><code>vim /etc/mysql/my.cnf// 在my.cnf 中添加如下配置[mysqld]server-id=110 # 服务器 id，同一局域网内唯一log-bin=/var/lib/mysql/mysql-bin # 二进制日志路径</code></pre><p>d) 重启 mysql 服务使配置生效</p><pre><code>service mysql restart</code></pre><p>e) 启动容器<br>重启 mysql 服务时会使得 docker 容器停止，需要重启容器。</p><pre><code>docker start mysql-master</code></pre><p>f) 创建数据同步用户并授权</p><pre><code>CREATE USER 'slave'@'%' IDENTIFIED BY '123456';GRANT REPLICATION SLAVE,REPLICATION CLIENT ON *.* TO 'slave'@'%';</code></pre><p><strong>2) 配置 slave</strong><br>通过以下命令进入容器内部</p><pre><code>docker exec -it mysql-slave /bin/bash</code></pre><p>a) 配置 my.cnf</p><pre><code>vim /etc/mysql/my.cnf// 在my.cnf 中添加如下配置[mysqld]server-id=120 # 服务器 id，同一局域网内唯一log-bin=/var/lib/mysql/mysql-bin # 二进制日志路径relay_log=/path/to/logs/relay-bin # 中继日志路径</code></pre><p><strong>3) 关联 master 和 slave</strong><br>配置完 master 和 slave，接下来就要让 master 和 slave 相关联。<br>回到我们的服务器，先找出 master 和 slave 容器的 IP，执行：</p><pre><code>docker inspect --format='{{.NetworkSettings.IPAddress}}' mysql-master</code></pre><p><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190402203411050-1484028544.png" alt="master IP"></p><p>因此，我们知道了 mysql-master 容器的 IP 是：<em>172.17.0.3</em>。同样的方法，mysq-slave 容器的 IP 是：<em>172.17.0.4</em>。记住这两个值，后面的配置需要用到。</p><p>我们首先配置 master。在 master 容器内通过 <em>mysql -u root -p</em> 进入 MySQL 命令行，执行 <em>show master status;</em></p><p><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190402203436827-1700544449.png" alt="master状态"></p><p>上图中，File 和 Position 字段对应的值要记录下来，后续在 slave 配置时需要用到这两个值。要注意的是，记录完这两个值后，就不能在 master 库上做任何操作，否则会出现数据不同步的情况。</p><p>接下来配置 slave，同样的，在 slave 上进入 MySQL 命令行。然后执行下面语句：</p><pre><code>change master to master_host='172.17.0.3', master_user='slave', master_password='123456', master_port=3306, master_log_file='mysql-bin.000001', master_log_pos=42852, master_connect_retry=30;</code></pre><p><em>change master to</em> 是 slave 配置 master 的命令，相关参数含义如下：</p><ul><li>master_host：master 的IP，就是我们上面获取的 IP 地址</li><li>master_port：master 的端口号，也就是我们 master mysql 的端口号</li><li>master_user：进行数据同步的用户</li><li>master_password：同步用户的密码</li><li>master_log_file：指定 slave 从 master 的哪个日志文件开始复制数据，也就是我们上面提到的 File 字段的值</li><li>master_log_pos：从 master 日志文件的那个位置开始读，上面提到的 Position 字段的值</li><li>master_connect_retry：重试时间间隔。单位是秒，默认 60</li></ul><h3 id="3-启动复制"><a href="#3-启动复制" class="headerlink" title="3 启动复制"></a>3 启动复制</h3><p>配置完 slave 后，可以通过 <em>show slave status\G;</em>  查看 slave 的状态。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190402203509920-1760529853.png" alt="lave 状态"></p><p>正常情况下，刚配置完 slave 的 Slave_IO_Running 和 Slave_SQL_Runing 都是 NO，因为我们还没开启主从复制。使用 <em>start slave</em> 开启主从复制，然后再查下 slave 状态。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190402203531769-1518965498.png" alt="开启主从复制后的 slave 状态"></p><p>slave 的 Slave_IO_Running 和 Slave_SQL_Runing 都是 YES，说明主从复制已成功启动。此时，可以通过客户端能否成功复制数据。</p><p>我们在 master 新建 replication 库，然后观察 slave 库是否创建了 replication 库，如下图，表示复制成功。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201904/861679-20190402203608282-1182295306.png" alt="主从复制测试"></p><p>另外，开启主从复制后，如果出现以下情况：</p><pre><code>Slave_IO_Running: CONNECTINGSlave_SQL_RUNNING: Yes</code></pre><p>表示开启主从复制后， slave 的 IO 进程连接 master 出现问题，一直在重试连接。我们可以根据 Last_IO_Error 的提示进行解决：</p><ol><li>网络不通。检查 IP、port。</li><li>密码错误。检查配置的同步用户和密码是否正确。</li><li>pos 错误。检查 slave 配置的 Position 的值 与 master 是否一致。</li></ol><h3 id="4-从另一个服务器开始复制"><a href="#4-从另一个服务器开始复制" class="headerlink" title="4 从另一个服务器开始复制"></a>4 从另一个服务器开始复制</h3><p>前面的设置都是假定主备库均为刚刚安装好且都是默认的数据，也就是说两台服务器上数据相同，并且知道当前主库的二进制日志。但在实际环境中，大多数情况下是有一个一级运行了一段时间的主库，然后用一台新安装的备库与之同步，此时这台备库还没有数据。</p><p>有几种方法来初始化备库或者从其他服务器克隆数据到备库。包括从主库复制数据、从另外一台备库克隆数据，以及使用最近的一次备份来启动备库等。而这些方法都需要有三个条件来让主库与备库保持同步：</p><ul><li>在某个时间点的主库的数据快照。</li><li>主库当前的<strong>二进制日志文件</strong>，和获得数据快照时在该二进制日志文件中的<strong>偏移量</strong>。我们把这两个值称为<strong>日志文件坐标（log file coordinates）</strong>。通过这两个值可以确定二进制日志的位置。可以通过 SHOW MASTER STATUS 命令来获取这些值。</li><li>从快照时间到现在的二进制日志。</li></ul><p>下面是一些从别的服务器克隆备库的方法：</p><ol><li><strong>使用冷备份</strong>。最基本的方法是关闭主库，把数据复制到备库。重启主库后，会使用一个新的二进制日志文件，我们在备库通过执行 CHANGE MASTER TO 指向这个文件的起始处。不过这个方法的缺点很明显：在复制数据时需要关闭主库。</li><li><strong>使用热备份</strong>。如果仅使用了 MyISAM 表，可以在主库运行时使用 mysqlhotcopy 或 rsync 来复制数据。</li><li><strong>使用 mysqldump</strong>。如果只包含 InnoDB 表，可以使用以下命令来转储主库数据并将其加载到备库，然后设置相应的二进制日志坐标：<em>mysqldump –single-transaction –all-databases –master-data=1 –host=server1 | mysql –host=server2</em>。选项 –single-transaction 使得转储的数据为事务开始前的数据。如果使用的是非事务型表，可以使用 –lock-all-tables 选项来获得所有表的一致性转储。</li><li><strong>使用快照或备份</strong>。只要知道对应的二进制日志坐标，就可以使用主库的快照或者备份来初始化备库。（如果使用备份，需要确保从备份的时间点开始的主库二进制日志都要存在）。只需要把备份或快照恢复到备库，然后使用 CHANGE MASTER TO 指定二进制日志的坐标。</li><li><strong>使用 Percona Xtrabackup</strong>。Percona 的 Xtrabackup 是一款开源的热备份工具。它能够在备份时不阻塞服务器的操作，因此可以在不影响主库的情况下设置备库。可以通过克隆主库或另一个已存在的备库的方式来建立备库。</li><li><strong>使用另外的备库</strong>。可以使用任何一种克隆或拷贝技术从任意一台备库上将数据克隆到另外一台服务器。但是如果使用的是 mysqldump，–master-data 选项就会不起作用。此外，不能使用 SHOW MASTER STATUS 来获得主库的二进制日志坐标，而是在获取快照时使用 SHOW SLAVE STATUS 来获取备库在主库上的执行位置。使用另外的备库进行数据克隆最大的缺点是，如果这台备库的数据已经和主库不同步，克隆得到的就是脏数据。</li></ol><h3 id="5-推荐的复制配置"><a href="#5-推荐的复制配置" class="headerlink" title="5 推荐的复制配置"></a>5 推荐的复制配置</h3><p>我们知道，MySQL 的复制有许多参数可以控制，其中一些会对数据安全和性能产生影响。这里，我们介绍一种“安全配置”，可以最小化问题发生的概率。</p><p>在主库上二进制日志最重要的选项是 sync_binlog：</p><blockquote><p>sync_binlog=1<br>如果开启该选项，MySQL 每次在提交事务前会将二进制日志同步到磁盘上，保证在服务器崩溃时不会丢失时间。如果禁止该选项，服务器会少做一些工作，但二进制日志文件可能在服务器崩溃时损坏或丢失信息。在一个不需要作为主库的备库上 ，该选项会带来不必要的开销。要注意的是，它只适用于二进制日志，而非中继日志。</p></blockquote><p>如果无法接受服务器崩溃导致表损坏，推荐使用 InnoDB。MyISAM 表在备库服务器崩溃重启后，可能已经处于不一致状态。</p><p>如果使用 InnoDB，推荐设置如下选项：</p><pre><code>innodb_flush_logs_at_trx_commit=1 # 每次事务提交时，将 log buffer 写入到日志文件并刷新到磁盘。默认值为 1innodb_safe_binlog</code></pre><p><strong>明确指定二进制日志文件的名称</strong>。当服务器间转移文件、克隆新的备库、转储备份或者其他场景下，如果以服务器名来命名二进制日志可能会导致很多问题。因此，我们需要给 log_bin 选项指定一个参数。</p><pre><code>log_bin=/var/lib/mysql/mysql-bin</code></pre><p>在备库上，同样开启如下培训，为中继日志指定绝对路径：</p><pre><code>relay_log=/path/to/logs/relay-binskip_slave_startread_only</code></pre><p>通过设置 relay_log 可以避免中继日志文件基于机器名来命名，防止之前提到的可能在主库上发生的问题。而 skip_slave_start 选项能够阻止备库在崩溃后自动启动复制，以留出时间修复可能发生的问题。read_only 选项可以阻止大部分用户更改非临时表。</p><h3 id="6-小结"><a href="#6-小结" class="headerlink" title="6 小结"></a>6 小结</h3><ol><li>复制初始化配置三部曲：创建账号、配置主备库、备库连接到主库开始复制；</li><li>从已有服务器复制时，可用热备份或 mysqldump 命令进行备份；</li><li>在不确定相关配置时，选择最安全的配置准没错；</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
          <category> 复制 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 复制部署 </tag>
            
            <tag> 复制配置 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 复制 - 性能与扩展性的基石 1：概述及其原理</title>
      <link href="/4/mysql/fuzhi/ck0669dkz0019agaa5yy85u8n/"/>
      <url>/4/mysql/fuzhi/ck0669dkz0019agaa5yy85u8n/</url>
      
        <content type="html"><![CDATA[<h3 id="1-复制概述"><a href="#1-复制概述" class="headerlink" title="1. 复制概述"></a>1. 复制概述</h3><p>MySQL 内置的复制功能是构建基于 MySQL 的大规模、高性能应用的基础，复制解决的基本问题是<strong>让一台服务器的数据与其他服务器保持同步</strong>。</p><p>接下来，我们将从复制概述及原理、复制的配置、常见的问题及解决方法来学习 MySQL 的复制功能。</p><h4 id="1-1-复制解决的问题"><a href="#1-1-复制解决的问题" class="headerlink" title="1.1 复制解决的问题"></a>1.1 复制解决的问题</h4><p>下面是复制常见的用途：</p><ul><li><strong>数据分布</strong>。Mysql 复制通常不会对带宽造成很大压力，但在 5.1 版本中引入的基于行的复制会比传统的基于语句的复制模式产生更大的带宽压力。你可以随意地停止或开始复制，并在不同的地理位置来分布数据备份，例如不同的数据中心。另外，即使在不稳定的网络环境下，远程复制也可以工作。但如果未来保存很低的复制延迟，最好有一个稳定、低延迟的连接。</li><li><strong>负载均衡</strong>。通过 Mysql 复制，可以将读操作分布到多个服务器上，实现对读密集型应用的优化，并且很容易实现，通过简单的代码修改就能实现基本的负载均衡。对应小规模的应用，可以简单的使用 DNS 轮询（将一个机器名指向多个 IP 地址）。</li><li><strong>备份</strong>。对于备份来说，负载是一项很有意义的技术补充。</li><li><strong>高可用性和故障切换</strong>。负载能够帮助应用避免 Mysql 单点失败，一个使用复制的设计良好的系统能够显著的缩短宕机时间。</li><li><strong>Mysql 升级测试</strong>。这是比较常见的做法，在更新 Mysql 版本前，先使用将要更新的版本作为备库，保证更新版本不会对系统造成影响。</li></ul><h4 id="1-2-复制是如何工作的？"><a href="#1-2-复制是如何工作的？" class="headerlink" title="1.2 复制是如何工作的？"></a>1.2 复制是如何工作的？</h4><p>在详细介绍如何设置复制之前，让我们先看看 Mysql 实际上是如何进行数据复制的。</p><p>总的来说，复制有三个步骤：</p><ol><li>在主库上把数据更改写入到二进制日志（Binary Log）中（这些记录被称为二进制日志事件）。</li><li>备库将主库上的日志复制到自己的中继日志（Relay Log）中。</li><li>备库读取中继日志中的事件，将其更改同步到备库。</li></ol><p>以上是复制的简单概述，下图描述了复制的细节：<br><img src="https://img2018.cnblogs.com/blog/861679/201903/861679-20190331175913955-903928645.png" alt="MySQL 复制流程图"></p><p>整体复制过程：</p><ol><li><strong>在主库上记录二进制日志</strong>。在每次准备提交事务完成 数据更新前，主库将数据更新的事件记录到二进制日志中。Mysql 会按事务提交的顺序而非每条语句的执行顺序来记录二进制日志。在记录二进制日志后，主库会告诉存储引擎可以提交事务了。</li><li><strong>备库将主库的二进制日志复制到其本地的中继日志中</strong>。<em>首先</em>，备库会启动一个工作线程，称为 I/O 线程，I/O 线程跟主库建立一个普通的客户端连接，<em>然后</em>在主库上启动一个特殊的二进制转储（binlog dump）线程，这个二进制转储线程会读取主库二进制日志中的事件。它不会对时间进行轮询。如果该线程“追赶”上了主库，它将进入睡眠状态，直到主库发送信号量通知它有新的事件产生才会被换新，备库 I/O 线程会将接收到的事件记录到中继日志中。</li><li><strong>备库启动 SQL 线程，执行最后一步</strong>。该线程从中继日志中读取事件并在备库执行，从而实现备库数据的更新。当 SQL 线程追赶上 I/O 线程时，中继日志通常已经在系统缓存中，所以中继日志的开销很低。SQL 线程执行的事件也可以通过配置项来决定是否写入自身的二进制日志中，这对于备库再配置备库的常见非常有用。</li></ol><p>这种复制架构实现了<strong>获取事件</strong>和<strong>重放事件</strong>的解耦，允许这两个过程异步进行。也就是说 I/O 线程能够独立于 SQL 线程之前工作。但是，这种架构也限制了复制的过程，其中最重要的一点是，在主库上并发运行的查询在备库上只能串行化执行，因为只有一个 SQL 线程来重放中继日志中的事件。</p><p>不过值得高兴的是，5.7 版本已经支持从库的并行复制了。基于二进制日志的并行复制，是在日志内容中新增了 last_committed 和 sequence_number，分别 表示事务提交的时间和上次事务提交的编号。如果事务具有相同的时间，表示这些事务是在一组内，可以进行并行回放。</p><h3 id="2-复制的原理"><a href="#2-复制的原理" class="headerlink" title="2. 复制的原理"></a>2. 复制的原理</h3><p>我们已经了解了复制的一些基本概念，接下来我们要更深入的了解复制，看看复制究竟是如何工作的，有哪些优缺点。</p><h4 id="2-1-基于语句的复制"><a href="#2-1-基于语句的复制" class="headerlink" title="2.1 基于语句的复制"></a>2.1 基于语句的复制</h4><p>在 Mysql 5.0 及之前的版本中只支持基于语句的复制（也称为逻辑复制）。基于语句的复制模式，<strong>主库会记录那些造成数据更改的 SQL 语句，当备库读取并重放这些事件时，实际上只是把主库执行过的 SQL 再执行一遍</strong>。这种方式既有优点，也有缺点。</p><p>优点是：</p><ol><li>实现简单。理论上来说，只要简单地记录和执行 SQL 语句，就能够让主备保持同步。</li><li>二进制日志不会对带宽产生较大影响。二进制日志里的事件更加紧凑，占用带宽较小。</li></ol><p>但事实上，基于语句的方式可能并不如其看起来那么便利，其缺点是：</p><ol><li><strong>主库上的数据除了执行的语句外，可能还依赖其他因素</strong>。当主库使用 CURRENT_USER() 函数的语句，存储过程和触发器在使用基于语句的复制模式时就可能会出现问题。</li></ol><h4 id="2-2-基于行的复制"><a href="#2-2-基于行的复制" class="headerlink" title="2.2 基于行的复制"></a>2.2 基于行的复制</h4><p>Mysql 5.1 开始支持基于行的复制。这种方式会将实际数据记录在二进制日志中。同样的，它也有其自身的优缺点。</p><p>它的优点是<strong>可以更加准确的复制数据</strong>，而缺点，则是可能造成较大的开销。比如一个工资表中有一万个用户，我们把每个用户的工资+1000，那么基于行的复制则要复制一万行的内容，由此造成的开销比较大，而基于语句的复制仅仅一条语句就可以了。</p><p><strong>由于没有哪种模式是对所有情况都是完美的，Mysql 就使复制模式可以动态切换</strong>。默认情况下使用的是基于语句的复制方式，但如果发现语句无法被正确地复制，就切换到基于行的复制模式。还可以根据需要来设置会话级别的变量 binlog_format，控制二进制日志格式。</p><h4 id="2-3-复制文件解读"><a href="#2-3-复制文件解读" class="headerlink" title="2.3 复制文件解读"></a>2.3 复制文件解读</h4><p>复制过程中会使用到一些文件。前面已经介绍了<strong>二进制日志文件</strong>和<strong>中继日志文件</strong>，除此之外，还有其他的文件会被用到。</p><ol><li><em>mysql-bin.index</em>：当在服务器上开启二进制日志时，同时会生成一个和二进制日志同名，但以 .index 作为后缀的文件，该文件用于记录磁盘上的二进制日志文件。这里的 index 并不是表的索引，而是说这个文件的每一行包含了二进制文件的文件名。Mysql 依赖这个文件识别二进制日志文件。</li><li><em>mysql-relay-bin-index</em>：中继日志的索引文件，和 mysql-bin.index 的作用类似。</li><li><em>master.info</em>：保存备库连接主库所需要的信息文件。格式为纯文本（每行一个值），不同的 Mysql 版本，记录的信息也可能不太。此文件不能删除，否则备库再重启后不能连接主库。这个文件以文本的方式记录了复制用户的密码，所以要注意此文件的权限控制。</li><li><em>relay-log.info</em>：记录当前备库复制的二进制日志和中继日志位置文件。</li></ol><p>使用这些文件来记录 Mysql 复制和日志状态是一种非常粗糙的方式。更不幸的是，它们不是同步写的。如果服务器断电并且文件数据没有被刷新到磁盘，在重启服务器后，文件中记录的数据可能是错误。不过好在这些问题以及在 5.5 版本里做了改进。</p><h4 id="2-4-发送复制事件到其它备库"><a href="#2-4-发送复制事件到其它备库" class="headerlink" title="2.4 发送复制事件到其它备库"></a>2.4 发送复制事件到其它备库</h4><p><strong>log_slave_update 选项可以让备库编程其它服务器的主库</strong>。在设置该选项后，Mysql 会将其执行过的事件记录到它自己的二进制日志中。这样它的备库就可以从其日志中检索并执行事件。下图阐述了这一过程：<br><img src="https://img2018.cnblogs.com/blog/861679/201903/861679-20190331175952473-460151901.png" alt="将复制时间传递到更多的备库"></p><p>在这种场景下，主库将数据更新事件写入二进制日志，第一个备库提取并执行这个事件。这个时候一个事件的生命周期应该已经结束了。但由于设置了 log_slave_updates，备库会将这个事件写到它自己的二进制日志中。这样第二个备库就可以从第一个备库中，将事件提取到它的中继日志中并执行。</p><p>这意味着作为源服务器的主库可以将其数据变化传递给没有与其直接相连的备库上。默认情况下，这个选项是被打开的，这样在连接到备库时就不需要重启服务器。</p><p>当第一个备库把自主库获得的事件写入到其它二进制日志中时，这个事件在备库二进制日志中的位置与其主库二进制日志中的位置几乎肯定是不相同的，可能在不同的日志文件或文件内不同的位置。这意味着你不能假定所有拥有同一逻辑复制点的服务器拥有相同的日志坐标。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ol><li>复制功能是 MySQL 高扩展性的基础，常见的读写分离就使用了复制。</li><li>复制使用了三个线程。master 的日志线程，将事件写入 binlog，slave 的 IO 线程获取 binlog，并将其写入 relaylog，SQL 线程重放 relaylog 日志。</li><li>复制有基于语句复制和基于行的复制。</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
          <category> 复制 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 复制概述 </tag>
            
            <tag> 复制原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 终章 - GTP 协议：复杂的移动网络</title>
      <link href="/1/wangluoxieyi/ck0669dww0072agaa8oj0fp0h/"/>
      <url>/1/wangluoxieyi/ck0669dww0072agaa8oj0fp0h/</url>
      
        <content type="html"><![CDATA[<p>前面都是讲电脑上网的情景，今天我们就来认识下使用最多的移动网络上网场景。</p><h3 id="移动网络的发展历程"><a href="#移动网络的发展历程" class="headerlink" title="移动网络的发展历程"></a>移动网络的发展历程</h3><p>你一定知道手机上网有 2G、3G、4G 的说法，究竟这都是什么意思呢？有一个通俗的说法就是：用 2G 看 txt，用 3G 看 jpg，用 4G 看 avi。</p><h4 id="2G-网络"><a href="#2G-网络" class="headerlink" title="2G 网络"></a>2G 网络</h4><p>手机本来是用来打电话的，不是用来上网的，所以原来在 2G 时代，上网使用的不是 IP 网络，而是电话网络，走模拟信号，专业名称为公共交换电话网（PSTN，Public Switched Telephone Network）。</p><p>那手机不连网线，也不连电话线，它是怎么上网的呢？</p><p>手机是通过<strong>收发无线信号来通信的</strong>，专业名称是 Mobile Station，简称 MS，需要嵌入 SIM。手机是客户端，而无线信号的服务端，就是基站子系统（BSS，Base Station SubsystemBSS）。至于什么是基站，你可以回想一下，你在爬山的时候，是不是看到过信号塔？我们平时城市里面的基站比较隐蔽，不容易看到，所以只有在山里才会注意到。正是这个信号塔，通过无线信号，让你的手机可以进行通信。</p><p>但是你要知道一点，<strong>无论无线通信如何无线，最终还是要连接到有线的网络里</strong>。</p><p>因而，基站子系统分两部分，一部分对外提供无线通信，叫作基站收发信台（BTS，Base Transceiver Station），另一部分对内连接有线网络，叫作基站控制器（BSC，Base Station Controller）。基站收发信台通过无线收到数据后，转发给基站控制器。</p><p>这部分属于无线的部分，统称为无线接入网（RAN，Radio Access Network）。</p><p>基站控制器通过有线网络，连接到提供手机业务的运营商的数据中心，这部分称为核心网（CN，Core Network）。核心网还没有真的进入互联网，这部分还是主要提供手机业务，是手机业务的有线部分。</p><p>首先接待基站来的数据的是移动业务交换中心（MSC，Mobile Service Switching Center），它是进入核心网的入口，但是它不会让你直接连接到互联网上。</p><p>因为在让你的手机真正进入互联网之前，提供手机业务的运营商，需要认证是不是合法的手机接入。别你自己造了一张手机卡，就连接上来。鉴权中心（AUC，Authentication Center）和设备识别寄存器（EIR，Equipment Identity Register）主要是负责安全性的。</p><p>另外，需要看你是本地的号，还是外地的号，这个牵扯到计费的问题，异地收费还是很贵的。访问位置寄存器（VLR，Visit Location Register）是看你目前在的地方，归属位置寄存器（HLR，Home Location Register）是看你的号码归属地。</p><p>当你的手机卡既合法又有钱的时候，才允许你上网，这个时候需要一个网关，连接核心网和真正的互联网。网关移动交换中心（GMSC ，Gateway Mobile Switching Center）就是干这个的，然后是真正的互连网。在 2G 时代，还是电话网络 PSTN。</p><p>数据中心里面的这些模块统称为网络子系统（NSS，Network and Switching Subsystem）。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190121124743167-76712017.png" alt=""></p><p>因而 2G 时代的上网如图所示，我们总结一下，有这几个核心点：</p><ul><li><strong>手机通过无线信号连接基站；</strong></li><li><strong>基站一面朝前接无线，一面朝后接核心网；</strong></li><li><strong>核心网一面朝前接到基站请求，一是判断你是否合法，二是判断你是不是本地号，还有没有钱，一面通过网关连接电话网络。</strong></li></ul><h4 id="2-5G-网络"><a href="#2-5G-网络" class="headerlink" title="2.5G 网络"></a>2.5G 网络</h4><p>后来从 2G 到了 2.5G，也即在原来电路交换的基础上，加入了分组交换业务，支持 Packet 的转发，从而支持 IP 网络。</p><p>在上述网络的基础上，基站一面朝前接无线，一面朝后接核心网。在朝后的组件中，多了一个分组控制单元（PCU，Packet Control Unit），用以提供分组交换通道。</p><p>在核心网里面，有个朝前的接待员（SGSN，Service GPRS Supported Node）和朝后连接 IP 网络的网关型 GPRS 支持节点（GGSN，Gateway GPRS Supported Node）。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190121124723117-858677423.png" alt=""></p><h4 id="3G-网络"><a href="#3G-网络" class="headerlink" title="3G 网络"></a>3G 网络</h4><p>到了 3G 时代，主要是无线通信技术有了改进，大大增加了无线的带宽。</p><p>以 W-CDMA 为例，理论最高 2M 的下行速度，因而基站改变了，一面朝外的是 Node  B，一面朝内连接核心网的是无线网络控制器（RNC，Radio Network Controller）。核心网以及连接的 IP 网络没有什么变化。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190121124700736-1331211206.png" alt=""></p><h4 id="4G-网络"><a href="#4G-网络" class="headerlink" title="4G 网络"></a>4G 网络</h4><p>然后就到了今天的 4G 网络，基站为 eNodeB，包含了原来 Node  B 和 RNC 的功能，下行速度向百兆级别迈进。另外，核心网实现了控制面和数据面的分离，这个怎么理解呢？</p><p>在前面的核心网里面，有接待员 MSC 或者 SGSN，你会发现检查是否合法是它负责，转发数据也是它负责，也即控制面和数据面是合二为一的，这样灵活性比较差，因为控制面主要是指令，多是小包，往往需要高的及时性；数据面主要是流量，多是大包，往往需要吞吐量。</p><p>于是有了下面这个架构：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190121124642944-1326420607.png" alt=""></p><p>HSS 用于存储用户签约信息的数据库，其实就是你这个号码归属地是哪里的，以及一些认证信息。</p><p>MME 是核心控制网元，是控制面的核心，当手机通过 eNodeB 连上的时候，MME 会根据 HSS 的信息，判断你是否合法。如果允许连上来，MME 不负责具体的数据的流量，而是 MME 会选择数据面的 SGW 和 PGW，然后告诉 eNodeB，我允许你连上来了，你连接它们吧。</p><p>于是手机直接通过 eNodeB 连接 SGW，连上核心网，SGW 相当于数据面的接待员，并通过 PGW 连到 IP 网络。PGW 就是出口网关。在出口网关，有一个组件 PCRF，称为策略和计费控制单元，用来控制上网策略和流量的计费。</p><h3 id="4G-网络协议解析"><a href="#4G-网络协议解析" class="headerlink" title="4G 网络协议解析"></a>4G 网络协议解析</h3><p>我们来仔细看一下 4G 网络的协议，真的非常复杂。我们将几个关键组件放大来看。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190121124619702-558957975.png" alt=""></p><h4 id="控制面协议"><a href="#控制面协议" class="headerlink" title="控制面协议"></a>控制面协议</h4><p>其中虚线部分是控制面的协议。当一个手机想上网的时候，先要连接 eNodeB，并通过 S1-MME 接口，请求 MME 对这个手机进行认证和鉴权。S1-MME 协议栈如下图所示。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190121124602151-1542706959.png" alt=""></p><p>UE 就是你的手机，eNodeB 还是两面派，朝前对接无线网络，朝后对接核心网络，在控制面对接的是 MME。</p><p>eNodeB 和 MME 之间的连接就是很正常的 IP 网络，但是这里面在 IP 层之上，却既不是 TCP，也不是 UDP，而是 SCTP。这也是传输层的协议，也是面向连接的，但是更加适合移动网络。 它继承了 TCP 较为完善的拥塞控制并改进 TCP 的一些不足之处。</p><p>SCTP 的第一个特点是<strong>多宿主</strong>。一台机器可以有多个网卡，而对于 TCP 连接来讲，虽然服务端可以监听 0.0.0.0，也就是从哪个网卡来的连接都能接受，但是一旦建立了连接，就建立了四元组，也就选定了某个网卡。</p><p>SCTP 引入了联合（association）的概念，将多个接口、多条路径放到一个联合中来。当检测到一条路径失效时，协议就会通过另外一条路径来发送通信数据。应用程序甚至都不必知道发生了故障、恢复，从而提供更高的可用性和可靠性。</p><p>SCTP 的第二个特点是<strong>将一个联合分成多个流</strong>。一个联合中的所有流都是独立的，但均与该联合相关。每个流都给定了一个流编号，它被编码到 SCTP 报文中，通过联合在网络上传送。在 TCP 的机制中，由于强制顺序，导致前一个不到达，后一个就得等待，SCTP 的多个流不会相互阻塞。</p><p>SCTP 的第三个特点是<strong>四次握手，防止 SYN 攻击</strong>。在 TCP 中是三次握手，当服务端收到客户的 SYN 之后，返回一个 SYN-ACK 之前，就建立数据结构，并记录下状态，等待客户端发送 ACK 的 ACK。当恶意客户端使用虚假的源地址来伪造大量 SYN 报文时，服务端需要分配大量的资源，最终耗尽资源，无法处理新的请求。</p><p>SCTP 可以通过四次握手引入 Cookie 的概念，来有效地防止这种攻击的产生。在 SCTP 中，客户机使用一个 INIT 报文发起一个连接。服务器使用一个 INIT-ACK 报文进行响应，其中就包括了 Cookie。然后客户端就使用一个 COOKIE-ECHO 报文进行响应，其中包含了服务器所发送的 Cookie。这个时候，服务器为这个连接分配资源，并通过向客户机发送一个 COOKIE-ACK 报文对其进行响应。</p><p>SCTP 的第四个特点是<strong>将消息分帧</strong>。TCP 是面向流的，也即发送的数据没头没尾，没有明显的界限。这对于发送数据没有问题，但是对于发送一个个消息类型的数据，就不太方便。有可能客户端写入 10 个字节，然后再写入 20 个字节。服务端不是读出 10 个字节的一个消息，再读出 20 个字节的一个消息，而有可能读入 25 个字节，再读入 5 个字节，需要业务层去组合成消息。</p><p>SCTP 借鉴了 UDP 的机制，在数据传输中提供了消息分帧功能。当一端对一个套接字执行写操作时，可确保对等端读出的数据大小与此相同。</p><p>SCTP 的第五个特点是<strong>断开连接是三次挥手</strong>。在 TCP 里面，断开连接是四次挥手，允许另一端处于半关闭的状态。SCTP 选择放弃这种状态，当一端关闭自己的套接字时，对等的两端全部需要关闭，将来任何一端都不允许再进行数据的移动了。</p><p>当 MME 通过认证鉴权，同意这个手机上网的时候，需要建立一个数据面的数据通路。建立通路的过程还是控制面的事情，因而使用的是控制面的协议 GTP-C。</p><p>建设的数据通路分两段路，其实是两个隧道。一段是从 eNodeB 到 SGW，这个数据通路由 MME 通过 S1-MME 协议告诉 eNodeB，它是隧道的一端，通过 S11 告诉 SGW，它是隧道的另一端。第二端是从 SGW 到 PGW，SGW 通过 S11 协议知道自己是其中一端，并主动通过 S5 协议，告诉 PGW 它是隧道的另一端。</p><p>GTP-C 协议是基于 UDP 的，这是UDP 的 “城会玩” 中的一个例子。如果看 GTP 头，我们可以看到，这里面有隧道的 ID，还有序列号。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190121124538192-1836844053.png" alt=""></p><p>通过序列号，不用 TCP，GTP-C 自己就可以实现可靠性，为每个输出信令消息分配一个依次递增的序列号，以确保信令消息的按序传递，并便于检测重复包。对于每个输出信令消息启动定时器，在定时器超时前未接收到响应消息则进行重发。</p><h4 id="数据面协议"><a href="#数据面协议" class="headerlink" title="数据面协议"></a>数据面协议</h4><p>当两个隧道都打通，接在一起的时候，PGW 会给手机分配一个 IP 地址，这个 IP 地址是隧道内部的 IP 地址，可以类比为 IPsec 协议里面的 IP 地址。这个 IP 地址是归手机运营商管理的。然后，手机可以使用这个 IP 地址，连接 eNodeB，从 eNodeB 经过 S1-U 协议，通过第一段隧道到达 SGW，再从 SGW 经过 S8 协议，通过第二段隧道到达 PGW，然后通过 PGW 连接到互联网。</p><p>数据面的协议都是通过 GTP-U，如图所示：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190121124508851-499849702.png" alt=""></p><p>手机每发出的一个包，都由 GTP-U 隧道协议封装起来，格式如下：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190121124444069-414199298.png" alt=""></p><p>和 IPsec 协议很类似，分为乘客协议、隧道协议、承载协议。其中乘客协议是手机发出来的包，IP 是手机的 IP，隧道协议里面有隧道 ID，不同的手机上线会建立不同的隧道，因而需要隧道 ID 来标识。承载协议的 IP 地址是 SGW 和 PGW 的 IP 地址。</p><h4 id="手机上网流程"><a href="#手机上网流程" class="headerlink" title="手机上网流程"></a>手机上网流程</h4><p>接下来，我们来看一个手机开机之后上网的流程，这个过程称为<strong>Attach</strong>。可以看出来，移动网络还是很复杂的。因为这个过程要建立很多的隧道，分配很多的隧道 ID，所以我画了一个图来详细说明这个过程。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190121124429063-1804398290.png" alt=""></p><ol><li>手机开机以后，在附近寻找基站 eNodeB，找到后给 eNodeB 发送 Attach Request，说“我来啦，我要上网”。</li><li>eNodeB 将请求发给 MME，说“有个手机要上网”。</li><li>MME 去请求手机，一是认证，二是鉴权，还会请求 HSS 看看有没有钱，看看是在哪里上网。</li><li>当 MME 通过了手机的认证之后，开始分配隧道，先告诉 SGW，说要创建一个会话（Create Session）。在这里面，会给 SGW 分配一个隧道 ID  t1，并且请求 SGW 给自己也分配一个隧道 ID。</li><li>SGW 转头向 PGW 请求建立一个会话，为 PGW 的控制面分配一个隧道 ID  t2，也给 PGW 的数据面分配一个隧道 ID  t3，并且请求 PGW 给自己的控制面和数据面分配隧道 ID。</li><li>PGW 回复 SGW 说“创建会话成功”，使用自己的控制面隧道 ID t2，回复里面携带着给 SGW 控制面分配的隧道 ID  t4 和控制面的隧道 ID  t5，至此 SGW 和 PGW 直接的隧道建设完成。双方请求对方，都要带着对方给自己分配的隧道 ID，从而标志是这个手机的请求。</li><li>接下来 SGW 回复 MME 说“创建会话成功”，使用自己的隧道 ID  t1 访问 MME，回复里面有给 MME 分配隧道 ID  t6，也有 SGW 给 eNodeB 分配的隧道 ID  t7。</li><li>当 MME 发现后面的隧道都建设成功之后，就告诉 eNodeB，“后面的隧道已经建设完毕，SGW 给你分配的隧道 ID 是 t7，你可以开始连上来了，但是你也要给 SGW 分配一个隧道 ID”。</li><li>eNodeB 告诉 MME 自己给 SGW 分配一个隧道，ID 为 t8。</li><li>MME 将 eNodeB 给 SGW 分配的隧道 ID  t8 告知 SGW，从而前面的隧道也建设完毕。</li></ol><p>这样，手机就可以通过建立的隧道成功上网了。</p><h3 id="异地上网问题"><a href="#异地上网问题" class="headerlink" title="异地上网问题"></a>异地上网问题</h3><p>接下来我们考虑异地上网的事情。</p><p>为什么要分 SGW 和 PGW 呢，一个 GW 不可以吗？SGW 是你本地的运营商的设备，而 PGW 是你所属的运营商的设备。</p><p>如果你在巴塞罗那，一下飞机，手机开机，周围搜寻到的肯定是巴塞罗那的 eNodeB。通过 MME 去查寻国内运营商的 HSS，看你是否合法，是否还有钱。如果允许上网，你的手机和巴塞罗那的 SGW 会建立一个隧道，然后巴塞罗那的 SGW 和国内运营商的 PGW 建立一个隧道，然后通过国内运营商的 PGW 上网。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190121124405227-526682433.png" alt=""></p><p>这样判断你是否能上网的在国内运营商的 HSS，控制你上网策略的是国内运营商的 PCRF，给手机分配的 IP 地址也是国内运营商的 PGW 负责的，给手机分配的 IP 地址也是国内运营商里统计的。运营商由于是在 PGW 里面统计的，这样你的上网流量全部通过国内运营商即可，只不过巴塞罗那运营商也要和国内运营商进行流量结算。</p><p>由于你的上网策略是由国内运营商在 PCRF 中控制的，因而你还是上不了脸书。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>移动网络的发展历程从 2G 到 3G，再到 4G，逐渐从打电话的功能为主，向上网的功能为主转变；</li><li>请记住 4G 网络的结构，有 eNodeB、MME、SGW、PGW 等，分控制面协议和数据面协议，你可以对照着结构，试着说出手机上网的流程；</li><li>即便你在国外的运营商下上网，也是要通过国内运营商控制的，因而也上不了脸书。</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 移动网络 </tag>
            
            <tag> GTP协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 22 - RPC 协议（下）- 二进制类 RPC 协议</title>
      <link href="/1/wangluoxieyi/ck0669dpv002lagaaig94dr88/"/>
      <url>/1/wangluoxieyi/ck0669dpv002lagaaig94dr88/</url>
      
        <content type="html"><![CDATA[<p>前面我们认识了两个常用文本类的 RPC 协议，对于陌生人之间的沟通，用 NBA、CBA 这样的缩略语，会使得协议约定非常不方便。</p><p>在讲 CDN 和 DNS 的时候，我们讲过接入层的设计，对于静态资源或者动态资源静态化的部分都可以做缓存。但是对于下单、支付等交易场景，还是需要调用 API。</p><p>对于微服务的架构，API 需要一个 API 网关统一的管理。API 网关有多种实现方式，用 Nginx 或者 OpenResty 结合 Lua 脚本是常用的方式。在上一节讲过的 Spring Cloud 体系中，有个组件 Zuul 也是干这个的。</p><h3 id="数据中心内部是如何相互调用的？"><a href="#数据中心内部是如何相互调用的？" class="headerlink" title="数据中心内部是如何相互调用的？"></a>数据中心内部是如何相互调用的？</h3><p>API 网关用来管理 API，但是 API 的实现一般在一个叫作<strong>Controller 层</strong>的地方。这一层对外提供 API。由于是让陌生人访问的，我们能看到目前业界主流的，基本都是 RESTful 的 API，是面向大规模互联网应用的。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190115200503502-128248181.png" alt=""></p><p>在 Controller 之内，就是咱们互联网应用的业务逻辑实现。上节讲 RESTful 的时候，说过业务逻辑的实现最好是无状态的，从而可以横向扩展，但是资源的状态还需要服务端去维护。资源的状态不应该维护在业务逻辑层，而是在最底层的持久化层，一般会使用分布式数据库和 ElasticSearch。</p><p>这些服务端的状态，例如订单、库存、商品等，都是重中之重，都需要持久化到硬盘上，数据不能丢，但是由于硬盘读写性能差，因而持久化层往往吞吐量不能达到互联网应用要求的吞吐量，因而前面要有一层缓存层，使用 Redis 或者 memcached 将请求拦截一道，不能让所有的请求都进入数据库“中军大营”。</p><p>缓存和持久化层之上一般是<strong>基础服务层</strong>，这里面提供一些原子化的接口。例如，对于用户、商品、订单、库存的增删查改，将缓存和数据库对再上层的业务逻辑屏蔽一道。有了这一层，上层业务逻辑看到的都是接口，而不会调用数据库和缓存。因而对于缓存层的扩容，数据库的分库分表，所有的改变，都截止到这一层，这样有利于将来对于缓存和数据库的运维。</p><p>再往上就是<strong>组合层</strong>。因为基础服务层只是提供简单的接口，实现简单的业务逻辑，而复杂的业务逻辑，比如下单，要扣优惠券，扣减库存等，就要在组合服务层实现。</p><p>这样，Controller 层、组合服务层、基础服务层就会相互调用，这个调用是在数据中心内部的，量也会比较大，还是使用 RPC 的机制实现的。</p><p>由于服务比较多，需要一个单独的注册中心来做服务发现。服务提供方会将自己提供哪些服务注册到注册中心中去，同时服务消费方订阅这个服务，从而可以对这个服务进行调用。</p><p>调用的时候有一个问题，这里的 RPC 调用，应该用二进制还是文本类？其实文本的最大问题是，占用字节数目比较多。比如数字 123，其实本来二进制 8 位就够了，但是如果变成文本，就成了字符串 123。如果是 UTF-8 编码的话，就是三个字节；如果是 UTF-16，就是六个字节。同样的信息，要多费好多的空间，传输起来也更加占带宽，时延也高。</p><p>因而对于数据中心内部的相互调用，很多公司选型的时候，还是希望采用更加省空间和带宽的二进制的方案。</p><p>这里一个著名的例子就是 Dubbo 服务化框架二进制的 RPC 方式。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190115200525264-2092504280.png" alt=""></p><p>Dubbo 会在客户端的本地启动一个 Proxy，其实就是客户端的 Stub，对于远程的调用都通过这个 Stub 进行封装。</p><p>接下来，Dubbo 会从注册中心获取服务端的列表，根据路由规则和负载均衡规则，在多个服务端中选择一个最合适的服务端进行调用。</p><p>调用服务端的时候，首先要进行编码和序列化，形成 Dubbo 头和序列化的方法和参数。将编码好的数据，交给网络客户端进行发送，网络服务端收到消息后，进行解码。然后将任务分发给某个线程进行处理，在线程中会调用服务端的代码逻辑，然后返回结果。</p><p>这个过程和经典的 RPC 模式何其相似啊！</p><h3 id="如何解决协议约定问题？"><a href="#如何解决协议约定问题？" class="headerlink" title="如何解决协议约定问题？"></a>如何解决协议约定问题？</h3><p>接下来我们还是来看 RPC 的三大问题，其中注册发现问题已经通过注册中心解决了。我们下面就来看协议约定问题。</p><p>Dubbo 中默认的 RPC 协议是 Hessian2。为了保证传输的效率，Hessian2 将远程调用序列化为二进制进行传输，并且可以进行一定的压缩。这个时候你可能会疑惑，同为二进制的序列化协议，Hessian2 和前面的二进制的 RPC 有什么区别呢？这不绕了一圈又回来了吗？</p><p>Hessian2 是解决了一些问题的。例如，原来要定义一个协议文件，然后通过这个文件生成客户端和服务端的 Stub，才能进行相互调用，这样使得修改就会不方便。Hessian2 不需要定义这个协议文件，而是自描述的。什么是自描述呢？</p><p>所谓自描述就是，关于调用哪个函数，参数是什么，另一方不需要拿到某个协议文件、拿到二进制，靠它本身根据 Hessian2 的规则，就能解析出来。</p><p>原来有协议文件的场景，有点儿像两个人事先约定好，0 表示方法 add，然后后面会传两个数。服务端把两个数加起来，这样一方发送 012，另一方知道是将 1 和 2 加起来，但是不知道协议文件的，当它收到 012 的时候，完全不知道代表什么意思。</p><p>而自描述的场景，就像两个人说的每句话都带前因后果。例如，传递的是“函数：add，第一个参数 1，第二个参数 2”。这样无论谁拿到这个表述，都知道是什么意思。但是只不过都是以二进制的形式编码的。这其实相当于综合了 XML 和二进制共同优势的一个协议。</p><p>Hessian2 是如何做到这一点的呢？这就需要去看 Hessian2 的序列化的<a href="http://hessian.caucho.com/doc/hessian-serialization.html" target="_blank" rel="noopener">语法描述文件</a>。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190115200332870-254084470.png" alt=""></p><p>看起来很复杂，编译原理里面是有这样的语法规则的。</p><p>我们从 Top 看起，下一层是 value，直到形成一棵树。这里面的有个思想，为了防止歧义，每一个类型的起始数字都设置成为独一无二的。这样，解析的时候，看到这个数字，就知道后面跟的是什么了。</p><p>这里还是以加法为例子，“add(2,3)”被序列化之后是什么样的呢？</p><pre><code>H x02 x00     # Hessian 2.0C          # RPC call x03 add     # method "add" x92        # two arguments x92        # 2 - argument 1 x93        # 3 - argument 2</code></pre><ul><li>H 开头，表示使用的协议是 Hession，H 的二进制是 0x48</li><li>C 开头，表示这是一个 RPC 调用</li><li>0x03，表示方法名是三个字符</li><li>0x92，表示有两个参数。其实这里存的应该是 2，之所以加上 0x90，就是为了防止歧义，表示这里一定是一个 int</li><li>第一个参数是 2，编码为 0x92，第二个参数是 3，编码为 0x93</li></ul><p>这个就叫作<strong>自描述</strong>。</p><p>另外，Hessian2 是面向对象的，可以传输一个对象。</p><pre><code>class Car { String color; String model;}out.writeObject(new Car("red", "corvette"));out.writeObject(new Car("green", "civic"));---C            # object definition (#0) x0b example.Car    # type is example.Car x92          # two fields x05 color       # color field name x05 model       # model field nameO            # object def (long form) x90          # object definition #0 x03 red        # color field value x08 corvette      # model field valuex60           # object def #0 (short form) x05 green       # color field value x05 civic       # model field value</code></pre><p>首先，定义这个类。对于类型的定义也传过去，因而也是自描述的。类名为 example.Car，字符长 11 位，因而前面长度为 0x0b。有两个成员变量，一个是 color，一个是 model，字符长 5 位，因而前面长度 0x05,。</p><p>然后，传输的对象引用这个类。由于类定义在位置 0，因而对象会指向这个位置 0，编码为 0x90。后面 red 和 corvette 是两个成员变量的值，字符长分别为 3 和 8。</p><p>接着又传输一个属于相同类的对象。这时候就不保存对于类的引用了，只保存一个 0x60，表示同上就可以了。</p><p>可以看出，Hessian2 真的是能压缩尽量压缩，多一个 Byte 都不传。</p><h3 id="如何解决-RPC-传输问题？"><a href="#如何解决-RPC-传输问题？" class="headerlink" title="如何解决 RPC 传输问题？"></a>如何解决 RPC 传输问题？</h3><p>接下来，我们再来看 Dubbo 的 RPC 传输问题。前面我们也说了，基于 Socket 实现一个高性能的服务端，是很复杂的一件事情，在 Dubbo 里面，使用了 Netty 的网络传输框架。</p><p>Netty 是一个非阻塞的基于事件的网络传输框架，在服务端启动的时候，会监听一个端口，并注册以下的事件。</p><ul><li><strong>连接事件</strong>：当收到客户端的连接事件时，会调用 void connected(Channel channel) 方法</li><li>当<strong>可写事件</strong>触发时，会调用 void sent(Channel channel, Object message)，服务端向客户端返回响应数据</li><li>当<strong>可读事件</strong>触发时，会调用 void received(Channel channel, Object message) ，服务端在收到客户端的请求数据</li><li>当<strong>发生异常</strong>时，会调用 void caught(Channel channel, Throwable exception)</li></ul><p>当事件触发之后，服务端在这些函数中的逻辑，可以选择直接在这个函数里面进行操作，还是将请求分发到线程池去处理。一般异步的数据读写都需要另外的线程池参与，在线程池中会调用真正的服务端业务代码逻辑，返回结果。</p><p>Hessian2 是 Dubbo 默认的 RPC 序列化方式，当然还有其他选择。例如，Dubbox 从 Spark 那里借鉴 Kryo，实现高性能的序列化。</p><p>到这里，我们说了数据中心里面的相互调用。为了高性能，大家都愿意用二进制，但是为什么后期 Spring Cloud 又兴起了呢？这是因为，并发量越来越大，已经到了微服务的阶段。同原来的 SOA 不同，微服务粒度更细，模块之间的关系更加复杂。</p><p>在上面的架构中，如果使用二进制的方式进行序列化，虽然不用协议文件来生成 Stub，但是对于接口的定义，以及传的对象 DTO，还是需要共享 JAR。因为只有客户端和服务端都有这个 JAR，才能成功地序列化和反序列化。</p><p>但当关系复杂的时候，JAR 的依赖也变得异常复杂，难以维护，而且如果在 DTO 里加一个字段，双方的 JAR 没有匹配好，也会导致序列化不成功，而且还有可能循环依赖。这个时候，一般有两种选择。</p><p>第一种，建立严格的项目管理流程。</p><ul><li>不允许循环调用，不允许跨层调用，只准上层调用下层，不允许下层调用上层</li><li>接口要保持兼容性，不兼容的接口新添加而非改原来的，当接口通过监控，发现不用的时候，再下掉</li><li>升级的时候，先升级服务提供端，再升级服务消费端。</li></ul><p>第二种，改用 RESTful 的方式。</p><ul><li>使用 Spring Cloud，消费端和提供端不用共享 JAR，各声明各的，只要能变成 JSON 就行，而且 JSON 也是比较灵活的</li><li>使用 RESTful 的方式，性能会降低，所以需要通过横向扩展来抵消单机的性能损耗</li></ul><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>RESTful API 对于接入层和 Controller 层之外的调用，已基本形成事实标准，但是随着内部服务之间的调用越来越多，性能也越来越重要，于是 Dubbo 的 RPC 框架有了用武之地</li><li>Dubbo 通过注册中心解决服务发现问题，通过 Hessian2 序列化解决协议约定的问题，通过 Netty 解决网络传输的问题</li><li>在更加复杂的微服务场景下，Spring Cloud 的 RESTful 方式在内部调用也会被考虑，主要是 JAR 包的依赖和管理问题</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RPC协议 </tag>
            
            <tag> 二进制RPC协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 21 - RPC 协议（中）- 基于 JSON 的 RESTful 接口协议</title>
      <link href="/1/wangluoxieyi/ck0669dp8002eagaacc5ly2f0/"/>
      <url>/1/wangluoxieyi/ck0669dp8002eagaacc5ly2f0/</url>
      
        <content type="html"><![CDATA[<p>上一节我们了解了基于 XML 的 SOAP 协议，SOAP 的 S 是啥意思来着？是 Simple，但是好像一点儿都不简单啊！</p><h3 id="传输协议问题"><a href="#传输协议问题" class="headerlink" title="传输协议问题"></a>传输协议问题</h3><p>对于 SOAP 来讲，比如我创建一个订单，用 POST，在 XML 里面写明动作是 CreateOrder；删除一个订单，还是用 POST，在 XML 里面写明了动作是 DeleteOrder。其实创建订单完全可以使用 POST 动作，然后在 XML 里面放一个订单的信息就可以了，而删除用 DELETE 动作，然后在 XML 里面放一个订单的 ID 就可以了。</p><p>于是上面的那个 SOAP 就变成下面这个简单的模样。</p><pre><code>POST /purchaseOrder HTTP/1.1Host: www.cnblog.comContent-Type: application/xml; charset=utf-8Content-Length: nnn&lt;?xml version="1.0"?&gt; &lt;order&gt;     &lt;date&gt;2018-07-01&lt;/date&gt;      &lt;className&gt; 板栗焖鸡 &lt;/className&gt;       &lt;price&gt;58&lt;/price&gt;  &lt;/order&gt;</code></pre><p>而且 XML 的格式也可以改成另外一种简单的文本化的对象表示格式 JSON。</p><p>经常写 Web 应用的应该已经发现，这就是 RESTful 格式的 API 的样子。</p><h3 id="协议约定问题"><a href="#协议约定问题" class="headerlink" title="协议约定问题"></a>协议约定问题</h3><p>然而 RESTful 可不仅仅是指 API，而是一种架构风格，全称 Representational State Transfer，表述性状态转移，来自一篇重要的论文《架构风格与基于网络的软件架构设计》（Architectural Styles and the Design of Network-based Software Architectures）。</p><p>这篇文章从深层次，更加抽象地论证了一个互联网应用应该有的设计要点，而这些设计要点，成为后来我们能看到的所有高并发应用设计都必须要考虑的问题，再加上 REST API 比较简单直接，所以后来几乎成为互联网应用的标准接口。</p><p>因此，和 SOAP 不一样，REST 不是一种严格规定的标准，它其实是一种设计风格。如果按这种风格进行设计，RESTful 接口和 SOAP 接口都能做到，只不过后面的架构是 REST 倡导的，而 SOAP 相对比较关注前面的接口。</p><p>而且由于能够通过 WSDL 生成客户端的 Stub，因而 SOAP 常常被用于类似传统的 RPC 方式，也即调用远端和调用本地是一样的。</p><p>然而本地调用和远程跨网络调用毕竟不一样，这里的不一样还不仅仅是因为有网络而导致的客户端和服务端的分离，从而带来的网络性能问题。更重要的问题是，客户端和服务端谁来维护状态。所谓的状态就是对某个数据当前处理到什么程度了。</p><p>这里举几个例子，例如，我浏览到哪个目录了，我看到第几页了，我要买个东西，需要扣减一下库存，这些都是状态。本地调用其实没有人纠结这个问题，因为数据都在本地，谁处理都一样，而且一边处理了，另一边马上就能看到。</p><p>当有了 RPC 之后，我们本来期望对上层透明，就像上一节说的“远在天边，尽在眼前”。于是使用 RPC 的时候，对于状态的问题也没有太多的考虑。</p><p>就像 NFS 一样，客户端会告诉服务端，我要进入哪个目录，服务端必须要为某个客户端维护一个状态，就是当前这个客户端浏览到哪个目录了。例如，客户端输入 cd hello，服务端要在某个地方记住，上次浏览到 /root/liuchao 了，因而客户的这次输入，应该给它显示 /root/liuchao/hello 下面的文件列表。而如果有另一个客户端，同样输入 cd hello，服务端也在某个地方记住，上次浏览到 /var/lib，因而要给客户显示的是 /var/lib/hello。</p><p>不光 NFS，如果浏览翻页，我们经常要实现函数 next()，在一个列表中取下一页，但是这就需要服务端记住，客户端 A 上次浏览到 20～30 页了，那它调用 next()，应该显示 30～40 页，而客户端 B 上次浏览到 100～110 页了，调用 next() 应该显示 110～120 页。</p><p>上面的例子都是在 RPC 场景下，由服务端来维护状态，很多 SOAP 接口设计的时候，也常常按这种模式。这种模式原来没有问题，是因为客户端和服务端之间的比例没有失衡。因为一般不会同时有太多的客户端同时连上来，所以 NFS 还能把每个客户端的状态都记住。</p><p>公司内部使用的 ERP 系统，如果使用 SOAP 的方式实现，并且服务端为每个登录的用户维护浏览到报表那一页的状态，由于一个公司内部的人也不会太多，把 ERP 放在一个强大的物理机上，也能记得过来。</p><p>但是互联网场景下，客户端和服务端就彻底失衡了。你可以想象“双十一”，多少人同时来购物，作为服务端，它能记得过来吗？当然不可能，只好多个服务端同时提供服务，大家分担一下。但是这就存在一个问题，服务端怎么把自己记住的客户端状态告诉另一个服务端呢？或者说，你让我给你分担工作，你也要把工作的前因后果给我说清楚啊！</p><p>那服务端索性就要想了，既然这么多客户端，那大家就分分工吧。服务端就只记录资源的状态，例如文件的状态，报表的状态，库存的状态，而客户端自己维护自己的状态。比如，你访问到哪个目录了啊，报表的哪一页了啊，等等。</p><p>这样对于 API 也有影响，也就是说，当客户端维护了自己的状态，就不能这样调用服务端了。例如客户端说，我想访问当前目录下的 hello 路径。服务端说，我怎么知道你的当前路径。所以客户端要先看看自己当前路径是 /root/liuchao，然后告诉服务端说，我想访问 /root/liuchao/hello 路径。</p><p>再比如，客户端说我想访问下一页，服务端说，我怎么知道你当前访问到哪一页了。所以客户端要先看看自己访问到了 100～110 页，然后告诉服务器说，我想访问 110～120 页。</p><p>这就是服务端的无状态化。这样服务端就可以横向扩展了，一百个人一起服务，不用交接，每个人都能处理。</p><p>所谓的无状态，其实是服务端维护资源的状态，客户端维护会话的状态。对于服务端来讲，只有资源的状态改变了，客户端才调用 POST、PUT、DELETE 方法来找我；如果资源的状态没变，只是客户端的状态变了，就不用告诉我了，对于我来说都是统一的 GET。</p><p>虽然这只改进了 GET，但是已经带来了很大的进步。因为对于互联网应用，大多数是读多写少的。而且只要服务端的资源状态不变，就给了我们缓存的可能。例如可以将状态缓存到接入层，甚至缓存到 CDN 的边缘节点，这都是资源状态不变的好处。</p><p>按照这种思路，对于 API 的设计，就慢慢变成了以资源为核心，而非以过程为核心。也就是说，客户端只要告诉服务端你想让资源状态最终变成什么样就可以了，而不用告诉我过程，不用告诉我动作。</p><p>还是文件目录的例子。客户端应该访问哪个绝对路径，而非一个动作，我就要进入某个路径。再如，库存的调用，应该查看当前的库存数目，然后减去购买的数量，得到结果的库存数。这个时候应该设置为目标库存数（但是当前库存数要匹配），而非告知减去多少库存。</p><p>这种 API 的设计需要实现幂等，因为网络不稳定，就会经常出错，因而需要重试，但是一旦重试，就会存在幂等的问题，也就是同一个调用，多次调用的结果应该一样，不能一次支付调用，因为调用三次变成了支付三次。不能进入 cd a，做了三次，就变成了 cd a/a/a。也不能扣减库存，调用了三次，就扣减三次库存。</p><p>当然按照这种设计模式，无论 RESTful API 还是 SOAP API 都可以将架构实现成无状态的，面向资源的、幂等的、横向扩展的、可缓存的。</p><p>但是 SOAP 的 XML 正文中，是可以放任何动作的。例如 XML 里面可以写 &lt; ADD &gt;，&lt; MINUS &gt; 等。这就方便使用 SOAP 的人，将大量的动作放在 API 里面。</p><p>RESTful 没这么复杂，也没给客户提供这么多的可能性，正文里的 JSON 基本描述的就是资源的状态，没办法描述动作，而且能够出发的动作只有 CRUD，也即 POST、GET、PUT、DELETE，也就是对于状态的改变。</p><p>所以，从接口角度，就让你死了这条心。当然也有很多技巧的方法，在使用 RESTful API 的情况下，依然提供基于动作的有状态请求，这属于反模式了。</p><h3 id="服务发现问题"><a href="#服务发现问题" class="headerlink" title="服务发现问题"></a>服务发现问题</h3><p>对于 RESTful API 来讲，我们已经解决了传输协议的问题——基于 HTTP，协议约定问题——基于 JSON，最后要解决的是服务发现问题。</p><p>有个著名的基于 RESTful API 的跨系统调用框架叫 Spring  Cloud。在 Spring  Cloud 中有一个组件叫 Eureka。传说，阿基米德在洗澡时发现浮力原理，高兴得来不及穿上裤子，跑到街上大喊：“Eureka（我找到了）！”所以 Eureka 是用来实现注册中心的，负责维护注册的服务列表。</p><p>服务分服务提供方，它向 Eureka 做服务注册、续约和下线等操作，注册的主要数据包括服务名、机器 IP、端口号、域名等等。</p><p>另外一方是服务消费方，向 Eureka 获取服务提供方的注册信息。为了实现负载均衡和容错，服务提供方可以注册多个。</p><p>当消费方要调用服务的时候，会从注册中心读出多个服务来，那怎么调用呢？当然是 RESTful 方式了。</p><p>Spring Cloud 提供一个 RestTemplate 工具，用于将请求对象转换为 JSON，并发起 Rest 调用，RestTemplate 的调用也是分 POST、PUT、GET、  DELETE 的，当结果返回的时候，根据返回的 JSON 解析成对象。</p><p>通过这样封装，调用起来也很方便。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>SOAP 过于复杂，而且设计是面向动作的，因而往往因为架构问题导致并发量上不去;</li><li>RESTful 不仅仅是一个 API，而且是一种架构模式，主要面向资源，提供无状态服务，有利于横向扩展应对高并发。</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RPC协议 </tag>
            
            <tag> RESTFUL接口协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 20 - RPC 协议（上）- 基于XML的SOAP协议</title>
      <link href="/1/wangluoxieyi/ck0669dp3002bagaas2aayefj/"/>
      <url>/1/wangluoxieyi/ck0669dp3002bagaas2aayefj/</url>
      
        <content type="html"><![CDATA[<p>上一节我们了解 RPC 的经典模型和设计要点，并用最早期的 ONC RPC 为例子，详述了具体的实现。而时代在进步，ONC RPC 逐渐因为各种问题被替代，SOAP 协议就是替代者之一。</p><h3 id="ONC-RPC-存在的问题"><a href="#ONC-RPC-存在的问题" class="headerlink" title="ONC RPC 存在的问题"></a>ONC RPC 存在的问题</h3><p>ONC RPC 将客户端要发送的参数，以及服务端要发送的回复，都压缩为一个二进制串，这样固然能够解决双方的协议约定问题，但是存在一定的不方便。</p><p>首先，<strong>需要双方的压缩格式完全一致</strong>，一点都不能差。一旦有少许的差错，多一位，少一位或者错一位，都可能造成无法解压缩。当然，我们可以用传输层的可靠性以及加入校验值等方式，来减少传输过程中的差错。</p><p>其次，<strong>协议修改不灵活</strong>。如果不是传输过程中造成的差错，而是客户端因为业务逻辑的改变，添加或者删除了字段，或者服务端添加或者删除了字段，而双方没有及时通知，或者线上系统没有及时升级，就会造成解压缩不成功。</p><p>因而，当业务发生改变，需要多传输一些参数或者少传输一些参数的时候，都需要及时通知对方，并且根据约定好的协议文件重新生成双方的 Stub 程序。自然，这样灵活性比较差。</p><p>如果仅仅是沟通的问题也还好解决，其实更难弄的还有<strong>版本的问题</strong>。比如在服务端提供一个服务，参数的格式是版本一的，已经有 50 个客户端在线上调用了。现在有一个客户端有个需求，要加一个字段，怎么办呢？这可是一个大工程，所有的客户端都要适配这个，需要重新写程序，加上这个字段，但是传输值是 0，不需要这个字段的客户端很“冤”，本来没我啥事儿，为啥让我也忙活？</p><p>最后，<strong>ONC RPC 的设计明显是面向函数的，而非面向对象</strong>。而当前面向对象的业务逻辑设计与实现方式已经成为主流。</p><p>这一切的根源就在于压缩。这就像平时我们爱用缩略语。如果是篮球爱好者，你直接说 NBA，他马上就知道什么意思，但是如果你给一个大妈说 NBA，她可能就不知所云。</p><p>所以，这种 RPC 框架只能用于客户端和服务端全由一拨人开发的场景，或者至少客户端和服务端的开发人员要密切沟通，相互合作，有大量的共同语言，才能按照既定的协议顺畅地进行工作。</p><h3 id="XML-与-SOAP"><a href="#XML-与-SOAP" class="headerlink" title="XML 与 SOAP"></a>XML 与 SOAP</h3><p>但是，一般情况下，我们做一个服务，都是要提供给陌生人用的，你和客户不会经常沟通，也没有什么共同语言。就像你给别人介绍 NBA，你要说美国职业篮球赛，这样不管他是干啥的，都能听得懂。</p><p>放到我们的场景中，对应的就是用<strong>文本类</strong>的方式进行传输。无论哪个客户端获得这个文本，都能够知道它的意义。</p><p>一种常见的文本类格式是 XML。我们这里举个例子来看。</p><pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;cnblog:purchaseOrder xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:cnblog="http://www.example.com"&gt;    &lt;order&gt;        &lt;date&gt;2019-01-08&lt;/date&gt;        &lt;className&gt; 板栗焖鸡 &lt;/className&gt;        &lt;price&gt;58&lt;/price&gt;    &lt;/order&gt;&lt;/cnblog:purchaseOrder&gt;</code></pre><p>我这里不准备详细讲述 XML 的语法规则，但是你相信我，看完下面的内容，即便你没有学过 XML，也能一看就懂，这段 XML 描述的是什么，不像全面的二进制，你看到的都是 010101，不知所云。</p><p>有了这个，刚才我们说的那几个问题就都不是问题了。</p><p>首先，<strong>格式没必要完全一致</strong>。比如如果我们把 price 和 author 换个位置，并不影响客户端和服务端解析这个文本，也根本不会误会，说这个作者的名字叫 68。</p><p>如果有的客户端想增加一个字段，例如添加一个推荐人字段，只需要在上面的文件中加一行：</p><pre><code>&lt;recommended&gt; Gary &lt;/recommended&gt; </code></pre><p>对于不需要这个字段的客户端，只要不解析这一行就是了。只要用简单的处理，就不会出现错误。</p><p>另外，这种表述方式显然是描述一个订单对象的，是一种面向对象的、更加接近用户场景的表示方式。</p><p>既然 XML 这么好，接下来我们来看看怎么把它用在 RPC 中。</p><h3 id="传输协议问题"><a href="#传输协议问题" class="headerlink" title="传输协议问题"></a>传输协议问题</h3><p>我们先解决第一个，传输协议的问题。</p><p>基于 XML 的最著名的通信协议就是<strong>SOAP</strong>了，全称<strong>简单对象访问协议</strong>（Simple Object Access Protocol）。它使用 XML 编写简单的请求和回复消息，并用 HTTP 协议进行传输。</p><p>SOAP 将请求和回复放在一个信封里面，就像传递一个邮件一样。信封里面的信分<strong>抬头</strong>和<strong>正文</strong></p><pre><code>POST /purchaseOrder HTTP/1.1Host: www.cnblog.comContent-Type: application/soap+xml; charset=utf-8Content-Length: nnn</code></pre><pre><code>&lt;?xml version="1.0"?&gt;&lt;soap:Envelope xmlns:soap="http://www.w3.org/2001/12/soap-envelope"soap:encodingStyle="http://www.w3.org/2001/12/soap-encoding"&gt;    &lt;soap:Header&gt;        &lt;m:Trans xmlns:m="http://www.w3schools.com/transaction/"          soap:mustUnderstand="1"&gt;1234        &lt;/m:Trans&gt;    &lt;/soap:Header&gt;    &lt;soap:Body xmlns:m="http://www.cnblog.com/perchaseOrder"&gt;        &lt;m:purchaseOrder"&gt;            &lt;order&gt;                &lt;date&gt;2019-01-08&lt;/date&gt;                &lt;className&gt; 板栗焖鸡 &lt;/className&gt;                &lt;price&gt;88&lt;/price&gt;            &lt;/order&gt;        &lt;/m:purchaseOrder&gt;    &lt;/soap:Body&gt;&lt;/soap:Envelope&gt;</code></pre><p>HTTP 协议我们学过，这个请求使用 POST 方法，发送一个格式为 application/soap + xml 的 XML 正文给 <a href="http://www.geektime.com" target="_blank" rel="noopener">www.geektime.com</a> ，从而下一个单，这个订单封装在 SOAP 的信封里面，并且表明这是一笔交易（transaction），而且订单的详情都已经写明了。</p><h3 id="协议约定问题"><a href="#协议约定问题" class="headerlink" title="协议约定问题"></a>协议约定问题</h3><p>接下来我们解决第二个问题，就是双方的协议约定是什么样的？</p><p>因为服务开发出来是给陌生人用的，就像上面下单的那个 XML 文件，对于客户端来说，它如何知道应该拼装成上面的格式呢？这就需要对于服务进行描述，因为调用的人不认识你，所以没办法找到你，问你的服务应该如何调用。</p><p>当然你可以写文档，然后放在官方网站上，但是你的文档不一定更新得那么及时，而且你也写的文档也不一定那么严谨，所以常常会有调试不成功的情况。因而，我们需要一种相对比较严谨的<strong>Web 服务描述语言</strong>，WSDL（Web Service Description Languages）。它也是一个 XML 文件。</p><p>在这个文件中，要定义一个类型 order，与上面的 XML 对应起来。</p><pre><code> &lt;wsdl:types&gt;  &lt;xsd:schema targetNamespace="http://www.example.org/cnblog"&gt;   &lt;xsd:complexType name="order"&gt;    &lt;xsd:element name="date" type="xsd:string"&gt;&lt;/xsd:element&gt;&lt;xsd:element name="className" type="xsd:string"&gt;&lt;/xsd:element&gt;&lt;xsd:element name="Author" type="xsd:string"&gt;&lt;/xsd:element&gt;    &lt;xsd:element name="price" type="xsd:int"&gt;&lt;/xsd:element&gt;   &lt;/xsd:complexType&gt;  &lt;/xsd:schema&gt; &lt;/wsdl:types&gt;</code></pre><p>接下来，需要定义一个 message 的结构。</p><pre><code> &lt;wsdl:message name="purchase"&gt;  &lt;wsdl:part name="purchaseOrder" element="tns:order"&gt;&lt;/wsdl:part&gt; &lt;/wsdl:message&gt;</code></pre><p>接下来，应该暴露一个端口。</p><pre><code> &lt;wsdl:portType name="PurchaseOrderService"&gt;  &lt;wsdl:operation name="purchase"&gt;   &lt;wsdl:input message="tns:purchase"&gt;&lt;/wsdl:input&gt;   &lt;wsdl:output message="......"&gt;&lt;/wsdl:output&gt;  &lt;/wsdl:operation&gt; &lt;/wsdl:portType&gt;</code></pre><p>然后，我们来编写一个 binding，将上面定义的信息绑定到 SOAP 请求的 body 里面。</p><pre><code> &lt;wsdl:binding name="purchaseOrderServiceSOAP" type="tns:PurchaseOrderService"&gt;  &lt;soap:binding style="rpc"   transport="http://schemas.xmlsoap.org/soap/http" /&gt;  &lt;wsdl:operation name="purchase"&gt;   &lt;wsdl:input&gt;    &lt;soap:body use="literal" /&gt;   &lt;/wsdl:input&gt;   &lt;wsdl:output&gt;    &lt;soap:body use="literal" /&gt;   &lt;/wsdl:output&gt;  &lt;/wsdl:operation&gt; &lt;/wsdl:binding&gt;</code></pre><p>最后，我们需要编写 service。</p><pre><code> &lt;wsdl:service name="PurchaseOrderServiceImplService"&gt;  &lt;wsdl:port binding="tns:purchaseOrderServiceSOAP" name="PurchaseOrderServiceImplPort"&gt;   &lt;soap:address location="http://www.cnblog.com:8080/purchaseOrder" /&gt;  &lt;/wsdl:port&gt; &lt;/wsdl:service&gt;</code></pre><p>WSDL 还是有些复杂的，不过好在有工具可以生成。</p><p>对于某个服务，哪怕是一个陌生人，都可以通过在服务地址后面加上“?wsdl”来获取到这个文件，但是这个文件还是比较复杂，比较难以看懂。不过好在也有工具可以根据 WSDL 生成客户端 Stub，让客户端通过 Stub 进行远程调用，就跟调用本地的方法一样。</p><h3 id="服务发现问题"><a href="#服务发现问题" class="headerlink" title="服务发现问题"></a>服务发现问题</h3><p>最后解决第三个问题，服务发现问题。</p><p>这里有一个<strong>UDDI</strong>（Universal Description, Discovery, and Integration），也即<strong>统一描述、发现和集成协议</strong>。它其实是一个注册中心，服务提供方可以将上面的 WSDL 描述文件，发布到这个注册中心，注册完毕后，服务使用方可以查找到服务的描述，封装为本地的客户端进行调用。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>原来的二进制 RPC 有很多缺点，格式要求严格，修改过于复杂，不面向对象，于是产生了基于文本的调用方式——基于 XML 的 SOAP；</li><li>SOAP 有三大要素：协议约定用 WSDL、传输协议用 HTTP、服务发现用 UDDL。</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RPC协议 </tag>
            
            <tag> SOAP协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 19 - RPC协议综述：远在天边近在眼前</title>
      <link href="/1/wangluoxieyi/ck0669dtk003zagaa5sqz1e7w/"/>
      <url>/1/wangluoxieyi/ck0669dtk003zagaa5sqz1e7w/</url>
      
        <content type="html"><![CDATA[<p>这几年微服务很火，想必各位博友或多或少的都接触过。微服务概念中，<br>各服务间的相互调用是不可或缺的一环。你知道微服务之间是通过什么方式相互调用的吗？</p><p>你可能说，这还不简单，用 socket 呗。服务之间分调用方和被调用方，我们就建立一个 TCP 或者 UDP 连接进行通信就好了。</p><p>说着说着，你可能就会发现，这事儿没那么简单。</p><p>我们就拿最简单的场景：</p><blockquote><p>客户端调用一个加法函数，将两个整数加起来，返回它们的和。</p></blockquote><p>如果放在本地调用，那是简单的不能再简单，但是一旦变成了远程调用，门槛一下子就上去了。</p><p>首先，你要会 socket 编程，至少要先了解咱们这个系列的所有协议 ，然后再看 N 本砖头厚的 socket 程序设计的书，学会咱们了解过的几种 socket 程序设计的模型。</p><p>这就使得本来大学毕业就能干的一项工作，变成了一件五年工作经验都不一定干好的工作，而且，搞定了 socket 程序设计，才是万里长征的第一步，后面还有很多问题呢。</p><h3 id="存在问题"><a href="#存在问题" class="headerlink" title="存在问题"></a>存在问题</h3><p><strong>问题一：如何规定远程调用的语法？</strong><br>客户端如何告诉服务端，我是一个加法，而另一个是减法。是用字符串 “add” 传给你，还是传给你一个整数，比如 1 表示加法，2 表示减法？</p><p>服务端又该如果告诉客户端，我这个是加法，目前只能加整数，不能加小数和字符串。而另一个加法 “add1”，它能实现小数和整数的混合加法，那返回值是什么？正确的时候返回什么，错误的时候又返回什么？</p><p><strong>问题二：如何传递参数？</strong><br>是先传两个整数，后传一个操作数 “add”，还是先传操作符，再传两个整数？</p><p>另外，如果我们是用 UDP 传输，把参数放在一个报文里还好，但如果是 TCP，是一个流，在这个流里面如何区分前后两次调用？</p><p><strong>问题三：如何表示数据？</strong><br>在我们的加法例子中，传递的就是一个固定长度的 int 值，这种情况还好，如果是变长的类型，是一个结构体，甚至是一个类，应该怎么办呢？即使是 int，在不同的平台上长度也不同，该怎么办呢？</p><p><strong>问题四：如何知道一个服务端都实现了哪些远程调用？从哪个端口可以访问这个远程调用？</strong><br>假设服务端实现了多个远程调用，每个实现可能都不在一个进程中，监听的端口也不一样，而且由于服务端都是自己实现的，不可能使用一个大家都公认的端口，而且有可能多个进程部署在一台机器上，大家需要抢占端口，为了防止冲突，往往使用随机端口，那客户端如何找到这些监听的端口呢？</p><p><strong>问题五：发生了错误、重传、丢包、性能等问题怎么办？</strong><br>本地调用没有这个问题，但是一旦到网络上，这些问题都需要处理，因为网络是不可靠的，虽然在同一个连接中，我们还可以通过 TCP 协议保证丢包、重传的问题，但是如果服务器崩溃了又重启，当前连接断开了，TCP 就保证不了了，需要应用自己进行重新调用，重新传输会不会同样的操作做两遍，远程调用性能会不会受影响呢？</p><h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><p>看到这么多问题，是不是很头疼？还记得咱们了解 http 的时候，认识的<strong>协议三要素</strong>吗？</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190106223746175-2043951331.png" alt=""></p><p>本地调用函数里很多问题，比如词法分析、语法分析、语义分析等待，这些问题编译器基本上都帮我们解决了，但是在远程调用中，这些问题我们都要自己考虑。</p><h4 id="协议约定问题"><a href="#协议约定问题" class="headerlink" title="协议约定问题"></a>协议约定问题</h4><p>很多公司对于这个问题，是弄一个核心通信组，里面都是 socket 编程的大牛，实现一个统一的库，让其他业务组的人来调用，业务的人不需要知道中间传输的细节。</p><p>通信双方的语法、语义、格式、端口、错误处理等，都需要调用方和被调用方开会商量，双方达成一致。一旦有一方改变，要及时通知对方，否则就会出现问题。</p><p>但是，不是每个公司都能通过这种大牛团队解决问题的，而是使用已经实现好的框架。</p><p>有一个大牛（Bruce Jay Nelson）通过一篇论文，定义了 RPC 的调用标准。后面所有 RPC 框架都是按照这个标准模式来的。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190106223813426-1499738762.png" alt=""></p><p>整个过程如下：</p><ol><li>客户端的应用想发起一个远程调用时，它实际上是通过本地调用方的 Stub。它负责将调用的接口、方法和参数，通过约定的协议规范进行编码，并通过本地 RPCRuntime 进行传输，将调用网络包发送到服务器；</li><li>服务端的 RPCRuntime 收到请求后，交给提供方 Stub 进行编码，然后调用服务端的方法，获取结果，并将结果编码后，发送给客户端；</li><li>客户端的 RPCRuntime 收到结果，发给调用方 Stub 解码得到结果，返回给客户端。</li></ol><p>上面过程中分了三个层次：客户端、Stub 层、服务端。</p><p>对于客户端和服务端，都像是本地调用一样，专注于业务逻辑的处理就可以了。对于 Stub 层，处理双方约定好的语法、语义、封装、解封装。对于 RPCRuntime，主要处理高性能的传输，以及网络的错误和异常。</p><p>最早的 RPC 的一种实现方式称为 <strong>Sun RPC</strong> 或 <strong>ONC RPC</strong>。Sun 公司是第一个提供商业化 RPC 库和 RPC 编译器的公司。这个 RPC 框架是在 NFS 协议中使用的。</p><p>NFS（Network File System）就是网络文件系统。要使 NFS 成功运行，就要启动两个服务端，一个 mountd，用来挂载文件路径。另一个是 nfsd，用来读写文件。NFS 可以在本地 mount 一个远程的目录到本地目录，从而实现让本地用户在本地目录里面读写文件时，操作是是远程另一台机器上的文件。</p><p>远程操作和远程调用的思路是一样的，就像本地操作一样，所以 NFS 协议就是基于 RPC 实现的。当然，无论是什么 RPC，底层都是 socket 编程。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190106223837333-1732100148.png" alt=""></p><p>XDR（External Data Representation，外部数据表示法）是有一个标准的数据压缩格式，可以表示基本的数据类型，也可以表示结构体。</p><p>这里有几种基本的数据类型。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190106223854961-1284035736.png" alt=""></p><p>在 RPC 的调用过程中，所有的数据类型都要封装成类似的格式，而且 RPC 的调用和结果返回也有严格的格式。</p><ul><li>XID 唯一标识请求和回复。请求是 0，回复是 1；</li><li>RPC 有版本号，两端要匹配 RPC 协议的版本号。如果不匹配，就会返回 Deny，原因是 RPC_MISMATCH；</li><li>程序有编号。如果服务端找不到这个程序，就会返回 PROG_UNAVAIL；</li><li>程序有版本号。如果程序的版本号不匹配，就会返回 PROG_MISMATCH；</li><li>一个程序可以有多个方法，方法也有编号，如果找不到方法，就会返回 PROG_UNAVAIL；</li><li>调用需要认证鉴权，如果不通过，返回 Deny；</li><li>最后是参数列表，如果参数无法解析，返回 GABAGE_ARGS；</li></ul><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190106223912594-1706578343.png" alt=""></p><p>为了可以成功调用 RPC，在客户端和服务端实现 RPC 的时候，首先要定义一个双方都认可的程序、版本、方法、参数等。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190106223929871-492941962.png" alt=""></p><p>对于上面的加法而言，双方约定为一个协议定义文件，同理，如果是 NFS、mount 和读写，也会有类似的定义。</p><p>有了协议定义文件，ONC RPC 会提供一个工具，根据这个文件生成客户端和服务器端的 Stub 程序。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190106223948442-1939357045.png" alt=""></p><p>最下层的是 XDR 文件，用于编码和解码参数。这个文件是客户端和服务端共享的，因为只有双方一致才能成功通信。</p><p>在客户端，会调用 clnt_create 创建一个连接，然后调用 add_1，这是一个 Stub 函数，感觉是在调用本地函数一样。其实是这个函数发起了一个 RPC 调用，通过调用 clnt_call 来调用 ONC RPC 的类库，来真正发送请求。调用的过程较为复杂，后续再进行专门的说明。</p><p>当然，服务端也有一个 Stub 程序，监听客户端的请求，当调用到达的时候，判断如果是 add，则调用真正的服务端逻辑，也就是将两个数加起来。</p><p>服务端将结果返回服务端的 Stub，Stub 程序发送结果给客户端 Stub，客户端 Stub 收到结果后就返回给客户端的应用程序，从而完成这个调用过。</p><p>有了这个 RPC 框架，前面五个问题中的 “如何规定远程调用的语法？”、“如何传递参数？” 以及 “如何表示数据？” 基本解决了，这三个问题我们统称为<strong>协议约定问题</strong>。</p><h4 id="传输问题"><a href="#传输问题" class="headerlink" title="传输问题"></a>传输问题</h4><p>前三个问题解决了，但是错误、重传、丢包以及性能问题还没有解决，这些问题我们统称为<strong>传输问题</strong>。这个 Stub 层就无能为力了，而是由 ONC RPC 的类库来实现。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190106224010488-825281005.png" alt=""></p><p>在这个类库中，为了解决传输问题，对于每一个客户端，都会创建一个传输管理层，而每一次 RPC 调用，都会是一个任务，在传输管理层，你可以看到熟悉的队列机制、拥塞窗口机制等。</p><p>由于在网络传输的时候，经常需要等待，而同步的方式往往效率比较低，因而也就有 socket 的异步模型。</p><p>为了能够异步处理，对于远程调用的处理，往往是通过状态机来实现的。只有当满足某个状态的时候，才进行下一步，如果不满足状态，不是在那里等待，而是将资源留出来，用来处理其他的 RPC 调用。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190106224024044-774432502.png" alt=""></p><p>如上图，从图也可以看出，这个状态转换图还是很复杂的。</p><p>首先，进入起始状态，查看 RPC 的传输层队列中有没有空闲的位置，可以处理新的 RPC 任务，如果没有，说明太忙了，直接结束或重试。如果申请成功，就可以分配内存，获取服务端的端口号，然后连接服务器。</p><p>连接的过程要有一段时间，因而要等待连接结果，如果连接失败，直接结束或重试。如果连接成功，则开始发送 RPC 请，然后等待获取 RPC 结果。同样的，这个过程也需要时间，如果发送出错，就重新发送，如果连接断开，要重新连接，如果超时，要重新传输。如果获取到结果，就可以解码，正常结束。</p><p>这里处理了连接失败、重试、发送失败、超时、重试等场景，因而实现一个 RPC 框架，其实很有难度。</p><h4 id="服务发现问题"><a href="#服务发现问题" class="headerlink" title="服务发现问题"></a>服务发现问题</h4><p>传输问题解决了，我们还遗留了一个 “如何找到 RPC 服务端的那个随机端口”，这个问题我们称为服务发现问题，在 ONC RPC 中，服务发现是通过 portmapper 实现的。</p><p>portmapper 会启动在一个众所周知的端口上，RPC 程序由于是用户自己写的，会监听在一个随机端口上，但是 RPC 程序启动的时候，会向 portmapper 注册。</p><p>客户端要访问 RPC 服务端这个程序的时候，首先查询 portmapper，获取 RPC 服务端程序的随机端口，然后向这个随机端口建立连接，开始 RPC 调用。</p><p>从下图中可以看出，mount 命令的 RPC 调用就是这样实现的。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190106224046831-189650954.png" alt=""></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>远程调用看起来用 socket 编程就可以了，其实是很复杂的，要解决协议约定问题、传输问题和服务发现问题；</li><li>ONC RPC 框架以及 NFS 的实现，给出了解决上述三大问题的示范性实现，也就是公用协议描述文件，并通过这个文件生成 Stub 程序。RPC 的传输一般需要一个状态机，需要另外一个进程专门做服务发现。</li></ul><p>参考：</p><ol><li>刘超-趣谈网络协议系列课；</li><li><a href="https://www.jianshu.com/p/2accc2840a1b" target="_blank" rel="noopener">如何给老婆解释什么是RPC</a>;</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RPC协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 18 - CDN：家门口的小卖铺</title>
      <link href="/1/wangluoxieyi/ck0669dol0025agaadfado113/"/>
      <url>/1/wangluoxieyi/ck0669dol0025agaadfado113/</url>
      
        <content type="html"><![CDATA[<p>到现在为止，我们基本上已经了解了网络协议中的大部分常用协议，对于整个 HTTP 请求流程也较为熟悉了。从无到有后，我们就要考虑如何优化“有”这个过程，也就是我们常见的<strong>请求优化</strong>。而现在的技术栈中，CDN 是最常用的一种方式。</p><p>在了解 CDN 前，我们可以先了解下现代社会的物流配置。</p><p>例如我们去电商网站下单买东西，这个东西一定要从电商总部的中心仓库送过来吗？在电商刚兴起的时候，所有的配送都是从中心仓库发货，所以买家可能要很久才能收到货。但是后来电商网站的物流系统学聪明了，他们在全国各地建立了很多仓库，而不是只有总部的中心仓库才可以发货。</p><p>电商网站根据统计大概知道，北京、上海、广州、深圳、杭州等地，每天能够卖出去多少书籍、纸巾、包、电器等存放期较长的商品，就将这些商品分布存放在各地仓库中，客户一下单，就从临近的仓库发货，大大减少了运输时间，提高了用户体验。</p><p>同样的，互联网也借鉴了<strong>“就近配送”</strong>这个思路。</p><h3 id="CDN-就近配送"><a href="#CDN-就近配送" class="headerlink" title="CDN 就近配送"></a>CDN 就近配送</h3><p>全球有那么多的数据中心，无论在哪里上网，临近不远的地方基本上都有数据中心。可以在每个数据中心里部署几台机器，形成一个缓存集群来缓存部分热数据，这样用户访问数据的是，就可以就近访问了。</p><p>这些分布在各个地方的各个数据中心的节点，我们一般称为<strong>边缘节点</strong>。</p><p>由于边缘节点数目比较多，但是每个集群规模比较小，不可能缓存下来所有东西，因而可能无法命中，这样就会在边缘节点之上，形成了<strong>区域节点</strong>。</p><p>区域节点规模较大，缓存的数据也较多，命中的概率也就更大。而在区域节点之上是中心节点，规模更大，缓存数据更多。</p><p>就这样，在这样一层层的节点中缓存数据，提高响应速度。但是所有的节点都没有缓存数据，就只有进行回源网站访问了。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190101194613639-2088500704.png" alt=""></p><p>如上图，就是 <strong>CDN 的分发系统的架构</strong>。CDN 系统的缓存，是一层层的，能不访问源数据，就不访问。这也是电商网站物流系统的思路，广州找不到，找华南局，华南局找不到，再找南方局。</p><p>有了这个分发系统之后，<strong>客户端如何找到相应的边缘节点进行访问呢？</strong></p><p>还记得咱们之前了解的<strong>基于 DNS 的全局负载均衡</strong>吗？这个负载均衡主要用来选择一个就近的相同运营商的服务器进行访问。</p><p>同样的，CDN 分发网络也可以用相同的思路选择最合适的边缘节点。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190101194726897-1265058928.png" alt=""></p><p>如上图，CDN 的负载均衡流程图。<br><strong>1）没有 CDN 的情况</strong>（图中虚线部分）。用户向浏览器输入 <a href="http://www.web.com" target="_blank" rel="noopener">www.web.com</a> 这个域名，客户端访问本地 DNS 服务器的时候，如果本地 DNS 服务器有缓存，则返回网站的地址。如果没有，递归查询到网站的权威 DNS 服务器，这个权威 DNS 服务器是负责 web.com 的，它会返回网站的 IP 地址。本地 DNS 服务器缓存下 IP 地址，将 IP 地址返回，然后客户端直接访问这个 IP 地址，就访问到了网站。</p><p><strong>2）有 CDN 的情况</strong>（图中实线部分）。此时，在 web.com 这个权威 DNS 服务器上，会设置一个 CNAME 别名，指向另外一个域名 <a href="http://www.web.cdn.com，返回给本地" target="_blank" rel="noopener">www.web.cdn.com，返回给本地</a> DNS 服务器。</p><p>当本地 DNS 服务器拿到这个新的域名时，需要继续解析这个新的域名。这个时候，再访问的就不是 web.com 这个权威 DNS 服务器了，而是 web.cdn.com 的权威 DNS 服务器，这是 CDN 自己的权威 DNS 服务器，在这个服务器上，还是会设置一个 CNAME，指向另外一个域名，也就是 CDN 网络的全局负载均衡器。</p><p>接下来，本地 DNS 服务器去请求 CDN 的全局负载均衡器解析域名。全局负载均衡器会为用户选择一台合适的缓存服务器提供服务，选择的依据包括：</p><ul><li>根据用户 IP 地址，判断哪一台服务器距用户最近；</li><li>用户所处的运营商；</li><li>根据用户所请求的 URL 中携带的内容名词，判断哪一台服务器上有用户所需的内容；</li><li>查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。</li></ul><p>基于以上这些条件，进行综合分析之后，全局负载均衡器会返回一台缓存服务器的 IP 地址。</p><p>本地 DNS 服务器缓存这个 IP 地址，然后将 IP 返回给客户端，客户端去访问这个边缘节点，下载资源。</p><p>缓存服务器响应用户请求，将用户所需内容传送给用户。如果这台缓存服务器上没有用户想要的内容，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器，将内容拉到本地。</p><h3 id="CDN-缓存内容"><a href="#CDN-缓存内容" class="headerlink" title="CDN 缓存内容"></a>CDN 缓存内容</h3><p>保质期长的日用品因为不容易过期，因此比较容易缓存。同样的，互联网中的静态页面、图片等，几乎不怎么改变，所以也适合缓存。而像生鲜之类的保存时间较短的，对应互联网中的动态资源，就需要用到*<em>动态 CDN *</em>。</p><h4 id="静态资源缓存"><a href="#静态资源缓存" class="headerlink" title="静态资源缓存"></a>静态资源缓存</h4><p><img src="https://img2018.cnblogs.com/blog/861679/201901/861679-20190101194759711-1086642405.png" alt=""></p><p>还记得上图这个<strong>接入层缓存的架构</strong>吗？在进入数据中心的时候，我们希望通过最外层接入层的缓存，将大部分静态资源的访问拦在边缘。而 CDN 则更进一步，将这些静态资源缓存到离用户更近的数据中心外。总体来说，就是缩短用户的“访问距离”。<strong>离客户越近，客户访问性能越好，时延越低</strong>。</p><h5 id="流媒体-CDN"><a href="#流媒体-CDN" class="headerlink" title="流媒体 CDN"></a>流媒体 CDN</h5><p>在静态内容中，流媒体也大量使用了 CDN。</p><p>CDN 支持流媒体协议。例如前面讲过的 RTMP 协议。在很多情况下，这相当于一个代理，从上一级缓存读取内容，转发给用户。由于流媒体往往是连续的，因而可以进行<strong>预先缓存</strong>的策略，也可以<strong>预先推送到用户的客户端</strong>。</p><p>对于静态页面来讲，内容的分发往往采取<strong>拉取</strong>的方式。也即，当发现缓存未命中的是，再去上一级进行拉取。</p><p>这个方式对于流媒体就不合适了。流媒体数据量大，如果出现回源，压力会比较大，所以往往采取<strong>主动推送</strong>的模式，将热点数据主动推送到边缘节点。</p><p>对于流媒体来讲，很多 CDN 还提供<strong>预处理服务</strong>。也就是在文件分发之前，进行一定的处理。例如将视频转换成不同的码流，以适应不同的网络带宽的用户需求。再如对视频进行分片，降低存储压力，也使得客户端可以选择使用不同的码率加载不同的分片。这就是我们常见的，超清、标清、流畅等。</p><p>除此之外，流媒体 CDN 还有个关键的<strong>防盗链</strong>问题。因为视频要花大价钱买版权，如果流媒体被其他网站盗走，在其他网站的播放，那损失就大了。</p><p>对于防盗链问题，最常用也最简单的方法就是<strong>利用 HTTP 头的 refer 字段</strong>。当浏览器发送请求的时候，一般会带上 refer。告诉服务器是从哪个页面链接过来的，服务器基于此可以获得一些信息用于处理。如果 refer 信息不是来自本站，就阻止访问或者跳到其它链接。</p><p>refer 的机制相对比较容易破解，所以还需要其它的机制配合。</p><p>一种常用的机制是<strong>时间戳防盗链</strong>。使用 CDN 的管理员可以在配置界面上，和 CDN 厂商约定一个加密字符串。</p><p>客户端访问时，取出当前的时间戳、要访问的资源极其路径，联通加密字符串进行前面算法得到一个字符串，然后生成一个下载链接，带上这个前面字符串和截止时间戳去访问 CDN。</p><p>在服务端，取出过期时间，和当前 CDN 节点时间进行比较，确认请求是否过期。然后 CDN 服务端根据请求的资源及路径、时间戳、和约定的加密字符串进行签名。只有签名和客户端发送的一致，才会将资源返回给客户。</p><h4 id="动态资源缓存"><a href="#动态资源缓存" class="headerlink" title="动态资源缓存"></a>动态资源缓存</h4><p>对于动态资源，用到动态 CDN。动态 CDN 主要有两种模式：<br><strong>1）“生鲜超市模式”，也就是边缘计算模式</strong>。</p><p>既然数据是动态生成的，所以数据的逻辑计算和存储，也相应的放在边缘的节点。其中定时从源数据那里同步存储的数据，然后在边缘节点进行计算得到结果。</p><p>这种方式很像现在的生鲜超市。新鲜的海鲜大餐是动态的，很难事先做好缓存，因而将生鲜超市放在你家旁边，既能够送货上门，也能够现场烹饪。这就是边缘计算的一种体现。</p><p><strong>2）“冷链运输模式”，也就是路径优化模式</strong>。数据不是在边缘计算生成的，而是在源站生成的，但是数据的下发则可以通过 CDN 的网络，对路径进行优化。</p><p>因为 CDN 节点较多，能够找到离源站很近的边缘节点，也能找到离用户很近的边缘节点。中间的链路完全由 CDN 来规划，选择一个更加可靠的路径，使用类似专线的方式进行访问。</p><p>除此之外，这些资源进行传输的时候，由于 TCP 的流量控制和拥塞控制，可以在 CDN 加速网络中调整 TCP 的参数，使得 TC 可以更加激进的传输数据。</p><p>所有这些手段就像冷链传输，优化整个物流运输，全程冷冻高速运输。不管是生鲜从你家旁边超市送过去，还是从产地运送，保证到你家是新鲜的。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>CDN 和电商系统的分布式仓储系统一样，分为中心节点、区域节点、边缘节点，从而将数据缓存在离用户最近的位置。</li><li>CDN 最擅长的缓存是缓存静态数据。除此之外还可以缓存流媒体数据。这时候要注意防盗链问题。它也支持动态数据的缓存，一种是边缘计算，另一种是链路优化。</li></ul><p>参考：</p><ol><li><a href="https://www.cloudflare.com/learning/cdn/what-is-a-cdn/" target="_blank" rel="noopener">What is a CDN?</a>;</li><li><a href="https://en.wikipedia.org/wiki/Content_delivery_network" target="_blank" rel="noopener">维基百科 - Content delivery network</a>;</li><li>刘超 - 趣谈网络协议系列课;</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CDN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 17 - HTTPDNS：私人定制的 DNS 服务</title>
      <link href="/12/wangluoxieyi/ck0669doz0029agaa3koef2qf/"/>
      <url>/12/wangluoxieyi/ck0669doz0029agaa3koef2qf/</url>
      
        <content type="html"><![CDATA[<p>全球统一的 DNS 是很权威，但是我们都知道“适合自己的，才是最好的”。很多时候，标准统一化的 DNS 并不能满足我们定制的需求，这个时候就需要 HTTPDNS 了。</p><p>上一节我们知道了 DNS 可以根据名称查地址，也可以针对多个地址做负载均衡。然而，我们信任的地址簿也会存在指错路的情况。明明离你 500 米就有个吃饭的地方，非要把你推荐到 5 公里外。为什么会出现这样的情况呢？</p><p>还记得吗？由我们发出请求解析 DNS 的时候，首先会连接到运营商本地的 DNS 服务器，由这个服务器帮我们去整棵 “DNS 树” 上进行解析，然后将解析的结果返回给客户端。但是本地的 DNS 服务器，作为一个本地导游，往往会有自己的“小心思”。</p><h3 id="传统-DNS-存在的问题"><a href="#传统-DNS-存在的问题" class="headerlink" title="传统 DNS 存在的问题"></a>传统 DNS 存在的问题</h3><p><strong>1）域名缓存问题</strong><br>它可以在本地做一个缓存。也就是说，不是每一个请求，它都会去访问权威 DNS 服务器，而是把访问过一次的结果缓存到本地，当其他人来问的时候，直接返回缓存的内容。</p><p>这就相当于导游去过一个饭店，自己记住了地址，当有一个游客问的时候，他就凭记忆回答了，不用再去查地址簿。这样会存在一个问题，游客问的那个饭店如果已经搬走了，然而因为导游没有刷新“记忆缓存”，导致游客白跑一趟。</p><p>另外，有的运营商会把一些静态页面，缓存到本运营商的服务器内，<strong>这样用户请求的时候，就不用跨运营商进行访问，既加快了速度，也减少了运营商直接流量计算的成本</strong>。也就是说，在域名解析的时候，不会将用户导向真正的网站，而是指向这个缓存的服务器。</p><p>缓存的问题，很多情况下是看不出问题的，但是当页面更新，用户访问到老的页面，问题就出来了。</p><p>再就是<strong>本地的缓存，往往使得全局负载均衡失败</strong>。上次进行缓存的时候，缓存中的地址不一定是客户此次访问离客户最近的地方，如果把这个地址返回给客户，就会让客户绕远路了。<br><strong>2）域名转发问题</strong><br>还记得我们域名解析的过程吗？捂脸是本地域名解析，还是去权威 DNS 服务器中查找，都可以认为是一种<strong>外包形式</strong>。有了请求，直接转发给其他服务去解析。如果转发的是权威 DNS 服务器还好说，但是如果因为“偷懒”转发给了邻居服务器去解析，就容易产生跨运营商访问的问题。</p><p>这就好像，如果 A 运营商的客户，访问自己运营商的 DNS 服务器，A 运营商去权威 DNS 服务器查询的话，会查到客户的 A 运营商的，返回一个部署在 A 运营商的网站地址，这样针对相同运营商的访问，速度就会快很多。</p><p>但是如果 A 运营商偷懒，没有转发给权威 DNS ，而是转发给了 B 运营商，让 B 运营商再去权威 DNS 服务器查询，这样就会让权威服务器误认为客户是 B 运营商的，返回一个 B 运营商的服务器地址，导致客户每次都要跨运营商访问，访问速度就会慢下来。</p><p><strong>3）出口 NAT 问题</strong><br>前面了解网关的时候，我们知道，出口的时候，很多机房都会配置 NAT，也就是<strong>网络地址转换</strong>，使得从这个网关出去的包，都换成新的 IP 地址。</p><p>这种情况下，权威 DNS 服务器就没办法通过请求 IP 来判断客户到底是哪个运营商的，很有可能误判运营商，导致跨运营商访问。</p><p><strong>4）域名更新问题</strong><br>本地 DNS 服务器是由不同地区、不同运营商独立部署的。对域名解析缓存的处理上，实现策略也有区别。有的会偷懒，忽略域名解析结构的 TTL 时间限制，在权威 DNS 服务器解析变更的时候，解析结果在全网生效的周期非常漫长。但是有的场景，在 DNS 的切换中，对生效时间要求比较高。</p><p>例如双机房部署的是，跨机房的负载均衡和容灾多使用 DNS 来做。当一个机房出问题之后，需要修改权威 DNS，将域名指向新的 IP 地址。但是如果更新太慢，很多用户都会访问一次。</p><p><strong>5）解析延迟问题</strong><br>从 DNS 的查询过程来看，DNS 的查询过程需要递归遍历多个 DNS 服务器，才能获得最终的解析结果，这带来一定的延时，甚至会解析超时。</p><p>上面总结了 DNS 的五个问题。问题有了，总得有解决办法，就像因为 HTTP 的安全问题，才火了 HTTPS 协议一样，对应的，也有 HTTPDNS 来解决上述 DNS 出现的问题。</p><h3 id="HTTPDNS"><a href="#HTTPDNS" class="headerlink" title="HTTPDNS"></a>HTTPDNS</h3><p>什么是 HTTPDNS ？其实很简单：</p><blockquote><p>HTTPDNS 是基于 HTTP 协议和域名解析的流量调度解决方案。它不走传统的 DNS 解析，而是自己搭建基于 HTTP 协议的 DNS 服务器集群，分布在多个地点和多个运营商。当客户端需要 DNS 解析的时候，直接通过 HTTP 请求这个服务器集群，得到就近的地址。</p></blockquote><p>这就相当于每家基于 HTTP 协议，自己实现自己的域名解析，做一个自己的地址簿，而不使用统一的地址簿。但是我们知道，域名解析默认都是走 DNS 的，因而使用 HTTPDNS 需要绕过默认的 DNS 路径，也就不能使用默认的客户端。**使用 HTTPDNS 的，往往是手机应用，需要在手机端嵌入支持 HTTPDNS 的客户端 SDK。</p><h4 id="HTTPDNS-的工作流程"><a href="#HTTPDNS-的工作流程" class="headerlink" title="HTTPDNS 的工作流程"></a>HTTPDNS 的工作流程</h4><p>接下来，我们一起来认识下 HTTPDNS 的工作流程。</p><p>HTTPDNS 会在客户端的 SDK 里动态请求服务端，获取 HTTPDNS 服务器的 IP 列表，缓存在本地。随着不断地解析域名，SDK 也会在本地缓存 DNS 域名解析的结果。</p><p>当手机应用要访问一个地址的时候，首先看是否有本地的缓存，如果有直接返回。这个缓存和本地 DNS 的缓存不一样的是，这个是手机应用自己做的，而非整个运营商统一做。如何更新以及何时更新缓存，手机应用的客户端可以和服务器协调来做这件事情。</p><p>如果本地没有，就需要请求 HTTPDNS 的服务器，在本地 HTTPDNS 服务器的 IP 列表中，选择一个发出 HTTP 请求，获取一个要访问的网站的 IP 列表。</p><p>请求的方式是这样的：</p><blockquote><p>curl <a href="http://123.4.5.6/d?dn=c.m.cnb.com" target="_blank" rel="noopener">http://123.4.5.6/d?dn=c.m.cnb.com</a></p></blockquote><p>手机客户端之道手机在哪个运营商、哪个地址。由于是直接的 HTTP 通信，HTTPDNS 服务器能够准确知道这些信息，因而可以做精准的全局负载均衡。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181230223915995-1765030461.png" alt=""></p><p>上面五个问题，归结起来就两大问题。一是<strong>解析速度和更新速度的平衡问题</strong>，二是<strong>智能调度的问题</strong>。HTTPDNS 对应的解决方案是 HTTPDNS 的缓存设计和调度设计。</p><h4 id="HTTPDNS-的缓存设计"><a href="#HTTPDNS-的缓存设计" class="headerlink" title="HTTPDNS 的缓存设计"></a>HTTPDNS 的缓存设计</h4><p>解析 DNS 过程复杂，通信此时多，对解析速度造成很大影响。为了加快解析，因而有了缓存，但是这又会产生缓存更新速度不及时的问题。最要命的是，这两个方面都掌握在别人手中，也就是本地 DNS 服务器手中，它不会为你定制，作为客户端干着急也没办法。</p><p>而 HTTPDNS 就是将解析速度和更新速度全部掌控在自己手中。</p><p>一方面，解析的过程，不需要本地 DNS 服务递归的调用一大圈，一个 HTTP 的请求直接搞定。要实时更新的时候，马上就能起作用。</p><p>另一方面，为了提高解析速度，本地也有缓存，缓存是在客户端 SDK 维护的，过期时间、更新时间，都可以自己控制。</p><p>HTTPDNS 的缓存设计策略也是咱们做应用架构中常用的缓存设计模式，也即分为客户端、缓存、数据源三层。</p><ul><li>对于应用架构来讲，就是应用、缓存、数据库。常见的是 Tomcat、Redis、Mysql；</li><li>对于 HTTPDNS 来讲，就是手机客户端、DNS 缓存、HTTPDNS 服务器。</li></ul><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181230225035554-1049785134.png" alt=""></p><p>只要是缓存模式，就存在缓存的过期、更新、不一致的问题，解决思路也是相似的。</p><p>例如，DNS 缓存在内存中，也可以持久化到存储上，从而 APP 重启之后，能够尽快从存储中加载上次累积的经常访问的网站的解析结果，就不需要每次都全部解析一遍，再变成缓存。这有点像 Redis 是基于内存的缓存，但是同样提供持久化的能力，使得重启或者主备切换的时候，数据不会完全丢失。</p><p>SDK 中的缓存会严格按照缓存过期时间，如果缓存没有命中，或者已经过期，而且客户端不允许使用过期的几率，则会发起一次解析，保证缓存记录是更新的。</p><p>解析可以<strong>同步进行</strong>，也就是直接调用 HTTPDNS 的接口，返回最新的记录，更新缓存。也可以<strong>异步进行</strong>，添加一个解析任务到后台，由后台任务调用 HTTPDNS 的接口。</p><p>同步更新的优点是实时性好，缺点是如果有多个请求都发现过期的时候，会同时请求 HTTPDNS 多次，造成资源浪费。</p><p>同步更新的方式对应到应用架构缓存的 <strong>Cache-Aside</strong> 机制，也就是先读缓存，不命中读数据库，同时将结果写入缓存。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181230224640359-995289518.png" alt=""></p><p>异步更新的优点是，可以将多个请求都发现过期的情况，合并为一个对于 HTTPDNS 的请求任务，只执行一次，减少 HTTPDNS 的压力。同时，可以在即将过期的时候，就创建一个任务进行预加载，防止过期之后再刷新，称为<strong>预加载</strong>。</p><p>它的缺点是，当前请求拿到过期数据的时候，如果客户端允许使用过期时间，需要冒一次风险。这次风险是指，如果过期的请求还能请求，就没问题，如果不能请求，就会失败一次，等下次缓存更新后，才能请求成功。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181230224230224-672655937.png" alt=""></p><p>异步更新的机制，对应到应用架构缓存的 <strong>Refresh-Ahead</strong> 机制，即业务仅仅访问缓存，当过期的时候定期刷新。在著名的应用缓存 Guava Cache 中，有个 RefreshAfterWrite 机制，对于并发情况下，多个缓存访问不命中从而引发并发回源的请求，可以采取只有一个请求回源的模式。在应用架构的缓存中，也常常用<strong>数据预热</strong>或者<strong>预加载</strong>的机制。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181230224317240-1735430617.png" alt=""></p><h4 id="HTTPDNS-的调度设计"><a href="#HTTPDNS-的调度设计" class="headerlink" title="HTTPDNS 的调度设计"></a>HTTPDNS 的调度设计</h4><p>由于客户端嵌入了 SDK，因而就不会因为本地 DNS 的各种缓存、转发、NAT，让权威 DNS 服务器误会客户端所在的位置和运营商，从而可以拿到第一手资料。</p><p>在客户端，可以知道手机是哪个国家、哪个运营商、哪个省、甚至是哪个市，HTTPDNS 服务端可以根据这些信息，选择最佳的服务节点返回。</p><p>如果有多个节点，还会考虑错误率、请求时间、服务器压力、网络状态等，进行综合选择，而非仅仅考虑地理位置。当有一个节点宕机或者性能下降的时候，可以尽快进行切换。</p><p>要做到这一点，需要客户端使用 HTTPDNS 返回的 IP 访问业务应用。客户端的 SDK 会收集网络请求数据，如错误率、请求时间等网络请求质量数据，并发送到统计后台，进行分析、聚合，以此查看不同 IP 的服务质量。</p><p>在服务端，应用可以通过调用 HTTPDNS 的管理接口，配置不同服务质量的优先级、权重。HTTPDNS 会根据这些策略综合地理位置和线路状况算出一个排序，优先访问当前那些优质的、时延低的 IP 地址。</p><p>HTTPDNS 通过智能调度之后返回的结果，也会缓存在客户端。为了不让缓存使得调度失真，客户端可以根据不同的移动网络运营商的 SSID 来分维度缓存。不同的运营商解析出来的结果会不同。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181230224359177-1241188906.png" alt=""></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>传统 DNS 会因为<strong>缓存、转发、NAT 等问题</strong>导致客户端误会自己所在的位置和运营商，从而影响流量的调度；</li><li>HTTPDNS 通过客户端 SDK 和服务端，通过 HTTP 直接调用解析 DNS 的方式，绕过了传统 DNS 的缺点，实现了智能的调度。</li></ul><p>参考：</p><ol><li><a href="http://www.linkedkeeper.com/detail/blog.action?bid=171" target="_blank" rel="noopener">HTTPDNS 的原理</a>；</li><li>刘超 - 趣谈网络协议系列课；</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 负载均衡 </tag>
            
            <tag> HTTPDNS协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 16 - DNS 协议：网络世界的地址簿</title>
      <link href="/12/wangluoxieyi/ck0669doh0022agaa752hsg4c/"/>
      <url>/12/wangluoxieyi/ck0669doh0022agaa752hsg4c/</url>
      
        <content type="html"><![CDATA[<p>为什么在地址栏输入域名，就能直接访问到对应服务器？全局负载均衡和内部负载均衡又是什么？这些都和 DNS 解析息息相关，让我们一起来解密 DNS 解析。</p><p>其实说起 DNS 解析，应该都知道它很像地址簿。就像我们去一家新开的沃尔玛超市，通过地址簿查出来沃尔玛在哪条路多少号，然后再去找。</p><p>在网络世界中，也是这样的。我们可以记住网站的名称，但是很难记住网站的 IP 地址，因此需要一个“地址簿”，帮我们将网站名称转换成 IP。这个“地址簿”就是 <strong>DNS 服务器</strong>。</p><h3 id="DNS-服务器"><a href="#DNS-服务器" class="headerlink" title="DNS 服务器"></a>DNS 服务器</h3><p>对于 DNS 服务器而言，全球每个人上网，都需要访问它。<br>而全球的网民数，据最新统计，已经有 40 亿，每个人都访问它，可想而知 DNS 服务器会有很大的访问流量压力（<strong>高并发</strong>）。<br>而且，它还非常重要，一旦出了故障，整个互联网都将瘫痪（<strong>高可用</strong>）。<br>此外，上网的人分布在全世界各地，如果大家都去同一个地方的某一台服务器，时延将会非常的（<strong>分布式</strong>）。</p><p>因此，DNS 服务器一定要具备<strong>高可用、高并发、分布式</strong>的特点。</p><p>基于此，DNS 服务器设计成<strong>树状的层次结构</strong>。如下图：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181225215224092-266298023.png" alt=""></p><ul><li>根 DNS 服务器：返回顶级域 DNS 服务器的 IP 地址；</li><li>顶级域 DNS 服务器：返回权威 DNS 服务器的 IP 地址；</li><li>权威 DNS 服务器：返回相应主机的 IP 地址。</li></ul><h3 id="DNS-解析流程"><a href="#DNS-解析流程" class="headerlink" title="DNS 解析流程"></a>DNS 解析流程</h3><p>上面说了 DNS 服务器面临大流量访问的压力，因此，为了提高 DNS 的解析性能，很多网站都会就近部署 DNS 缓存服务器。所以，我们常见的 DNS 解析流程就变成了：</p><ol><li><strong>客户端发出 DNS 请求给本地域名服务器</strong>。我们访问博客园，客户端会问本地域名服务器， <a href="http://www.cnblogs.com" target="_blank" rel="noopener">www.cnblogs.com</a> 的 IP 是什么？（本地域名服务器，如果网络是通过 DHCP 配置，本地 DNS 是由你的网络服务商，如电信、联通等自动分配，它通常就在网络服务商的机房里）；</li><li><strong>本地 DNS 收到来自客户端的请求，查找“地址簿”，返回 IP 或请求根域名服务器</strong>。我们可以理解为服务器上缓存了一张域名与 IP 对应的大表，如果能找到 <a href="http://www.cnblogs.com，就直接返回对应的" target="_blank" rel="noopener">www.cnblogs.com，就直接返回对应的</a> IP 地址。如果没有找到，本地 DNS 会去问它的根域名服务器；</li><li><strong>根 DNS 收到来自本地 DNS 的请求，返回 .com 对应的顶级域名服务器的地址</strong>。根域名服务器是最高层次的，全球共有 13 套，它不直接用于域名解析，而是指明怎样去查找对应 IP。它发现请求的域名后缀是 .com，就会返回 .com 对应的顶级域名服务器的地址；</li><li><strong>本地 DNS 服务器收到顶级 DNS 服务器地址，请求顶级 DNS 服务器查询域名 IP</strong>；</li><li><strong>顶级 DNS 服务器返回权威 DNS 服务器地址</strong>。顶级域名服务器就是大名鼎鼎的，负责 .com、.net、.org 这些二级域名，比如 cnblogs.com，它会返回对应的权威 DNS 服务器地址；</li><li><strong>本地 DNS 服务器收到权威 DNS 服务器地址，请求权威 DNS 服务器查询域名 IP</strong>。而 cnblogs.com 的权威 DNS 服务器就是域名解析结果的原出处；</li><li><strong>权威 DNS 服务器返回对应 IP</strong>。权威 DNS 服务器查询“地址簿”，获取到域名对应 IP 地址，返回给本地 DNS 服务器；</li><li><strong>本地 DNS 服务器收到 IP，返回给客户端</strong>；</li><li><strong>客户端与目标建立连接</strong>。</li></ol><p>至此，我们完成了 DNS 的解析过程，整个过程如下图：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181225215156262-462153761.png" alt=""></p><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p>站在客户端角度，上述过程是一次 <strong>DNS 递归查询过程</strong>。因为本地 DNS 全权为它代劳，它只要坐等结果就好了。在这个过程中，DNS 除了可以通过名称映射为 IP 地址外，它还可以做另外一件很重要的事 - <strong>负载均衡</strong>。</p><p>还是拿我们逛沃尔玛超市为例。它可能在一个城市里会有多家店，我们要逛沃尔玛，可以<strong>就近找一家，而不用都去同一家</strong>，这就是负载均衡。</p><p>DNS 做负载均衡也有花样可以玩。<br><strong>1）DNS 做内部负载均衡</strong><br>所谓的内部负载均衡，其实很好理解。就像我们的应用访问数据库，在应用里配置的数据库地址。如果配置成 IP 地址，一旦数据库换到了另外一台机器，我们就要修改配置。如果我们有很多台应用同时连一个数据库，一换 IP，就需要将这些应用的配置全部修改一遍，是不是很麻烦？所以，我们可以将数据地址配置成<strong>域名</strong>。在更换数据库位置时，只要在 DNS 服务器里，将域名映射为新的 IP 地址就可以了。</p><p>在这个基础上，我们可以更进一步 。例如，某个应用要访问另外一个应用，如果配置另外一个应用的 IP 地址，那么这个访问就是一对一的。但是当被访问的应用因流量过大撑不住的时候，我们就需要部署多个应用。这时候，我们就不能直接配置成 IP，而是要配置域名了。只要在域名解析的时候，配置好策略，这次返回一个 IP，下次返回第二个 IP，就实现了负载均衡。</p><p><strong>2）DNS 做全局负载均衡</strong><br>为了保证我们应用的高可用性，往往会将应用部署在多个机房，每个地方都会有自己的 IP 地址。当用户访问某个域名的时候，这个 IP 地址可以轮询访问多个数据中心。如果一个数据中心因为某种原因挂了，只要将这个 IP 地址从 DNS 服务器中删掉就可以了，用户不会访问到宕机的服务器，保证了应用的可用性。</p><p>另外，我们肯定希望用户能访问就近的数据中心。这样客户访问速度就会快很多，体验也会好很多，也就实现了全局负载均衡的概念。</p><h4 id="负载均衡示例"><a href="#负载均衡示例" class="headerlink" title="负载均衡示例"></a>负载均衡示例</h4><p>我们通过 NDS 访问数据中心对象存储上的静态资源为例，来看一看整个过程。</p><p>假设全国有多个数据中心，托管在多个运营商，每个数据中心有三个可用区。对象存储可以通过跨可用区部署，实现高可用性。在每个数据中心中，都至少部署两个内部负载均衡器，内部负载均衡器后面对接多个对象存储的前置服务器（Proxy-server）。那么，请求过程如下图：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181225215101398-1249773735.png" alt=""></p><ol><li>当一个客户端要访问 object.yourcompany.com 的时候，需要将域名转换为 IP 地址进行访问，所以它要请求本地 DNS 解析器；</li><li>本地 DNS 解析器先查看本地的缓存是否有这个记录。如果有，就直接用，省略后续查询步骤，提高相应时间；</li><li>如果本地无缓存，就需要请求本地的 DNS 服务器；</li><li>本地 DNS 服务器一般部署在数据中心或者你所在的运营商网络中。本地 DNS 服务器也需要看本地是否有缓存，如果有，就直接返回；</li><li>本地没有，通过第 5、6、7 步骤获取到 IP 地址，缓存到本地 DNS 解析器中，然后在返回给客户端。</li></ol><p>对于不需要做全局负载均衡的简单应用来讲，yourcompany.com 的权威 DNS 服务器可以直接将 object.yourcompa.com 这个域名解析为一个或者多个 IP 地址，然后客户端可以通过多个 IP 地址，进行简单的轮询，实现简单的负载均衡。</p><p>但是对于复制的应用，尤其是跨地域跨运营商的大型应用，就需要更加复杂的全局负载均衡机制，因而需要专门的设备或者服务器来做这件事情，这就是<strong>全局负载均衡器（GSLB，Global Server Load Balance）</strong>。</p><p>在 yourcompany.com 的 DNS 服务器中，一般是通过配置 CNAME 的方式，给 object.yourcompany.com 起一个别名。例如  object.vip.yourcompany.com，然后告诉本地 DNS 服务器，让它请求 GSLB 解析这个域名，GSLB 就可以在解析这个域名的过程中，通过自己的策略实现负载均衡。</p><p>上图中画了两层的 GSLB，是因为分运营商和地域。我们希望不同运营商的客户，可以访问对应运营商机房中的资源，这样不跨运营商访问，有利于提高吞吐量，减少时延。两层 GSLB 的过程如下：</p><ol><li>第一层 GSLB，通过查看请求它的本地 DNS 服务器所在的运营商，就知道用户所在的运营商。假设是移动，通过 CNAME 的方式，通过另一个别名  object.yd.yourcompany.com，告诉本地 DNS 服务器去请求第二层的 GSLB；</li><li>第二层 GSLB，通过查看请求它的本地 DNS 服务器的地址，知道用户所在的地理位置，然后将距离用户位置比较近的一个 Region 的六个内部负载均衡的地址，返回给本地 DNS 服务器；</li><li>本地 DNS 服务器将结果返回给本地 DNS 解析器；</li><li>本地 DNS 解析器将结果缓存后，返回给客户端；</li><li>客户端开始访问属于相同运营商的，且距离比较近的 Region1 中的对象存储。当然，客户端得到了六个 IP 地址，它可以通过负载均衡的方式，随机或者轮询选择一个可用区进行访问。对象存储一般会有三个备份，从而实现对存储读写的负载均衡。</li></ol><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>DNS 是网络世界的地址簿。可以通过域名查地址，因为域名服务器是按照树状结构组织的，因而域名查找是使用递归查询的方式，并通过缓存的方式加快效率；</li><li>在域名和 IP 的映射中，给了应用基于域名做负载均衡的机会，可以是简单的负载均衡，也可以是根据地址和运营商做的全局负载均衡。</li></ul><p>参考：</p><ol><li>维基百科-域名系统 词条；</li><li><a href="https://www.zhihu.com/question/23042131" target="_blank" rel="noopener">知乎-域名解析</a>；</li><li>刘超 - 趣谈网络协议系列课；</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 负载均衡 </tag>
            
            <tag> DNS协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 15 - P2P 协议：小种子大学问</title>
      <link href="/12/wangluoxieyi/ck0669dwt0071agaazv2d95ol/"/>
      <url>/12/wangluoxieyi/ck0669dwt0071agaazv2d95ol/</url>
      
        <content type="html"><![CDATA[<p>“兄弟，有种子吗？”<br>“什么种子？小麦种吗？”<br>“……，来，哥今天带你认识下什么是种子”。</p><p>大家说起种子，应该都知道是用来下载资源的。那么资源下载都有哪些方式？种子下载又有什么优势呢？</p><h3 id="下载电影的两种方式"><a href="#下载电影的两种方式" class="headerlink" title="下载电影的两种方式"></a>下载电影的两种方式</h3><p>第一种是通过 HTTP 进行下载。这种方式，有过经历的人应该体会到，当下载文件稍大点，下载速度简直能把人急死。</p><p>第二种方式就是是<strong>通过 FTP（文件传输协议）</strong>。FTP 采用两个 TCP 连接来传输一个文件。</p><ol><li><strong>控制连接</strong>。服务器以被动的方式，打开众所周知用于 FTP 的端口 21，客户端则主动发起连接。该连接将<strong>命令</strong>从客户端传给服务器，并传回服务器的<strong>应答</strong>。常用的命令有：lsit - 获取文件目录，reter - 取一个文件，store - 存一个文件；</li><li><strong>数据连接</strong>。每当一个文件在客户端与服务器之间传输时，就创建一个数据连接。</li></ol><h3 id="FTP-的工作模式"><a href="#FTP-的工作模式" class="headerlink" title="FTP 的工作模式"></a>FTP 的工作模式</h3><p>在 FTP 的两个 TCP 连接中，每传输一个文件，都要新建立一个数据连接。基于这个数据连接，FTP 又有两种工作模式：<strong>主动模式（PORT）</strong>和<strong>被动模式（PASV）</strong>，要注意的是，这里的主动和被动都是站在服务器角度来说的。工作模式过程如下：</p><p> <strong>主动模式工作流程</strong></p><ol><li>客户端随机打开一个大于 1024 的端口 N，向服务器的<strong>命令端口 21</strong> 发起连接，同时开放 N+1 端口监听，并向服务器发出“port N+1” 命令；</li><li>由服务器从自己的数据端口 20，<strong>主动连接到客户端指定的数据端口 N+1</strong>。</li></ol><p><strong>被动模式工作流程</strong></p><ol><li>客户端在开启一个 FTP 连接时，打开两个任意的本地端口 N（大于1024）和 N+1。然后用 N 端口连接服务器的 21 端口，提交 PASV 命令；</li><li>服务器收到命令，开启一个任意的端口 P（大于 1024），返回“227 entering passive mode”消息，消息里有服务器开放的用来进行数据传输的端口号 P。</li><li>客户端收到消息，取得端口号 P，通过 N+1 端口连接服务器的 P 端口，进行数据传输。</li></ol><p>上面说了 HTTP 下载和 FTP 下载，这两种方式都有一个大缺点-<strong>难以解决单一服务器的带宽压力</strong>。因为它们使用的都是传统 C/S 结构，这种结构会随着客户端的增多，下载速度越来越慢。这在当今互联网世界显然是不合理的，我们期望能实现“下载人数越多，下载速度不变甚至更快”的愿望。</p><p>后来，一种创新的，称为 P2P 的方式实现了我们的愿望。</p><h3 id="P2P"><a href="#P2P" class="headerlink" title="P2P"></a>P2P</h3><p>P2P 就是 peer-to-peer。这种方式的特点是，资源一开始并不集中存储在某些设备上，而是分散地存储在多台设备上，这些设备我们称为 peer。</p><p>在下载一个文件时，只要得到那些已经存在了文件的 peer 地址，并和这些 peer 建立点对点的连接，就可以就近下载文件，而不需要到中心服务器上。一旦下载了文件，你的设备也就称为这个网络的一个 peer，你旁边的那些机器也可能会选择从你这里下载文件。</p><p>通过这种方式解决上面 C/S 结构单一服务器带宽压力问题。如果使用过 P2P2 软件，例如 BitTorrent，你就会看到自己网络不仅有下载流量，还有上传流量，也就是说你加入了这个 P2P 网络，自己可以从这个网络里下载，同时别人也可以从你这里下载。这样就实现了，<strong>下载人数越多，下载速度越快的愿望</strong>。</p><h4 id="种子文件（-torent）"><a href="#种子文件（-torent）" class="headerlink" title="种子文件（.torent）"></a>种子文件（.torent）</h4><p>上面整个过程是不是很完美？是的，结果很美好，但为了实现这个美好，我们还是有很多准备工作要做的。比如，我们怎么知道哪些 peer 有某个文件呢？</p><p>这就用到我们常说的<strong>种子（.torrent）</strong>。 .torrent 文件由<strong>Announce（Tracker URL）</strong>和<strong>文件信息</strong>两部分组成。</p><p>其中，文件信息里有以下内容：</p><ul><li><strong>Info 区</strong>：指定该种子包含的文件数量、文件大小及目录结构，包括目录名和文件名；</li><li><strong>Name 字段</strong>：指定顶层目录名字；</li><li><strong>每个段的大小</strong>：BitTorrent（BT）协议把一个文件分成很多个小段，然后分段下载；</li><li><strong>段哈希值</strong>：将整个种子种，每个段的 SHA-1 哈希值拼在一起。</li></ul><p>下载时，BT 客户端首先解析 .torrent 文件，得到 Tracker 地址，然后连接 Tracker 服务器。Tracker 服务器回应下载者的请求，将其他下载者（包括发布者）的 IP 提供给下载者。</p><p>下载者再连接其他下载者，根据 .torrent 文件，两者分别对方自己已经有的块，然后交换对方没有的数据。</p><p>可以看到，下载的过程不需要其他服务器参与，并分散了单个线路上的数据流量，减轻了服务器的压力。</p><p>下载者每得到一个块，需要算出下载块的 Hash 验证码，并与 .torrent 文件中的进行对比。如果一样，说明块正确，不一样就需要重新下载这个块。这种规定是为了解决下载内容的准确性问题。</p><p>从这个过程也可以看出，这种方式特别依赖 Tracker。Tracker 需要收集所有 peer 的信息，并将从信息提供给下载者，使下载者相互连接，传输数据。虽然下载的过程是非中心化的，但是加入这个 P2P 网络时，需要借助 Tracker 中心服务器，这个服务器用来登记有哪些用户在请求哪些资源。</p><p>所以，这种工作方式有一个弊端，一旦 Tracker 服务器出现故障或者线路被屏蔽，BT 工具就无法正常工作了。那能不能彻底去中心化呢？答案是可以的。</p><h4 id="去中心化网络（DHT）"><a href="#去中心化网络（DHT）" class="headerlink" title="去中心化网络（DHT）"></a>去中心化网络（DHT）</h4><p><strong>DHT（Distributed Hash Table）</strong>，这个网络中，每个加入 DHT 网络的人，都要负责存储这个网络里的资源信息和其他成员的联系信息，相当于所有人一起构成了一个庞大的分布式存储数据库。</p><p>而 <strong>Kedemlia 协议</strong> 就是一种著名的 DHT 协议。我们来基于这个协议来认识下这个神奇的 DHT 网络。</p><p>当一个客户端启动 BitTorrent 准备下载资源时，这个客户端就充当了两个角色：</p><ol><li>peer 角色：监听一个 TCP 端口，用来上传和下载文件。对外表明我这里有某个文件；</li><li>DHT Node 角色：监听一个 UDP 端口，通过这个角色，表明这个节点加入了一个 DHT 网络。</li></ol><p>在 DHT 网络里面，每一个 DHT Node 都有一个 ID。这个 ID 是一个长字符串。每个 DHT Node 都有责任掌握一些“知识”，也就是<strong>文件索引</strong>。也就是说，每个节点要知道哪些文件是保存哪些节点上的。注意，这里它只需要有这些“知识”就可以了，而它本身不一定就是保存这个文件的节点。</p><p>当然，每个 DHT Node 不会有全局的“知识”，也就是说它不知道所有的文件保存位置，只需要知道一部分。这里的一部分，就是通过哈希算法计算出来的。</p><h5 id="Node-ID-和文件哈希值"><a href="#Node-ID-和文件哈希值" class="headerlink" title="Node ID 和文件哈希值"></a>Node ID 和文件哈希值</h5><p>每个文件可以计算出一个哈希值，而 <strong>DHT Node 的 ID 是和哈希值相同长度的串</strong>。</p><p>对于文件下载，DHT 算法是这样规定的：</p><blockquote><p>如果一个文件计算出一个哈希值，则和这个哈希值一样的那个 DHT Node，就有责任知道从哪里下载这个文件，即便它自己没保存这个文件。</p></blockquote><p>当然不一定总这么巧，都能找到和哈希值一模一样的，有可能文件对应的 DHT Node 下线了，所以 DHT 算法还规定：</p><blockquote><p>除了一模一样的那个 DHT Node 应该知道文件的保存位置，ID 和这个哈希值非常接近的 N 个 DHT Node 也应该知道。</p></blockquote><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181223223107137-132740073.png" alt=""></p><p>以上图为例。文件 1 通过哈希运算，得到匹配 ID 的 DHT Node 为 Node C（当然还会有其他的，为了便于理解，咱们就先关注 Node C），所以，Node C 就有责任知道文件 1 的存放地址，虽然 Node C 本身没有存放文件 1。</p><p>同理，文件 2 通过哈希计算，得到匹配 ID 的 DHT Node 为 Node E，但是 Node D 和 E 的值很近，所以 Node D 也知道。当然，文件 2 本身不一定在 Node D 和 E 这里，但是我们假设 E 就有一份。</p><p>接下来，一个新节点 Node new 上线了，如果要下载文件 1，它首先要加入 DHT 网络。如何加入呢？</p><p>在这种模式下，种子 .torrent 文件里面就不再是 Tracker 的地址了，而是一个 list 的 Node 地址，所有这些 Node 都是已经在 DHT 网络里面的。当然，随着时间的推移，很有可能有退出的，有下线的，这里我们假设，不会所有的都联系不上，总有一个能联系上。</p><p>那么，Node new 只要在种子里面找到一个 DHT Node，就加入了网络。</p><p>Node new 不知道怎么联系上 Node C，因为种子里面的 Node 列表里面很可能没有 Node C，但是没关系，它可以问。DHT 网络特别像一个社交网络，Node new 会去它能联系上的 Node 问，你们知道 Node C 的联系方式吗？</p><p>在 DHT 网络中，<strong>每个 Node 都保存了一定的联系方式，但是肯定没有所有 Node 的联系方式</strong>。节点之间通过相互通信，会交流联系方式，也会删除联系方式。这和人们的沟通方式一样，你有你的朋友圈，他有他的朋友圈，你们互相加微信，就互相认识了，但是过一段时间不联系，就可能会删除朋友关系一样。</p><p>在社交网络中，还有个著名的<strong>六度理论</strong>，就是说社交网络中的<strong>任何两个人的直接距离不超过六度</strong>，也就是即使你想联系比尔盖茨，最多通过六个人就能够联系上。</p><p>所以，Node New 想联系 Node C，就去万能的朋友圈去问，并且求转发，朋友再问朋友，直到找到 C。如果最后找不到 C，但是能找到离 C 很近的节点，也可以通过 C 的相邻节点下载文件 1。</p><p>在 Node C上，告诉 Node new，要下载文件 1，可以去 B、D、F，这里我们假设 Node new 选择了 Node B，那么新节点就和 B 进行 peer 连接，开始下载。它一旦开始下载，自己本地也有文件 1 了，于是，Node new 就告诉 C 以及 C 的相邻节点，我也有文件 1 了，可以将我加入文件 1 的拥有者列表了。</p><p>你可能会发现，上面的过程中漏掉了 Node new 的文件索引，但是根据哈希算法，一定会有某些文件的哈希值是和 Node new 的 ID 匹配的。在 DHT 网络中，会有节点告诉它，你既然加入了咱们这个网络，也就有责任知道某些文件的下载地址了。</p><p>好了，完成分布式下载了。但是我们上面的过程中遗留了两个细节性的问题。</p><p><strong>1）DHT Node ID 以及文件哈希值是什么？</strong><br>其实，我们可以将节点 ID 理解为一个 160bits（20字节）的字符串，文件的哈希也使用这样的字符串。</p><p><strong>2）所谓 ID 相似，具体到什么程度算相似？</strong><br>这里就要说到两个节点距离的定义和计算了。</p><p>在 Kademlia 网络中，两个节点的距离采用的是逻辑上的距离，假设节点 A 和 节点 B 的距离为 d，则：</p><blockquote><p>d = A XOR B</p></blockquote><p>上面说过，每个节点都有一个哈希 ID，这个 ID 由 20 个字符，160 bits 位组成。这里，我们就用一个 5 bits ID 来举例。<br>我们假设，节点 A 的 ID 是 01010，节点 B 的 ID 是 01001，则：</p><blockquote><p>距离 d = A XOR B = 01010 XOR 00011 = 01001 = 9</p></blockquote><p>所以，我们说节点 A 和节点 B 的逻辑距离为 9。</p><p>回到我们上面的问题，哈希值接近，可以理解为距离接近，也即，<strong>和这个节点距离近的 N 个节点要知道文件的保存位置</strong>。</p><p>要注意的是，这个距离不是地理位置，因为在 Kademlia 网络中，位置近不算近，ID 近才算近。我们可以将这个距离理解为<strong>社交距离</strong>，也就是在朋友圈中的距离，或者社交网络中的距离。这个和你的空间位置没有多少关系，和人的经历关系比较大。</p><h5 id="DHT-网络节点关系的维护"><a href="#DHT-网络节点关系的维护" class="headerlink" title="DHT 网络节点关系的维护"></a>DHT 网络节点关系的维护</h5><p>就像人一样，虽然我们常联系的只有少数，但是朋友圈肯定是远近都有。DHT 网络的朋友圈也一样，远近都有，并且<strong>按距离分层</strong>。</p><p>假设某个节点的 ID 为 01010，如果一个节点的 ID，前面所有位数都与它相同，只有最后 1 位不停，这样的节点只有 1 个，为 01011。与基础节点的异或值为 00001，也就是距离为 1。那么对于 01010 而言，这样的节点归为第一层节点，也就是<strong>k-buket 1</strong>。</p><p>类似的，如果一个节点的 ID，前面所有位数和基础节点都相同，从倒数第 2 位开始不同，这样的节点只有 2 个，即 01000 和 01001，与基础节点的亦或值为 00010 和 00011，也就是距离为 2 和 3。这样的节点归为第二层节点，也就是<strong>k-bucket 2</strong>。</p><p>所以，我们可以总结出以下规律：</p><blockquote><p>如果一个节点的 ID，前面所有位数相同，从倒数第 i 位开始不同，这样的节点只有 2^(i-1) 个，与基础节点的距离范围为 [2^(i-1), 2^i]，对于原始节点而言，这样的节点归为<strong>k-bucket i</strong>。</p></blockquote><p>你会发现，差距越大，陌生人就越多。但是朋友圈不能把所有的都放下，所以每一层都只放 K 个，这个 K 是可以通过参数配置的。</p><h5 id="DHT-网络中查找好友"><a href="#DHT-网络中查找好友" class="headerlink" title="DHT 网络中查找好友"></a>DHT 网络中查找好友</h5><p>假设，Node A 的 ID 为 00110，要找 B（10000），异或距离为 10110，距离范围在 [2^4, 2^5)，这就说明 B 的 ID 和 A 的从第 5 位开始不同，所以 B 可能在 k-bucket 5 中。</p><p>然后，A 看看自己的 k-bucket 5 有没有 B，如果有，结束查找。如果没有，就在 k-bucket 5 里随便找一个 C。因为是二进制，C、B 都和 A 的第 5 位不停，那么 C 的 ID 第5 位肯定与 B 相同，即它与 B 的距离小于 2^4，相当于 A、B 之间的距离缩短了一半以上。</p><p>接着，再请求 C，在 C 的通讯里里，按同样的查找方式找 B，如果 C 找到了 B，就告诉 A。如果 C 也没有找到 B，就按同样的搜索方法，在自己的通讯里里找到一个离 B 更近一步的 D（D、B 之间距离小于 2^3），把 D 推荐给 A，A 请求 D 进行下一步查找。</p><p>你可能已经发现了，Kademlia 这种查询机制，是通过<strong>折半查找</strong>的方式来收缩范围，对于总的节点数目为 N 的网络，最多只需要 log2(N) 次查询，就能够找到目标。</p><p>如下图，A 节点找 B 节点，最坏查找情况：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181223223149837-1310321834.png" alt=""></p><p>图中过程如下：</p><ol><li>A 和 B 的每一位都不一样，所以相差 31，A 找到的朋友 C，不巧正好在中间，和 A 的距离是 16，和 B 的距离是 15；</li><li>C 去自己朋友圈找，碰巧找到了 D，距离 C 为 8，距离 B 为 7；</li><li>D 去自己朋友圈找，碰巧找到了 E，距离 D 为 4，距离 B 为 3；</li><li>E 在自己朋友圈找，找到了 F，距离 E 为 2，距离 B 为 1；</li><li>F 在距离为 1 的地方找到了 B。</li></ol><h5 id="节点的沟通"><a href="#节点的沟通" class="headerlink" title="节点的沟通"></a>节点的沟通</h5><p>在 Kademlia 算法中，每个节点下面 4 个指令：</p><ul><li>PING：测试一个节点是否在线。相当于打个电话，看还能打通不；</li><li>STORE：要钱一个节点存储一份数据；</li><li>FIND_NODE：根据节点 ID 查找一个节点；</li><li>FIND_VALUE：根据 KEY 查找一个数据，实则上和 FIND_NODE 非常类似。KEY 就是文件对应的哈希值，找到保存文件的节点。</li></ul><h5 id="节点的更新"><a href="#节点的更新" class="headerlink" title="节点的更新"></a>节点的更新</h5><p>整个 DHT 网络，会通过相互通信，维护自己朋友圈好友的状态。</p><ul><li>每个 bucket 里的节点，都按最后一次接触时间<strong>倒序排列</strong>。相当于，朋友圈里最近联系的人往往是最熟的；</li><li>每次执行四个指令中的任意一个都会触发更新；</li><li>当一个节点与自己接触时，检查它是否已经在 k-bucket 中。就是说是否已经在朋友圈。如果在，那么就将它移到 k-bucket 列表的最底，也就是最新的位置（刚联系过，就置顶下，方便以后多联系）。如果不在，就要考虑新的联系人要不要加到通讯录里面。假设通讯录已满，就 PING 一下列表最上面的节点（最旧的），如果 PING 通了，将旧节点移动到列表最底，并丢弃新节点（老朋友还是要留点情面的）。如 PING 不同，就删除旧节点，并将新节点加入列表（联系不上的老朋友还是删掉吧）。</li></ul><p>通过上面这个机制，保证了任意节点的加入和离开都不影响整体网络。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>下载一个文件可以通过 HTTP 或 FTP。这两种都是<strong>集中下载</strong>的方式，而 P2P 则换了一种思路，采用非中心化下载的方式；</li><li>P2P 有两种。一种是依赖于 Tracker 的，也就是元数据集中，文件数据分散。另一种是基于分布式的哈希算法，元数据和文件数据全部分散。</li></ul><p>参考：</p><ol><li>维基百科-DHT 网络词条；</li><li>维基百科-Kademlia 词条；</li><li>刘超 - 趣谈网络协议系列课；</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> P2P协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 14 - 流媒体协议：要说爱你不容易</title>
      <link href="/12/wangluoxieyi/ck0669dtd003wagaax9p0d2x5/"/>
      <url>/12/wangluoxieyi/ck0669dtd003wagaax9p0d2x5/</url>
      
        <content type="html"><![CDATA[<p>大家都会关注“在浏览器输入一个地址，然后回车，会发生什么”这样一个问题，但是有没有想过这样一个问题：主播开始直播，用户打开客户端观看，这个过程发生了什么？</p><p>随着技术的发展，直播技术对人们生活的渗透日益加深。从最开始的游戏直播，到前几天爆出来的教育直播，甚至现在都有直播招聘。</p><p>而我们喜欢的这些直播，他们用到的传输协议有一个通用名-<strong>流媒体传输协议</strong>。</p><p>要认识流媒体协议，就离不开下面的三大系列名词。</p><h3 id="三大系列名词"><a href="#三大系列名词" class="headerlink" title="三大系列名词"></a>三大系列名词</h3><ul><li>系列一：AVI、MPEG、RMVB、MP4、MOV、FLV、WebM、WMV、ASF、MKV。是不是就 MP4 看着熟悉？</li><li>系列二：H.261、H.262、H.263、H.264、H.265。能认出来几个？别着急，重点关注 H.264。</li><li>系列三：MPEG-1、MPEG-2、MPEG-4、MPEG-7。是不是更懵逼了？</li></ul><p>在解释上面的三大系列名词之前，咱们先来了解下，视频究竟是什么？</p><p>博主记得小时候，经常会玩一种叫动感画册的东西。一本很小的画册上，每一页都画了一幅图，用手快速的翻过每一页，就能看到一个很短的“动画片”。</p><p>没错，咱们看到的视频，本质上就是<strong>一连串快速播放的图片</strong>。</p><p>每一张图片，我们称为<strong>一帧</strong>。只要每秒钟的数据足够多，也就是播放速度足够快，人眼就看不出是一张张独立的图片。对于人眼而言，这个播放临界速度是<strong>每秒 30 帧</strong>，而这里的 30 也就是我们常说的<strong>帧率（FPS)</strong>。</p><p>每一张图片，都是由<strong>像素</strong>组成，而每个像素又是由 RGB 组成，每个 8 位，共 24 位。</p><p>我们假设一个视频中的所有图片的像素都是 1024*768，可以大概估算下视频的大小：</p><blockquote><p>每秒钟大小 = 30 帧 x 1024 x 768 x 24 = 566,231,010 Bits = 70,778,880 Bytes</p></blockquote><p>按我们上面的估算，一分钟的视频大小就是 4,,246,732,800 Bytes，这里已经有 4 个 G 了。</p><p>是不是和我们日常接触到的视频大小明显不符？这是因为我们在传输的过程中，<strong>将视频压缩了</strong>。</p><p>为什么要压缩视频？按我们上面的估算，一个一小时的视频，就有 240G，这个数据量根本没办法存储和传输。因此，人们利用<strong>编码技术</strong>，给视频“瘦身”，用尽量少的 Bit 数保持视频，同时要保证播放的时候，画面仍然很清晰。实际上，<strong>编码就是压缩的过程</strong>。</p><h3 id="视频和图片的压缩特点"><a href="#视频和图片的压缩特点" class="headerlink" title="视频和图片的压缩特点"></a>视频和图片的压缩特点</h3><p>我们之所以能够对视频流中的图片进行压缩，因为视频和图片有下列这些特点：</p><ol><li><strong>空间冗余</strong>：图像的相邻像素之间有较强的相关性，一张图片相邻像素往往是渐变的，而不是突变的，没必要每个像素都完整的保存，可以隔几个保存一个，中间的用算法计算出来。</li><li><strong>时间冗余</strong>：视频序列的相邻图像之间内容相似。一个视频中连续出现的图片也不是突变的，可以根据已有的图片进行预测和推断。</li><li><strong>视觉冗余</strong>：人的视觉系统对某些细节不敏感，因此不会注意到每一个细节，可以允许丢失一些数据。</li><li><strong>编码冗余</strong>：不同像素值出现的概率不同，概率高的用的字节少，概率低的用的字节多，类似<strong>霍夫曼编码</strong>的思路。</li></ol><p>从上面这些特点中可以看出，用于编码的算法非常复杂，而且多种多样。虽然算法多种，但编码过程实际上是类似的，如下图：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181219095437679-259130497.png" alt=""></p><h3 id="视频编码的两大流派"><a href="#视频编码的两大流派" class="headerlink" title="视频编码的两大流派"></a>视频编码的两大流派</h3><p>视频编码的算法这么多，能不能形成一定的标准呢？当然能，这里咱们就来认识下视频编码的两大流派。</p><ul><li>流派一：ITU（International tELECOMMUNICATIONS Union）的 VCEG（Video Coding Experts Group），这个称为<strong>国际电联下的 VCEG</strong>。既然是电信，可想而知，他们最初是做视频编码，主要侧重<strong>传输</strong>。我们上面的系列名词二，就是这个组织制定的标准。</li><li>流派二：ISO（International Standards Organization）的 MPEG（Moving Picture Experts Group），这个是 <strong>ISO 旗下的 MPEG</strong>。本来是做视频存储的，就像咱们场面常说的 VCD 和 DVD。后来也慢慢侧重视频传输了。系列名词三就是这个组织制定的标准。</li><li>后来，ITU-T（国际电信联盟电信标准化部门）与 MPEG 联合制定了 H.264/MPEG-4 AVC，这也是我们重点关注的。</li></ul><h3 id="直播数据传输"><a href="#直播数据传输" class="headerlink" title="直播数据传输"></a>直播数据传输</h3><p>视频经过编码之后，生动活泼的一帧帧图像就变成了一串串让人看不懂的二进制。这个二进制可以放在一个文件里，然后按照一定的格式保存起来，这里的<strong>保存格式</strong>，就是系列名词一。</p><p>编码后的二进制文件就可以通过某种网络协议进行封装，放在互联网上传输，这个时候就可以进行网络直播了。</p><p>网络协议将编码好的视频流，从主播端推送到服务器，在服务器上有个运行了同样协议的服务端来接收这些网络数据包，从而得到里面的视频流，这个过程称为<strong>接流</strong>。</p><p>服务端接到视频流之后，可以滴视频流进行一定的处理，比如<strong>转码</strong>，也就是从一个编码格式转成另一种格式，这样才能适应各个观众使用的客户端，保证他们都能看到直播。</p><p><strong>流处理</strong>完毕后，就可以等待观众的客户端来请求这些视频流。观众的客户端请求视频流的过程称为<strong>拉流</strong>。</p><p>如果有非常多的观众同时看一个视频直播，都从一个服务器上<strong>拉流</strong>，压力就非常大，因此需要一个视频的<strong>分发网络</strong>，将视频预先加载到就近的边缘节点，这样大部分观众就能通过边缘节点拉取视频，降低服务器的压力。</p><p>当观众将视频流拉下来后，就需要进行<strong>解码</strong>，也就是通过上述过程的逆过程，将一串串看不懂的二进制转变成一帧帧生动的图片，在客户端播放出来。</p><p>整个直播过程，可以用下图来描述：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181219095506532-578796935.png" alt=""></p><p>接下来，我们依次来看一下每个过程：</p><h4 id="编码：将丰富多彩的图片变成二进制流"><a href="#编码：将丰富多彩的图片变成二进制流" class="headerlink" title="编码：将丰富多彩的图片变成二进制流"></a>编码：将丰富多彩的图片变成二进制流</h4><p>虽然我们说视频是一张张图片的序列，但如果每张图片都完整，就太大了，因而会将视频序列分成三种帧：</p><ul><li><strong>I帧</strong>，也称<strong>关键帧</strong>。里面是完整的图片，只需要本帧数据，就可以完成解码。</li><li><strong>P帧</strong>，前向预测编码帧。P 帧表示的是这一帧跟之前一个关键帧（或 P 帧）的差别，解码时需要用之前缓存的画面，叠加上和本帧定义的差别，生成最终画面。</li><li><strong>B帧</strong>，双向预测内插编码帧。B 帧记录的是本帧与前后帧的差别。要解码 B 帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的数据与本帧数据的叠加，取得最终的画面。</li></ul><p>可以看出，I 帧最完整，B 帧压缩率最高，而压缩后帧的序列，应该是 IBBP 间隔出现。这就是<strong>通过时序进行编码</strong>。</p><p>在一帧中，分成多个片，每个片中分成多个宏块，每个宏块分成多个子块，这样将一张大图分解成一个个小块，可以方便进行<strong>空间上的编码</strong>。如下图：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181219095521595-1319647957.png" alt=""></p><p>尽管时空非常立体的组成了一个序列，但总归还是要压缩成一个二进制流。这个流是有结构的，是一个个的<strong>网络提取层单元（NALU，Network Abstraction Layer Unit）</strong>。变成这种格式就是为了传输，因为网络上的传输，默认的是一个个的包，因而这里也就分成了一个个的单元。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181219095557700-1247930589.png" alt=""></p><p>如上图，每个 NALU 首先是一个起始标识符，用于标识 NALU 之间的间隔。然后是 NALU 的头，里面主要配置了 NALU 的类型。最后的 Payload 里面是 NALU 承载的数据。</p><p>在 NALU 头里面，主要的内容是类型 NAL Type，其中：</p><ul><li>0x07 表示 SPS，是序列参数集，包括一个图像序列的所有信息，如图像尺寸、视频格式等。</li><li>0x08 表示 PPS，是图像参数集，包括一个图像的所有分片的所有相关信息，包括图像类型、序列号等。</li></ul><p>在传输视频流之前，剥削要传输者两类参数，不然就无法解码。为了保证容错性，每一个 I 帧之前，都会传一遍这两个参数集合。</p><p>如果 NALU Header 里面的表示类型是 SPS 或 PPS，则 Payload 中就是真正的参数集的内容。</p><p>如果类型是帧，则 Payload 中是真正的视频数据。当然也是一帧帧保存的。前面说了，一帧的内容还是挺多的，因而每一个 NALU 里面保存的是一片。对于每一片，到底是 I 帧，还是 P 帧，亦或是 B 帧，在片结构里面也有 Header，这里面有个类型用来标识帧的类型，然后是片的内容。</p><p>这样，整个格式就出来了。<strong>一个视频，可以拆分成一系列的帧，每一帧拆分成一系列的片，每一片都放在一个 NALU 里面，NALU 之间都是通过特殊的起始标识符分隔，在每一个 I 帧的第一片前面，要插入单独保存 SPS 和 PPS 的 NALU，最终形成一个长长的 NALU 序列</strong>。</p><h4 id="推流：将数据流打包传输到对端"><a href="#推流：将数据流打包传输到对端" class="headerlink" title="推流：将数据流打包传输到对端"></a>推流：将数据流打包传输到对端</h4><p>形成 NALU 序列后，还需要将这个二进制的流打包成网络包进行发送。这里我们以 RTMP 协议为例，进入第二个过程，<strong>推流</strong>。</p><p>RTMP 是基于 TCP 的，因而也需要双方建立一个 TCP 连接。在有 TCP 的连接的基础上，还需要建立一个 RTMP 连接，也就是在程序里面，我们调用 RTMP 类库的 Connet 函数，显式创建一个连接。</p><p>RTMP 为什么需要建立一个单独的连接呢？</p><p>因为通信双方需要商量一些事情，保证后续的传输能正常进行。其实主要就是两个事情：</p><ol><li>确定版本号。如果客户端、服务端的版本号不一致，就不能正常工作；</li><li>确定时间戳。视频播放中，时间是很重要的一个元素，后面的数据流互通的时候，经常要带上时间戳的差值，因而一开始双方就要知道对方的时间戳。</li></ol><p>沟通这些事情，需要发送 6 条消息：</p><ul><li>客户端发送 C0、C1、C2</li><li>服务端发送 S0、S1、S2</li></ul><p>首先，客户端发送 C0 表示自己的版本号，不必等对方回复，然后发送 C1 表示自己的时间戳。</p><p>服务器只有在收到 C0 的时候，才会返回 S0，表明自己的版本号，如果版本不匹配，可以断开连接。</p><p>服务器发送完 S0 后，也不用等待，就直接发送自己的时间戳 S1。</p><p>客户端收到 S1 时，发一个知道了最烦时间戳的 ACK C2。同理，服务器收到 C1 的时候，发一个知道了对方时间戳的 ACK S2。</p><p>于是，握手完成。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181219095619231-389417433.png" alt=""></p><p>握手之后，双方需要互相传递一些控制信息，例如 Chunk 块的大小、窗口大小等。</p><p>真正传输数据的时候，还是需要创建一个流 Stream，然后通过这个 Stream 来推流。</p><p>推流的过程，就是讲 NALU 放在 Message 里面发送，这个也称为 <strong>RTMP Packet 包</strong>。其中，Message 的格式就像下图所示：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181219095632060-873642705.png" alt=""></p><p>发送的时候，去掉 NALU 的起始标识符。因为这部分对于 RTMP 协议来讲没有用。接下来，将 SPS 和 PPS 参数集封装成一个 RTMP 包发送，然后发送一个个片的 NALU。</p><p>RTMP 在收发数据的时候并不是以 Message 为单位的，而是把 Message 拆分成 Chunk 发送，而且必须在一个 Chunk 发送完成之后，才能开始发送下一个 Chunk。每个 Chunk 中都带有 Message ID，表示属于哪个 Message，接收端也会按照这个 ID 将 Chunk 组装成 Message。</p><p>前面连接的时候，设置 Chunk 块大小就是指这个 Chunk。将大的消息变为小的块再发送，可以在低带宽的情况下，减少网络拥塞。</p><p>下面用一个分块的示例，来了解下 RTMP 是如何分块的。</p><p>假设一个视频的消息长度是 307，而 Chunk 大小约定为 128，那么消息就会被拆分为 3 个 Chunk。</p><p>第一个 Chunk 的 Type = 0，表示 Chunk 头是完整的。头里面 Timestamp 为 1000，总长度 Length 为 307，类型为 9，是个视频，Stream ID 为 12346，正文部分承担 128 个字节的 Data。</p><p>第二个 Chunk 也要发送 128 个字节，但是由于 Chunk 头和第一个一样，因此它的 Chunk Type = 3，表示头和第一个 Chunk 一样。</p><p>第三个 Chunk 要发送的 Data 的长度为 51 个字节，Chunk Type 还是用的 3。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181219095650914-2078070730.png" alt=""></p><p>就这样，数据源源不断的到达流媒体服务器，整个过程就像下图：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181219095718680-348946359.png" alt=""></p><p>这个时候，大量观看直播的观众就可以通过 RTMP 协议从流媒体服务器上拉取。为了减轻服务器压力，我们会使用<strong>分发网络</strong>。</p><p>分发网络分为<strong>中心</strong>和<strong>边缘</strong>两层。边缘层服务器部署在全国各地及横跨各大运营商里，和用户距离很近。而中心层是流媒体服务集群，负责内容的转发。</p><p>智能负载均衡系统，根据用户的地理位置信息，就近选择边缘服务器，为用户提供推/拉流服务。中心层也负责转码服务。例如，将 RTMP 协议的码流转换成 HLS 码流。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181219095734336-847048556.png" alt=""></p><h4 id="拉流：观众的客户端看到直播视频"><a href="#拉流：观众的客户端看到直播视频" class="headerlink" title="拉流：观众的客户端看到直播视频"></a>拉流：观众的客户端看到直播视频</h4><p>接下来，我们再来看看观众通过 RTMP 拉流的过程。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181219095753598-1034574842.png" alt=""></p><p>先读到的是 H.264 的解码参数，例如 SPS 和 PPS，然后对收到的 NALU 组成一个个帧，进行解码，交给播放器播放，这样客户端就能看到直播视频了。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>视频名词比较多，编码两大流派达成了一致，都是通过时间、空间的各种算法来压缩数据；</li><li>压缩好的数据，为了传输而组成一系列的 NALU，按照帧和片依次排列；</li><li>排列好的 NALU，在网络传输的是，要按照 RTMP 包的格式进行包装，RTMP 的包会拆分成 Chunk 进行传输；</li><li>推送到流媒体集群的视频流经过转码和分发，可以被客户端通过 RTMP 协议拉取，然后组合成 NALU，解码成视频格式进行播放。</li></ul><p>参考：</p><ol><li>RTMP 协议规范；</li><li>刘超 - 趣谈网络协议系列课；</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 流媒体协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 13 - HTTPS 协议：加密路上无尽头</title>
      <link href="/12/wangluoxieyi/ck0669do0001yagaa11v0qpxy/"/>
      <url>/12/wangluoxieyi/ck0669do0001yagaa11v0qpxy/</url>
      
        <content type="html"><![CDATA[<p>之前说了 HTTP 协议的各种问题，但是它还是陪伴着互联网、陪伴着我们走过了将近二十年的风风雨雨。现在有很多新的协议尝试去取代它，来解决性能、效率等问题，但它还还能靠着“多年的情分”活的滋润。然而，近些年，因为致命的安全问题，它不得不升级成 HTTPS 了。</p><p>就拿我们叫外卖来说，我们点外卖的数据包被黑客截获，然后在服务器回复你之前给你回复一个假消息：“好啊，你该付款了，把银行卡号、密码拿来。”，这时如果你真的把卡号和密码发给他，那你的钱包就真的危险了。</p><p>为了解决这些问题，我们给 HTTP 引入了加密，变成了 HTTPS。大家千万不要以为 HTTPS 是个新的协议，它实际上就是：</p><blockquote><p>HTTPS = HTTP + SSL 层</p></blockquote><p>这里的 SSL 层的主要工作就是加密。加密方式一般分为两种：<strong>对称加密</strong>和<strong>非对称加密</strong>。</p><p>这两种加密算法，对称加密要比非对称加密的效率要高很多，性能也好很多，所以交互的场景下多用对称加密。</p><h3 id="对称加密"><a href="#对称加密" class="headerlink" title="对称加密"></a>对称加密</h3><p>在对称加密算法中，<strong>加密和解密的密钥是相同的</strong>。也就是说，加密和解密使用的是同一个密钥。因此，使用者一定要做好保密功能，不能让第三方知道。</p><p>假设叫外卖的你和第三方约定了一个密钥 A，你发送请求的时候用 A 进行加密，外卖网站也用 A 进行解密，这样就算黑客截获了你们的请求，但是没有正确的密钥，还是破解不了。</p><p>看起来很好的解决了黑客的问题。但是这里又引入了一个问题，你和外卖网站怎么来约定这个密钥呢？如果这个密钥在互联网上传输，就必须还得用 B 密钥来加密，否则被黑客获取到 A，你们的交互还是不安全，而且，你们又怎么约定 B 呢？所以，只能通过<strong>线下传输</strong>。</p><p>线下传输的话，看过《肖申克的救赎》的博友应该知道，安迪越狱前给瑞德约定了一个地点，让他去那里拿一个信封，里面写着他的住处。</p><p>那我们和外卖网站也可以用这样的骚操作，偷偷约定时间地点，它给你一个纸条，上面写着你们两个的密钥，然后就用这个密钥在互联网定外卖。</p><p>打住打住，上面这个操作想想都不可思议，如果最初的互联网是这样发展的话，那相信肯定活不久。</p><p>相信你也发现了，只有对称加密，就会陷入密钥安全问题的死循环里，这时候，就需要非对称加密了。</p><h3 id="非对称加密"><a href="#非对称加密" class="headerlink" title="非对称加密"></a>非对称加密</h3><p>在非对称加密中 ，加密和解密过程中使用两个不相同的密钥。一个是公开的公钥，另一个是谁都不给的私钥。<strong>公钥加密的信息，只有私钥才能解密，而私钥加密的信息，也只有公钥才能解密</strong>。</p><p>放到外面上面的叫外卖过程中，非对称加密的私钥由外卖网站保存，不会再网上传输，这样就保证了私钥的私密性。与之对应的公钥是可以在互联网上随意传播的，只要外卖网站把这个公钥给你，你们就可以安全的互通了。</p><p>还是来看我们点外卖的过程。我们用公钥加密，说“我要豆浆加油条”。黑客在中间截获了这个数据包，但是他没有私钥，没法解密数据，因此可以顺利到达外卖网站。而外卖网站用私钥把这个报文解出来，然后回复，“我知道了，你付款吧，给我卡号和密码”。</p><p>整个过程好像很安全，再也不怕黑客了。但是，先别太乐观，你的银行卡是安全了，但是外卖网站可还是有危险的。黑客有外卖网站的公钥，可以模拟发送“我要定外卖”这个信息。</p><p>为了解决这个问题，看来一对公钥私钥是不够的，客户端也需要有自己的公钥和私钥，并且客户端也要把自己的公钥给外卖网站。</p><p>这样，客户端给外卖网站发送信息的时候，用外卖网站的公钥加密，而外卖网站给客户端发送消息的时候，使用客户端的公钥。这样就算有黑客企图模拟客户端获取一些信息，或者半路截获回复信息，但是由于它没有私钥，这些信息它还是打不开。</p><p>说了那么多，相信你也发现了，非对称加密也会有同样的问题，如何将不对称加密的公钥给对方？这时有两种可行方式，一种是放在一个公网的地址上，让对方下载，另一种就是在建立连接的时候传给对方。</p><p>这两种方法也有相同的问题。作为普通网民，你怎么鉴别别人给你的公钥是对方的，而不是被黑客冒充的？要知道，<strong>每个人都是可以创建自己的公钥和私钥的</strong>，创建过程如下：</p><pre><code># bash// 创建私钥：openssl genrsa -out httpsprivate.key 1024// 根据私钥获取公钥openssl rsa -in httpsprivate.key -pubout -out httpspublic.pem</code></pre><h4 id="HTTPS-证书"><a href="#HTTPS-证书" class="headerlink" title="HTTPS 证书"></a>HTTPS 证书</h4><p>可以看到，通过工具，我们可以很容易的创建公钥和私钥，那么黑客也是可以创建的，咱们怎么知道外卖网站传过来的公钥是不是真的就是外卖网站的呢？这时候，就需要第三方机构来当这个中间人了。</p><p>这就像我们的户口本一样，每个人都可以打印出来，说是真的户口本，但是去使用的时候，人家就只认<strong>有公安局盖章的户口本</strong>。这个由权威部门颁发的称为**证书（Certificate）。</p><p>HTTPS 证书里面应该有以下内容：</p><ul><li>公钥：这是最重要的；</li><li>所有者：说明证书是属于谁的，就像户口本上的姓名和身份证号，来证明这个户口本是你的；</li><li>证书发布机构：看看你的户口本上有没有某某公安局的字样？</li><li>证书有效时间：这个和咱们身份证有效期是一个意思。</li></ul><p>说完了证书的内容，就到了下一步，怎么获取证书？这就像家里添了个小公举，去哪里上户口呢？恐怕大家都知道去公安局。与之对应的，HTTPS 也有专门负责派发证书的机构，这个机构我们称为 <strong>CA（Certificate Authrity）</strong>。而证书则可以通过下面这个命令生成：</p><blockquote><p>openssl req -key httpsprivate.key -new -out httpscertificate.req</p></blockquote><p>将这个请求发给 CA，CA 会给这个证书“盖”一个章，我们称为<strong>签名算法</strong>。这个签名用到 CA 的私钥进行签发，来保证签名不被伪造。</p><p>签名算法大概是这样工作的：一般是对信息做一个 Hash 计算，得到一个 Hash 值，这个过程是不可逆的，也就是说无法通过 Hash 值还原回原来的信息内容。再把信息发出时，把上面得到的 Hash 加密后，作为一个签名和信息一起发出去。CA 给整数签名的命令是：</p><blockquote><p>openssl x509 -req -in httpscertificate.req -CA cacertificate-pem -CAkey caprivate.key</p></blockquote><p>这个命令会返回 Signature ok，而 httpscertificate.pem 就是签名过的整数。CA 用自己的私钥给外卖网站的公钥签名，这就相当于给外卖网站背书，形成了外卖网站的证书。我们可以通过下面这个命令查看证书内容：</p><blockquote><p>openssl x509 -in httpscertificate.pem -noout -text</p></blockquote><p>证书会显示以下内容：</p><ul><li>lssuer：证书颁发者；</li><li>Subject：证书颁发给谁；</li><li>Validity：证书期限；</li><li>Public-key：公钥内容；</li><li>Sinature Algorithm：签名算法</li></ul><p>通过这种方式，我们访问外卖网站时，得到的不再是一个公钥，而是一个整数。这个证书里有发布机构 CA，你只要通过这个 CA 的公钥去解密外卖网站证书的签名，解密成功，Hash 对的上，就说明外卖网站的公钥是真实可信的。</p><p>上述整个过程中，都有一个前提，CA 是可信的。但是，我们又怎么确定 CA 的公钥就是对的呢？这就像有的人在偏远农村搞了个假公安局一样（应该没人这么干吧），我们怎么知道公安局是不是假的呢？然后我们就会想到，我去县公安局确认下当地公安局的信息不就好了。没错，CA 也是这么干的。</p><p>CA 的公钥也需要更牛的 CA 给它签名，然后形成 CA 的公钥。要想知道某个 CA 的证书是否可靠，要看 CA 的上级证书的公钥能不能解开这个 CA 的签名。这样追根溯源，直到全球皆知的几大著名 CA，我们称为<strong>Root CA</strong>，做最后的背书。正是通过这种<strong>层层授信背书</strong>的形式，保证了非对称加密模式的争吵运转。</p><p>除此之外，还有一种证书， 称为<strong>Self-Signed Certificate</strong>，就是自己给自己签名。这个就给人一种“我就是我，不一样的烟火，你爱信不信”的感觉，有兴趣的博友可以自行搜索了解。</p><h3 id="HTTPS-的工作模式"><a href="#HTTPS-的工作模式" class="headerlink" title="HTTPS 的工作模式"></a>HTTPS 的工作模式</h3><p>上面说了对称加密和非对称加密的原理，我们知道了非对称加密在性能上远不如对称加密，那在 HTTP 中，能否将两者结合起来呢？例如，公钥私钥主要用于<strong>传输对称加密的密钥</strong>，而真正的双方<strong>大数据量的通信都是通过对称加密进行</strong>。</p><p>是的，HTTPS 协议的思路就是这样的。如下图：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181213203739659-838849439.png" alt=""></p><p>图比较长，整个过程最后的目标是<strong>生成在后续通信过程中使用的对称密钥，以及约定使用的加密算法</strong>。整体过程如下：</p><ol><li>客户端明文发送 TLS 版本信息、加密套件候选列表、压缩算法候选列表等信息，另外还会发送一个随机数，在协商对称密钥的时候使用（你好，我想定外卖，但你要保密我点了什么。这是我的加密套路列表，还有一个随机数 A，你留着）；</li><li>服务器返回 Server Hello 消息，告诉客户端，服务器选择使用的协议版本、加密套件、压缩算法等，还有一个随机数 B，用于后续进行密钥协商（你好，保密没问题，就按套路 2 来吧，我也给你一个随机数 B，你留着）；</li><li>服务器给客户端证书；</li><li>客户端从自己信任的 CA 仓库中，拿 CA 的证书里面的公钥去解密服务器传来的证书。解密成功，说明外卖网站是可信的。这个解密过程，客户端可能胡不断往上追溯 CA、CA 的 CA、CA 的 CA 的 CA，直到一个授信的 CA 为止；</li><li>证书验证可信后，客户端会计算产生随机数字 Pre-master，发送Client Key Exchange，用证书中的公钥加密，再发给服务器；</li></ol><p>到此时，无论是客户端还是服务端，都有了三个随机数，分别是：A、B、Pre-master。通过这三个随机数，客户端和服务端可以产生相同的对称密钥。</p><p>约定好对称密钥和加密算法，就可以用对称加密的形式进行加密通信了，后续的通信除了多了一步密钥校验的过程，HTTP 协议里的那些过程都不会少。</p><p>不过上面的过程中只包含了 HTTPS 的单向认证，也就是客户端验证服务端的证书，这也是最常见的场景。不过在更加严格要求通信安全的情况下，也可以启用双向认证，双方互相验证证书。</p><p>通过上面的整个过程，我们可以看出，HTTPS 协议并不是一个新的协议，它只是 HTTP 协议与一些加密算法的组合，用来保证通信的安全。</p><p>虽然上面介绍的非对称加密方式，在现在看来是完美不可解的，但未来谁知道呢？正所谓“道高一尺魔高一丈”，加密安全路上永无尽头。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>加密分<strong>对称加密</strong>和<strong>非对称加密</strong>。对称加密效率高，但存在密钥传输的问题；非对称加密可以解决密钥传输的问题，但效率较低。</li><li>非对称加密需要通过<strong>证书</strong>和<strong>权威机构</strong>来验证公钥的合法性。</li><li>HTTPS 是综合了对称加密和非对称加密算法的 HTTP 协议。既保证了传输安全，也保证了传输效率。</li></ul><p>参考：</p><ol><li>百度百科 - htps 词条；</li><li>刘超 - 趣谈网络协议系列课；</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTPS协议 </tag>
            
            <tag> 对称加密 </tag>
            
            <tag> 非对称加密 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 12 - HTTP 协议：常用而不简单</title>
      <link href="/12/wangluoxieyi/ck0669dwh006xagaai5qp60rv/"/>
      <url>/12/wangluoxieyi/ck0669dwh006xagaai5qp60rv/</url>
      
        <content type="html"><![CDATA[<p>网络协议五层通天路，咱们从物理层、到链路层、网络层、再到传输层，现在又进一步，来到了应用层。这也是我们五层协议里最上面的一层，关于应用层，有太多协议要了解。但要说最有名的，那肯定就是 HTTP 了。</p><p>HTTP 协议，几乎是每个人上网用的第一个协议，同时也是很容易被人忽略的协议。</p><p>就像 <a href="http://blog.muzixizao.com/，是个" target="_blank" rel="noopener">http://blog.muzixizao.com/，是个</a> URL，叫作<strong>统一资源定位符</strong>。之所以叫统一，是因为它是有规定格式的。HTTP 称为协议，blog.muzixizao.com 是一个域名，表示互联网的一个位置。有的 URL 会有更详细的位置标识，例如</p><blockquote><p><a href="http://blog.muzixizao.com/?p=140" target="_blank" rel="noopener">http://blog.muzixizao.com/?p=140</a></p></blockquote><p>正是因为格式是统一的，所以当你把这样一个字符串输入到浏览器的框里的时候，浏览器才知道如何进行统一处理。</p><h3 id="HTTP-请求的准备"><a href="#HTTP-请求的准备" class="headerlink" title="HTTP 请求的准备"></a>HTTP 请求的准备</h3><p>浏览器会将 blog.muzixizao.com 这个域名发送给 DNS 服务器，让它解析为 IP 地址。关于 DNS 解析的过程，较为复杂，后面会专门介绍。</p><p>域名解析成 IP 后，下一步是干嘛呢？</p><p>还记得吗？HTTP 是基于 TCP 协议的，所以接下来就是建立 TCP 连接了。具体的连接过程可<a href="https://www.cnblogs.com/BeiGuo-FengGuang/p/10029735.html" target="_blank" rel="noopener">点击这里查看</a>。</p><p>目前使用的 HTTP 协议大部分都是 1.1.在 1.1 协议里面，默认开启了 Keep-Alive 的，这样建立的 TCP 连接，就可以在多次请求中复用。虽然 HTTP 用了各种方式来解决它存在的问题，但基于TCP 的它，每次建立连接的三次握手以及断开连接的四次挥手，这个过程还是挺费时的。如果好不容易建立了连接，然后做一点儿事情就结束了，未免太浪费了。</p><h3 id="HTTP-请求的构建"><a href="#HTTP-请求的构建" class="headerlink" title="HTTP 请求的构建"></a>HTTP 请求的构建</h3><p>建立了连接以后，浏览器就要发送 HTTP 的请求。请求的格式如下图：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181211212008388-1450862566.png" alt=""></p><p>如图，HTTP 的报文大概分为<strong>请求行、首部、正文实体</strong>三部分。接下来，咱们就来一一认识。</p><h4 id="请求行"><a href="#请求行" class="headerlink" title="请求行"></a>请求行</h4><p>在请求行中，URL 就是 <a href="http://blog.muzixizao.com，版本为" target="_blank" rel="noopener">http://blog.muzixizao.com，版本为</a> HTTP 1.1。这里要说一下的，就是对应的请求方法。有以下几种类型：</p><p><strong>1）GET 请求</strong></p><p>对于访问网页来讲，最常用的类型就是 GET。顾名思义，GET 就是去服务器获取一些资源。对于访问网页来讲，要获取的资源往往是一个页面。其实也有很多其他的格式，比如返回一个 JSON 字符串。当然，具体要返回什么，是由服务端决定的。</p><p>例如，在云计算中，如果我们的服务端要提供一个基于 HTTP 协议的 API，获取所有云主机的列表，就会使用 GET 方法请求，返回的可能是一个 JSON 字符串，字符串里面是一个列表，列表里面会有各个云主机的信息。</p><p><strong>2）POST 请求</strong><br>另一种类型叫做 POST。它需要主动告诉服务端一些信息，而非获取。而要告诉服务端的信息，一般都放在正文里面。正文里有各种各样的格式，最常见的的就是 JSON了。</p><p>例如，我们平时的支付场景，客户端就需要把 “我是谁？我要支付多少？我要买什么？” 这样信息告诉服务器，这就需要 POST 方法。</p><p>再如，在云计算里，如果我们的服务器，要提供一个基于 HTTP 协议的创建云主机的 API，也会用到 POST 方法。这个时候往往需要将 “我要创建多大的云主机？多少 CPU 和多少内存？多大硬盘？” 这些信息放在 JSON 字符串里面，通过 POST 的方法告诉服务器。</p><p>除了上面常见的两种类型，还有一种 PUT 类型，这种类型就是向指定资源位置上传最新内容。但是 HTTP 的服务区往往是不允许上传文件的，所以 PUT 和 POST 就都变成了要传给服务器东西的方法。</p><p>在我们的实际使用过程中，PUT 和 POST 还是有区别的。POST 往往是用来创建一个资源，而 PUT 往往是用来更新一个资源。</p><p>例如，云主机已经创建好了，想对云主机打一个标签，说明这个云主机是生产环境的，另外一个云主机是测试环境的。我们修改标签的请求往往就是用 PUT 方法。</p><p>还有 DELETE 方法。这个是用来删除资源的。</p><h4 id="首部字段"><a href="#首部字段" class="headerlink" title="首部字段"></a>首部字段</h4><p>请求行下面就是首部字段。首部是 key-value 格式，通过冒号分割。这里面，往往保存了一些非常重要的字段。</p><ul><li>Accpet-Charset：客户端可以接受的字符集。防止传过来的字符串客户端不支持，从而出现乱码；</li><li>Content-Type：正文格式。我们进行 POST 请求时，如果正文是 JSON，我们就应该将这个值设置为 application/json；</li><li>缓存字段 Cache-Control、If-Modified-Since。</li></ul><p>这里重点认识下<strong>缓存字段</strong>。为什么要使用缓存呢？这是因为一个非常大的页面有很多东西。</p><p>例如，我们浏览一个商品的详情，里面有商品的价格、库存、展示图片、使用手册等待。</p><p>商品的展示图片会保持较长时间不变，而库存胡一根筋用户购买情况经常改变。如果图片非常大，而库存数非常小，如果我们每次要更新数据的时候都要刷新整个页面，对于服务器的压力也会很大。</p><p>对于这种高并发场景下的系统，在真正的业务逻辑之前，都需要有个接入层，将这些静态资源的请求拦在最外面。架构就像下图：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181211212055562-838440812.png" alt=""></p><p>其中 DNS、CDN 会在后面的章节详细说明。这里咱们就先来了解下 Nginx 这一层。它是如果处理 HTTP 协议呢？对于静态资源，有 Vanish 缓存层，当缓存过期的时候，才会访问真正的 Tomcat 应用集群。</p><p>在 HTTP 头里面，<strong>Cache-Control 是用来控制缓存的</strong>。当客户端发送的请求中包含 max-age 指令时，如果判定缓存层中，资源的缓存时间数值比指定时间的数值校，那么客户端可以接受缓存的资源；当指定 max-age 值为 0，那么缓存层通常需要将请求转发给应用集群。</p><p>另外，If-Modified-Since 也是关于缓存的字段，这个字段是说，如果服务器的资源在某个时间之后更新了，那么客户端就应该下载最新的资源；如果没有更新，服务端会返回“304 Not Modified” 的响应，那客户端就不用下载了，也会节省带宽。</p><p>到此，我们拼凑起了 HTTP 请求的报文格式，接下来，浏览器会把它交给传输层。</p><h3 id="HTTP-请求的发送"><a href="#HTTP-请求的发送" class="headerlink" title="HTTP 请求的发送"></a>HTTP 请求的发送</h3><p>HTTP 协议是基于 TCP 协议的，所以它是以面向连接的方式发送请求，通过 stream 二进制流的方式传给对方。当然，到了 TCP 层，它会把二进制流变成一个个的报文段发送给服务器。</p><p>在发送给每个报文段的时候，都需要对方有一个回应 ACK，来保证报文可靠地到达了地方。如果没有回应，那么 TCP 这一层会重新传输，直到可以到达。同一个包有可能被传了好多次，但是 HTTP 这一层不需要知道这一点，因为是 TCP 这一层在埋头苦干。</p><p>而后续传输过程如下：</p><ol><li><strong>TCP 层封装目标地址和源地址</strong>。TCP 层发送每一个报文的时候，都需要加上自己的地址和它想要去的地址，将这两个信息放到 IP 头里面，交给 IP 层进行传输。</li><li><strong>IP 层获取 MAC 头</strong>。IP 层需要查看目标地址和自己是否在同一个局域网。如果是，就发送 ARP 协议来请求这个目标地址对应的 MAC 地址，然后将源 MAC 和目标 MAC 放入 MAC 头，发送出去；如果不在同一个局域网，就需要发送到网关，这里也要通过 ARP 协议来获取网关的 MAC 地址，然后将源 MAC 和网关 MAC 放入 MAC 头，发送出去。</li><li><strong>网关转发</strong>。网关收到包发现 MAC 符合，取出目标 IP 地址，根据路由协议找到下一跳的路由器，获取下一跳路由器的 MAC 地址，将包发给下一跳路由器。</li><li><strong>数据包到达目标地址的局域网</strong>。通过 ARP 协议获取目标地址的 MAC 地址，将包发出去。</li><li><strong>目标地址检查信息，返回 ACK</strong>。目标机器发现数据包中的 MAC 地址及 IP 地址都和本机匹配，就根据 IP 头中的协议类型，知道是 TCP 协议，解析 TCP 的头，获取序列号。判断序列号是否是本机需要的，如果是，就放入缓存中然后返回一个 ACK，如果不是就丢弃。</li><li><strong>根据端口号将数据包发送到指定应用</strong>。TCP 头里面还有端口号，HTTP 的服务器正在监听这个端口号。于是，目标机器自然指定是 HTTP 服务器这个进程想要这个包，就把数据包发给 HTTP 服务器。</li><li><strong>HTTP 服务器处理请求</strong>。HTTP 服务器根据请求信息进行处理，并返回数据给客户端。</li></ol><h3 id="HTTP-返回的构建"><a href="#HTTP-返回的构建" class="headerlink" title="HTTP 返回的构建"></a>HTTP 返回的构建</h3><p>HTTP 的返回报文也是有一定格式的，如下图：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181211220130158-747127240.png" alt=""></p><p><strong>状态行包含状态码和短语</strong>。状态码反应 HTTP 请求的结果。200 是大吉大利；404 则是我们最不想见到的，也就是服务端无法响应这个请求。短语中会说明出错原因。</p><p><strong>首部 key-value</strong>。这里常用的有以下字段：</p><ul><li>Retry-After：客户端应该在多长时间后再次尝试连接；</li><li>Content-Type：返回数据格式</li></ul><p>构造好了返回的 HTTP 报文，接下来就是把这个报文发送出去。当然，还是交给 Socket 去发送，交给 TCP，让 TCP 返回的 HTML 分成一个个小的数据段，并且保证每一段都安全到达。这些小的数据段会加上 TCP 头，然后交给 IP 层，沿着来时的路反向走一遍。虽然不一定是完全相同的路径，但是逻辑过程是一样的，一直到达客户端。</p><p>客户端取出数据后 ，会根据端口号交给指定的程序，这时候就是我们的浏览器出马的时候。</p><p>浏览器拿到了 HTTP 报文，发现返回 200，一切正常，就从正文中将 HTML 拿出来，展示出一个炫酷吊炸天的网页。</p><p>以上就是正常的 HTTP 请求与返回的完整过程。</p><h3 id="HTTP-2-0"><a href="#HTTP-2-0" class="headerlink" title="HTTP 2.0"></a>HTTP 2.0</h3><p>上面提到了，现在用到 HTTP 大多是 1.1 版本，而 HTTP 2.0 在 1.1 的基础上进行了一些优化，以期解决一些问题。</p><p>HTTP 1.1 在应用层以纯文本的形式进行通信。每次通信都要带完整的 HTTP 头，而且不考虑 pipeline 模式的话，每次的过程都要像上面描述的那样一去一回。显然，在效率上会存在问题。</p><p>为了解决这些问题，HTTP 2.0 会对 HTTP 头进行一定的压缩，将原来每次都要携带的大量 key-value 对在两端建立一个索引表，对相同的头只发送索引表中的索引。</p><p>另外，HTTP 2.0 协议将一个 TCP 连接切分成多个流，每个流都有自己的 ID，而且流可以是客户端发给服务端，也可以是服务端发给客户端，它其实只是个虚拟的通道，除此之外，它还有优先级。</p><p>HTTP 2.0 将所有的传输信息分割成更小的消息和帧，并对它们采用二进制格式编码。常见的帧有 <strong>Header 帧</strong>，用于传输 Header 内容，并且会开启一个新的流。还有 <strong>Data 帧</strong>，用来传输正文实体，并且多个 Data 帧属于同个流。</p><p>通过这两种机制，HTTP 2.0 的客户端可以将多个请求分到不同的流中， 然后将请求内容拆分成帧，进行二进制传输。这些帧可以打散乱序发送，然后根据帧首部的流标识符重新组装，并且可以根据优先级，决定先处理哪个流的数据。</p><p>针对 HTTP 2.0，我们来看一个例子。</p><p>假设我们有一个页面要发送三个独立的请求，一个获取 CSS、一个获取 JS、一个获取图片 jsg。如果使用 HTTP 1.1，这<strong>三个请求就是串行的</strong>，但是如果使用 HTTP 2.0，就可以在一个连接里，客户端和服务端同时反思多个请求和回应，而且不用按照顺序一对一对应。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181211220404537-1366735316.png" alt=""></p><p>如上图。HTTP 2.0 其实是将三个请求变成三个流，将数据分成帧，乱序发送到一个 TCP 连接中。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181211220526511-1759402231.png" alt=""></p><p>HTTP 2.0 成功解决了 HTTP 1.1 的<strong>队首阻塞问题</strong>。同时，也不需要通过 HTTP 1.x 的 pipeline 机制用多条 TCP 连接来实现并行请求与响应，减少了 TCP 连接数对服务器性能的影响，加快页面组件的传输速度。</p><p>HTTP 2.0 虽然大大增加了并发性，但由于 TCP 协议的<strong>按序处理</strong>的特性，还是会出现阻塞的问题。</p><p>还记得咱们之前说过的 QUIC 协议吗？这时候就是它登场的时候了。</p><p>它用以下四个机制，解决了 TCP 存在的一些问题。</p><h3 id="QUIC-协议"><a href="#QUIC-协议" class="headerlink" title="QUIC 协议"></a>QUIC 协议</h3><p><strong>机制一：自定义连接机制</strong></p><p>我们知道，一条 TCP 连接是由四元组标识的。一旦一个元素发生变化，就需要端口重连。这在移动互联网的情况下，当我们切换网络或者信号不稳定时，都会导致重连，从而增加时延。</p><p>TCP 没办法解决上述问题，但是 QUCI 基于 UDP 协议，就可以在自己的逻辑里面维护连接的机制，不再以四元组标识，而是以一个 64 位的随机数作为标识 ID，而且 UDP 是无连接的，只要 ID 不变，就不需要重新建立连接。</p><p><strong>机制二：自定义重传机制</strong><br>TCP 为了保证可靠性，通过使用<strong>序号</strong>和<strong>应答</strong>机制，来解决顺序问题和丢包问题。</p><p>任何一个序号的包发出去，都要在一定时间内得到应答，否则就会超时重发。这个超时时间就是通过*<em>采样往返时间 RTT *</em>不断调整的。其实，这个超时时间的采样是不太准确的。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181211220609639-1286857333.png" alt=""></p><p>如上图。发送一个包，序号为 100，超时后，再发送一个 100。然后收到了一个 ACK101。这个时候客户端知道服务器已经收到了 100，但是往返时间怎么计算呢？是 ACK 到达时间减去后一个 100 发送的时间，还是减去前一个 100 发送的时间呢？<strong>前者把时间算短了，后者把时间算长了</strong>。</p><p>QUIC 也有一个序列号，是完全递增的。任何一个包发送一次后，下一次序列号就要加一。像我们上面的例子，在 QUIC 协议中，100 的包没有返回，再次发送时，序号就是 101 了，如果返回是 ACK100，就是对第一个包的响应，如果返回 ACK101，就是对第二个包的响应，<strong>RTT 时间计算相对准确</strong>，过程如下图：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181211220759099-1701097317.png" alt=""></p><p>上面的过程中，有的童鞋可能会问了，两个序号不一样的包，服务器怎么知道是同样的内容呢？没错，这确实是个问题。为了解决这个问题，QUIC 协议定义了一个 <strong>Offset</strong> 的概念。</p><p>QUIC 既然是面向连接的，也就像 TCP 一样，是一个数据流。，发送的数据在这个流里面都有个偏移量 Offset，可以通过 Offset 查看数据发送到了那里，这样只要这个 Offset 的包没有来，就要重发。如果来了，就按照 Offset 拼接成一个流。</p><p><strong>机制三：无阻塞的多路复用</strong><br>有了自定义的连接和重传机制，我们就可以解决上面 HTTP 2.0 的多路复用问题。</p><p>同 HTTP 2.0 一样，同一条 QUIC 连接上可以创建多个 stream，来发送多个 HTTP 请求。更棒的是，QUIC 是基于 UDP 的，一个连接上的多个 stream 之间没有依赖。这样，假如 stream2 丢了一个 UDP 包，后面跟着 stream3 的一个 UDP 包，虽然 stream2 的那个包需要重传，但是 stream3 的包无需等待，就可以发给用户。</p><p><strong>机制四：自定义流量控制</strong><br>TCP 的流量控制是通过<strong>滑动窗口协议</strong>。QUIC 的流量控制也是通过 window_update，来告诉对端它可以接受的字节数。但是 QUIC 的窗口是适应自己的多路复用机制的，不但在一个连接上控制窗口，还在一个连接中的每个 stream 控制窗口。</p><p>还记得吗？在 TCP 协议中，接收端的窗口的起始点是下一个要接收并且 ACK 的包，即便后来的包都到了，放在缓存里面，窗口也不能右移，因为 TCP 的 ACK 机制是基于序列号的累计应答，一旦 ACK 一个序列号，就说明前面的都到了，所以只要前面的没到，后面的即使到了也不能 ACK，就会导致后面的到了，也有可能超时重传，浪费带宽。</p><p>QUIC 的 ACK 是基于 offset 的，每个 offset 的包来了，进了缓存，就可以应答，应答后就不会重发，中间的空档会等待到来或者重发即可，而窗口的起始位置为当前收到的最大 offset，从这个 offset 到当前的 stream 所能容纳的最大缓存，是真正的窗口大小，显然，这样更加准确。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181211220849757-1736601348.png" alt=""></p><p>另外，还有整个连接的窗口，需要对于所有的 stream 的窗口做一个统计。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>HTTP 协议虽然很常用，也很复杂，我们只需要重点记住 GET、POST、PUT、DELETE 这几个方法，以及重要的首部字段；</li><li>HTTP 2.0 通过头压缩、分帧、二进制编码、多路复用等技术提升性能；</li><li>QUIC 协议通过基于 UDP 自定义的类似 TCP 的连接、重试、多路复用、流量控制技术，进一步提升性能。</li></ul><p>参考：</p><ol><li>The TCP/IP Guide；</li><li>百度百科 - HTTP 词条；</li><li>刘超 - 趣谈网络协议系列课；</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 11 - Socket 编程（下）：眼见为实耳听为虚</title>
      <link href="/12/wangluoxieyi/ck0669dd9000cagaa5w1dez5c/"/>
      <url>/12/wangluoxieyi/ck0669dd9000cagaa5w1dez5c/</url>
      
        <content type="html"><![CDATA[<p>之前我们基本了解了网络通信里的大部分协议，一直都是在“听”的过程。很多人都会觉得，好像看懂了，但关了页面回忆起来，好像又什么都没懂。这次咱们就“真枪实弹”的码起来，再用一个“神器”-网络分析系统详细跟踪下数据包的生命历程，让我们的理论真实的呈现出来，对网络通信感兴趣的博友，还可以自己拿着系统分析一遍，你一定会大有所获。</p><p>不多说，直接上代码。有兴趣的博友可以按各编程语言进行相关改写，然后拿着我们的分析系统真实的看看网络通信过程。</p><h3 id="本机请求转发到网关"><a href="#本机请求转发到网关" class="headerlink" title="本机请求转发到网关"></a>本机请求转发到网关</h3><p>代码中的 192.168.1.10 是内网另一台服务器，楼主的 IP 是 192.168.1.73。在本机跑服务器的时候，要做一个路由配置，否则分析系统无法抓取相关的包。window 下可按下面步骤配置：</p><ol><li>管理员身份打开 DOS 窗口；</li><li>route add 本机ip mask 255.255.255.255 网关ip（路由转发，还记得吗？忘记了？<a href="https://www.cnblogs.com/BeiGuo-FengGuang/p/9990693.html" target="_blank" rel="noopener">点我点我点我</a>）；</li></ol><p>什么？不知道怎么查 IP 和网关？<a href="https://www.cnblogs.com/BeiGuo-FengGuang/p/9877801.html" target="_blank" rel="noopener">点我告诉你</a><br>操作完成后记得<strong>删除转发规则</strong>，否则，你会发现本机的请求，速度会变得很慢、、、<br>实例：</p><pre><code>// 添加路由转发规则route add 192.168.1.73 mask 255.255.255.255 192.168.1.1 // 删除转发规则route delete 192.168.1.73</code></pre><h3 id="基于-TCP-的-Socket"><a href="#基于-TCP-的-Socket" class="headerlink" title="基于 TCP 的 Socket"></a>基于 TCP 的 Socket</h3><p>服务端：</p><pre><code>&lt;?php/** * 1. socket_create: 新建 socket * 2. socket_bind:   绑定 IP 和 port * 3. socket_listen: 监听 * 4. socket_accept: 接收客户端连接，返回连接 socket * 5. socket_read:   读取客户端发送数据 * 6. socket_write:  返回数据 * 7. socket_close:  关闭 socket */$ip = '192.168.1.10';$port = 23333;// $port = 80;$sk = socket_create(AF_INET, SOCK_STREAM, SOL_TCP);!$sk &amp;&amp; outInfo('socket_create error');// 绑定 IP!socket_bind($sk, $ip, $port) &amp;&amp; outInfo('socket_bind error');// 监听!socket_listen($sk) &amp;&amp; outInfo('sever listen error');outInfo("Success Listen: $ip:$port", 'INFO');while (true) {    $accept_res = socket_accept($sk);    !$accept_res &amp;&amp; outInfo('sever accept error');    $reqStr = socket_read($accept_res, 1024);    if (!$reqStr) outInfo('sever read error');    outInfo("Server receive client msg: $reqStr", 'INFO');    $response = 'Hello A, I am B. you msg is : ' . $reqStr . PHP_EOL;    if (socket_write($accept_res, $response, strlen($response)) === false) {        outInfo('response error');    }    socket_close($accept_res);}socket_close($sk);function outInfo($errMsg, $level = 'ERROR'){    if ($level === 'ERROR') {        $errMsg = "$errMsg, msg: " . socket_strerror(socket_last_error());    }    echo $errMsg . PHP_EOL;    $level === 'ERROR' &amp;&amp; die;}</code></pre><p>客户端：</p><pre><code>&lt;?php/** * 1. socket_create:  新建 socket * 2. socket_connect: 连接服务端 * 3. socket_write:   给服务端发数据 * 4. socket_read:    读取服务端返回的数据 * 5. socket_close:   关闭 socket */$ip = '192.168.1.10';$port = 23333;$sk = socket_create(AF_INET, SOCK_STREAM, SOL_TCP);!$sk &amp;&amp; outInfo('socket_create error');!socket_connect($sk, $ip, $port) &amp;&amp; outInfo('connect fail');$msg = 'hello, I am A';if (socket_write($sk, $msg, strlen($msg)) === false) {    outInfo('socket_write fail');}while ($res = socket_read($sk, 1024)) {    echo 'server return message is:'. PHP_EOL. $res;}socket_close($sk);//工作完毕，关闭套接流function outInfo($errMsg, $level = 'ERROR'){    if ($level === 'ERROR') {        $errMsg = "$errMsg, msg: " . socket_strerror(socket_last_error());    }    echo $errMsg . PHP_EOL;    $level === 'ERROR' &amp;&amp; die;}</code></pre><p>上面的代码是基于 PHP 原生 Socket 写的，其它语言也有对应 Socket 操作函数，进行相关的改写即可。主要是下面的分析过程。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181208172638786-201596475.png" alt=""></p><p>如上图，这是我们的分析系统捕捉的所有数据传输过程，你可以真实的看到每一步都发生了什么，以及对应的状态的改变（图片较大，建议右键在新标签页打开看）。</p><p>在图中上半部分，我们可以看到分析系统将整个 TCP 的生命历程分为了三个阶段：建立连接、交易、关闭连接。这和我们之前了解的理论知识完全相符。<br>左下角的交易时序图，则详细记录了客户端和服务端每次通信的详细信息，而右下角部分，则展示了每次通信，数据包的状态等信息。</p><h3 id="基于-UDP-的Socket"><a href="#基于-UDP-的Socket" class="headerlink" title="基于 UDP 的Socket"></a>基于 UDP 的Socket</h3><pre><code>&lt;?php/** * 1. socket_create:   新建 socket * 2. socket_bind:     绑定 IP 和 port * 3. socket_recvfrom: 读取客户端发送数据 * 4. socket_sendto:   返回数据 * 5. socket_close:    关闭 socket */$ip = '192.168.1.10';$port = 23333;$sk = socket_create(AF_INET, SOCK_DGRAM, SOL_UDP);!$sk &amp;&amp; outInfo('socket_create error');// 绑定 IP!socket_bind($sk, $ip, $port) &amp;&amp; outInfo('socket_bind error');outInfo("Success Listen: $ip:$port", 'INFO');while (true) {    $from = '';    $reqPort = 0;    if (!socket_recvfrom($sk, $buf, 1024, 0, $from, $reqPort)) {        outInfo('sever socket_recvfrom error');    }    outInfo("Received msg $buf from remote address $from:$port", 'INFO');    $response = "Hello $from:$port, I am Server. your msg : " . $buf . PHP_EOL;    if (!socket_sendto($sk, $response, strlen($response), 0, $from, $reqPort)) {        outInfo('socket_sendto error');    }}socket_close($sk);function outInfo($errMsg, $level = 'ERROR'){    if ($level === 'ERROR') {        $errMsg = "$errMsg, msg: " . socket_strerror(socket_last_error());    }    echo $errMsg . PHP_EOL;    $level === 'ERROR' &amp;&amp; die;}</code></pre><p>客户端：</p><pre><code>&lt;?php/** * 1. socket_create:  新建 socket * 2. socket_write:   给服务端发数据 * 3. socket_read:    读取服务端返回的数据 * 4. socket_close:   关闭 socket */$ip = '192.168.1.10';$port = 23333;$sk = socket_create(AF_INET, SOCK_DGRAM, SOL_UDP);!$sk &amp;&amp; outInfo('socket_create error');$msg = 'hello, I am A';if (!socket_sendto($sk, $msg, strlen($msg), 0, $ip, $port)) {    outInfo('socket_sendto fail');}$from = '';$reqPort = 0;if (!socket_recvfrom($sk, $buf, 1024, 0, $from, $reqPort)) {    outInfo('server socket_recvfrom error');}outInfo("Received $buf from server address $from:$port", 'INFO');socket_close($sk);function outInfo($errMsg, $level = 'ERROR'){    if ($level === 'ERROR') {        $errMsg = "$errMsg, msg: " . socket_strerror(socket_last_error());    }    echo $errMsg . PHP_EOL;    $level === 'ERROR' &amp;&amp; die;}</code></pre><p>UDP 数据包分析图：<br><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181208174449420-2050339711.png" alt=""></p><p>如上图，UDP 数据包分析图，明显比 TCP 要简单很多，人家单纯嘛，就不多说了。不过要注意的，写代码的时候，<strong>UDP 的服务端，在循环里千万不要关闭 Socket</strong>。</p><h3 id="分析系统介绍"><a href="#分析系统介绍" class="headerlink" title="分析系统介绍"></a>分析系统介绍</h3><p>上面用到的分析系统叫：科来网络分析系统，<a href="http://www.colasoft.com.cn/download/capsa.php" target="_blank" rel="noopener">点我下载</a>。这个分析系统很良心，提供了一个免费的技术交流版。有兴趣的小伙伴可以下载下来玩玩，很强大。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TCP协议 </tag>
            
            <tag> socket编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 10 - Socket 编程（上）：实践是检验真理的唯一标准</title>
      <link href="/12/wangluoxieyi/ck0669dt8003sagaabn1eiy30/"/>
      <url>/12/wangluoxieyi/ck0669dt8003sagaabn1eiy30/</url>
      
        <content type="html"><![CDATA[<p>前面一直在说各种协议，偏理论方面的知识，这次咱们就来认识下基于 TCP 和 UDP 协议这些理论知识的 Socket 编程。</p><p>说 TCP 和 UDP 的时候，我们是分成客户端和服务端来认识的，那在写 Socket 的时候，我们也这样分。</p><p>Socket 这个名字很有意思，可以作插口或者插槽讲。我们写程序时，就可以将 Socket 想象为，一头插在客户端，一头插在服务端，然后进行通信。</p><p>在建立 Socket 的时候，应该设置什么参数呢？Socket 编程进行的是端到端的通信，往往意识不到中间经过多少局域网，多少路由器，因而能够设置的参数，也只能是<strong>端到端协议之上网络层和传输层的</strong>。</p><p>对于网络层和传输层，有以下参数需要设置：</p><ul><li>IP协议：IPv4 对应 AF_INEF，IPv6 对应 AF_INET6；</li><li>传输层协议：TCP 与 UDP。TCP 协议基于数据流，其对应值是 SOCKET_STREAM，而 UDP 是基于数据报的，其对应值是 SOCKET_DGRAM。</li></ul><p>两端创建了 Socket 之后，而后面的过程中，TCP 和 UDP 稍有不同，我们先来看看 TCP。</p><h3 id="基于-TCP-协议的-Socket"><a href="#基于-TCP-协议的-Socket" class="headerlink" title="基于 TCP 协议的 Socket"></a>基于 TCP 协议的 Socket</h3><p>对于 TCP 创建 Socket 的过程，有以下几步走：</p><p><strong>1）TCP 调用 bind 函数赋予 Socket IP 地址和端口。</strong></p><p>为什么需要 IP 地址？还记得吗？咱们之前了解过，一台机器会有多个网卡，而每个网卡就有一个 IP 地址，我们可以选择监听所有的网卡，也可以选择监听一个网卡，只有，发给指定网卡的包才会发给你。</p><p>为什么需要端口？要知道，咱们写的是一个应用程序，当一个网络包来的时候，内核就是要通过 TCP 里面的端口号来找到对应的应用程序，把包给你。</p><p><strong>2）调用 listen 函数监听端口。</strong> 在 TCP 的状态图了，有一个 listen 状态，当调用这个函数之后，服务端就进入了这个状态，这个时候客户端就可以发起连接了。</p><p>在内核中，为每个 Socket 维护两个队列。一个是已经建立了连接的队列，这里面的连接已经完成三次握手，处于 established 状态；另一个是还没有完全建立连接的队列，这里面的连接还没有完成三次握手，处于 syn_rcvd 状态。</p><p><strong>3）服务端调用 accept 函数。</strong> 这时候服务端会拿出一个已经完成的连接进行处理，如果还没有已经完成的连接，就要等着。</p><p>在服务端等待的时候，客户端可以通过 connect 函数发起连接。客户端先在参数中指明要连接的 IP 地址和端口号，然后开始发起三次握手。内核会给客户端分配一个临时的端口，一旦握手成功，<strong>服务端的 accep 就会返回另一个 Socket</strong>。</p><p>注意，从上面的过程中可以看出，<strong>监听的 Socket 和真正用来传数据的 Socket 是不同的两个。</strong> 一个叫做<strong>监听 Socket</strong>，一个叫做<strong>已连接 Socket</strong>。</p><p>下图就是基于 TCP 协议的 Socket 函数调用过程：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181205095137019-327439578.png" alt=""></p><p>连接建立成功之后，双方开始通过 read 和write 函数来读写数据，就像往一个文件流里写东西一样。</p><p>这里说 TCP 的 Socket 是一个文件流，是非常准确的。因为 Socket 在 linux 中就是以文件的形式存在的。除此之外，还存在<strong>文件描述符</strong>。写入和读出，也是通过文件描述符。</p><p>每一个进程都有一个数据结构 task_struct，里面指向一个<strong>文件描述符数组</strong>，来列出这个进程打开的所有文件的文件描述符。文件描述符是一个整数索引值，是这个数组的下标。</p><p>这个数组中的内容是一个指针，指向内核中所有打开的文件列表。而每个文件也会有一个 inode（索引节点）。</p><p>对于 Socke 而言，它是一个文件，也就有对于的文件描述符。与真正的文件系统不一样的是，Socket 对于的 inode 并不是保存在硬盘上，而是在内存中。在这个 inode 中，指向了 Socket 在内核中的 Socket 结构。</p><p>在这个机构里面，主要有两个队列。一个发送队列，一个接收队列。这两个队列里面，保存的是一个缓存 sk_buff。这个缓存里能够看到完整的包结构。说到这里，你应该就会发现，数据结构以及和前面了解的收发包的场景联系起来了。</p><p>上面整个过程说起来稍显混乱，可对比下图加深理解。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181205095320283-70879430.png" alt=""></p><h3 id="基于-UDP-协议的-Socket"><a href="#基于-UDP-协议的-Socket" class="headerlink" title="基于 UDP 协议的 Socket"></a>基于 UDP 协议的 Socket</h3><p>基于 UDP 的 Socket 编程过程和 TCP 有些不同。UDP 是没有连接状态的，所以不需要三次握手，也就不需要调用 listen 和 connect。没有连接状态，也就不需要维护连接状态，因而不需要对每个连接建立一组 Socket，只要建立一组 Socket，就能和多个客户端通信。也正是因为没有连接状态，每次通信的时候，都可以调用 sendto 和 recvfrom 传入 IP 地址和端口。</p><p>下图是基于 UDP 的 Socket 函数调用过程：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181205095341100-416056031.png" alt=""></p><h3 id="服务器最大并发量"><a href="#服务器最大并发量" class="headerlink" title="服务器最大并发量"></a>服务器最大并发量</h3><p>了解了基本的 Socket 函数后，就可以写出一个网络交互的程序了。就像上面的过程一样，在建立连接后，进行一个 while 循环，客户端发了收，服务端收了发。</p><p>很明显，这种一台服务器服务一个客户的方式和我们的实际需要相差甚远。这就相当于老板成立了一个公司，只有自己一个人，自己亲自服务客户，只能干完一家再干下一家。这种方式肯定赚不了钱，这时候，就要想，我最多能接多少项目呢？</p><p>我们可以先来算下理论最大值，也就是<strong>理论最大连接数</strong>。系统会用一个四元组来标识一个 TCP 连接：</p><blockquote><p>{本机 IP，本机端口，对端 IP，对端端口}</p></blockquote><p>服务器通常固定监听某个本地端口，等待客户端连接请求。因此，上面四元组中，可变的项只有<strong>对端 IP 和对端端口</strong>，也就是<strong>客户端 IP 和客户端端口</strong>。不难得出：</p><blockquote><p>最大 TCP 连接数 = 客户端 IP 数 x 客户端端口数。</p></blockquote><p>对于 IPv4：</p><blockquote><p>客户端最大 IP 数 = 2 的 32 次方</p></blockquote><p>对于端口数：</p><blockquote><p>客户端最大端口数 = 2 的 16 次方</p></blockquote><p>因此：</p><blockquote><p>最大 TCP 连接数 = 2 的 48 次方（估算值）</p></blockquote><p>当然，服务端最大并发 TCP 连接数远不能达到理论最大值。主要有以下原因：</p><ol><li><strong>文件描述符限制</strong>。按照上面的原理，Socket 都是文件，所以首先要通过 ulimit 配置文件描述符的数目；</li><li><strong>内存限制</strong>。按上面的数据结构，每个 TCP 连接都要占用一定的内存，而系统内存是有限的。</li></ol><p>所以，作为老板，在资源有限的情况下，要想接更多的项目，赚更多的钱，就要<strong>降低每个项目消耗的资源数目</strong>。</p><p>本着这个原则，我们可以找到以下几种方式来最可能的降低消耗项目消耗资源。</p><h4 id="1）将项目外包给其他公司（多进程方式）"><a href="#1）将项目外包给其他公司（多进程方式）" class="headerlink" title="1）将项目外包给其他公司（多进程方式）"></a>1）将项目外包给其他公司（多进程方式）</h4><p>这就相当于你是一个代理，监听来的请求，一旦建立一个连接，就会有一个已连接的 Socket，这时候你可以创建一个紫禁城，然后将基于已连接的 Socket 交互交给这个新的子进程来做。就像来了一个新项目，你可以注册一家子公司，招人，然后把项目转包给这就公司做，这样你就又可以去接新的项目了。</p><p>这里有个问题是，如何创建子公司，并将项目移交给子公司？</p><p>在 Linux 下，创建子进程使用 fork 函数。通过名字可以看出，这是在父进程的基础上完全拷贝一个子进程。在 Linux 内核中，<strong>会复制文件描述符的列表，也会复制内存空间，还会复制一条记录当前执行到了哪一行程序的进程。</strong></p><p>这样，复制完成后，父进程和子进程都会记录当前刚刚执行完 fork。这两个进程刚复制完的时候，几乎一模一样，只是根据 fork 的返回值来区分是父进程还是子进程。<strong>如果返回值是 0，则是子进程，如果返回值是其他的整数，就是父进程</strong>，这里返回的整数，就是<strong>子进程的 ID</strong>。</p><p>进程复制过程如下图：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181205095430794-1580385237.png" alt=""></p><p>因为复制了文件描述符列表，而文件描述符都是指向整个内核统一的打开文件列表的。因此父进程刚才因为 accept 创建的已连接 Socket 也是一个文件描述符，同样也会被子进程获得。</p><p>接下来，子进程就可以通过这个已连接 Socket 和客户端进行通信了。当通信完成后，就可以退出进程。那父进程如何知道子进程干完了项目要退出呢？父进程中 fork 函数返回的整数就是子进程的 ID，父进程可以通过这个 ID 查看子进程是否完成项目，是否需要退出。</p><h4 id="2）将项目转包给独立的项目组（多线程方式）"><a href="#2）将项目转包给独立的项目组（多线程方式）" class="headerlink" title="2）将项目转包给独立的项目组（多线程方式）"></a>2）将项目转包给独立的项目组（多线程方式）</h4><p>上面这种方式你应该能发现问题，如果每接一个项目，都申请一个新公司，然后干完了，就注销掉，实在是太麻烦了。而且新公司要有新公司的资产、办公家具，每次都买了再卖，不划算。</p><p>这时候，我们应该已经想到了<strong>线程</strong>。相比于进程来讲，线程更加轻量级。如果创建进程相当于成立新公司，而创建线程，就相当于在同一个公司成立新的项目组。一个项目做完了，就解散项目组，成立新的项目组，办公家具还可以共用。</p><p>在 Linux 下，通过 pthread_create 创建一个线程，也是调用 do_fork。不同的是，虽然新的线程在 task 列表会新创建一项，但是很多资源，例如文件描述符列表、进程空间，这些还是共享的，只不过多了一个引用而已。</p><p>下图是线程复制过程：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181205095500243-1492761681.png" alt=""></p><p>新的线程也可以通过已连接 Socket 处理请求，从而达到并发处理的目的。 </p><p>上面两种方式，无论是基于进程还是线程模型的，其实还是有问题的。新到来一个 TCP 连接，就需要分配一个进程或者线程。一台机器能创建的进程和线程数是有限的，并不能很好的发挥服务器的性能。著名的<strong>C10K问题</strong>，就是说一台机器如何维护 1 万了连接。按我们上面的方式，系统就要创建 1 万个进程或者线程，这是操作系统无法承受的。</p><p>那既然一个线程负责一个 TCP 连接不行，能不能一个进程或线程负责多个 TCP 连接呢？这就引出了下面两种方式。</p><h4 id="3）一个项目组支撑多个项目（IO-多路复用，一个线程维护多个-Socket）"><a href="#3）一个项目组支撑多个项目（IO-多路复用，一个线程维护多个-Socket）" class="headerlink" title="3）一个项目组支撑多个项目（IO 多路复用，一个线程维护多个 Socket）"></a>3）一个项目组支撑多个项目（IO 多路复用，一个线程维护多个 Socket）</h4><p>当一个项目组负责多个项目时，就要有个<strong>项目进度墙</strong>来把控每个项目的进度，除此之外，还得<strong>有个人专门盯着进度墙</strong>。</p><p>上面说过，Socket 是文件描述符，因此某个线程盯的所有的 Socket，都放在一个文件描述符集合 fd_set 中，这就是<strong>项目进度墙</strong>。然后调用 select 函数来监听文件描述符集合是否有变化，一旦有变化，就会依次查看每个文件描述符。那些发生变化的文件描述符在 fd_set 对应的位都设为 1，表示 Socket 可读或者可写，从而可以进行读写操作，然后再调用 select，接着盯着下一轮的变化。</p><h4 id="4）一个项目组支撑多个项目（IO-多路复用，从“派人盯着”到“有事通知”）"><a href="#4）一个项目组支撑多个项目（IO-多路复用，从“派人盯着”到“有事通知”）" class="headerlink" title="4）一个项目组支撑多个项目（IO 多路复用，从“派人盯着”到“有事通知”）"></a>4）一个项目组支撑多个项目（IO 多路复用，从“派人盯着”到“有事通知”）</h4><p>上面 select 函数还是有问题的，因为每次 Socket 所在的文件描述符集合中有发生变化的时候，都需要通过轮询的方式将所有的 Socket 查看一遍，这大大影响了一个进程或者线程能够支撑的最大连接数量。使用 select，能够同时监听的数量由 FD_SETSIZE 限制。</p><p>如果改成事件通知的方式，情况就会好很多。项目组不需要通过轮询挨个盯着所有项目，而是当项目进度发生变化的时候，主动通知项目组，然后项目组再根据项目进展情况做相应的操作。</p><p>而 epoll 函数就能完成事件通知。它在内核中的实现不是通过轮询的方式，而是通过注册 callback 函数的方式，当某个文件描述符发生变化的时候，主动通知。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181205095549477-1883648695.png" alt=""></p><p>如上图所示，假设进程打开了 Socket m、n、x 等多个文件描述符，现在需要通过 epoll 来监听这些 Socket 是否有事件发生。其中 epoll_create 创建一个 epoll 对象，也是一个文件，对应一个文件描述符，同样也对应着打开文件列表中的一项。在这项里面有一个红黑树，在红黑树里，要保存这个 epoll 监听的所有的 Socket。</p><p>当 epoll_ctl 添加一个 Scoket 的时候，其实就是加入这个红黑树中。同时，红黑树里面的节点指向一个结构，将这个结构挂在被监听的 Socket 的事件列表中。当一个 Socket 发生某个事件时，可以从这个列表中得到 epoll 对象，并调用 call_back 通知它。</p><p>这种事件通知的方式使得监听的 Socket 数量增加的同时，效率也不会大幅度降低。因此，能够同时监听的 Socket 的数量就非常的多了。上限为系统定义的，进程打开的最大文件描述符个数。因而，<strong>epoll 被称为解决 C10K 问题的利器</strong>。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>牢记基于 TCP 和 UDP 的 Socket 编程中，客户端和服务端需要调用的函数；</li><li>epoll 机制能够解决 C10K 问题。</li></ul><p>参考：</p><ol><li>The TCP/IP Guide；</li><li>百度百科 - Socket 词条；</li><li>刘超 - 趣谈网络协议系列课；</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TCP协议 </tag>
            
            <tag> socket编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 9 - TCP协议（下）：聪明反被聪明误</title>
      <link href="/12/wangluoxieyi/ck0669dra0030agaapklegpbd/"/>
      <url>/12/wangluoxieyi/ck0669dra0030agaapklegpbd/</url>
      
        <content type="html"><![CDATA[<p>上次了解了 TCP 建立连接与断开连接的过程，我们发现，TCP 会通过各种“套路”来保证传输数据的安全。除此之外，我们还大概了解了 TCP 包头格式所对应解决的五个问题：顺序问题、丢包问题、连接维护、流量控制、拥塞控制。今天，我们就来看下 TCP 又是用怎样的套路去解决这五个问题的。</p><p>在解决问题之前，咱们先来看看 TCP 是怎么成为一个“靠谱”的协议的。</p><h3 id="“靠谱”协议-TCP"><a href="#“靠谱”协议-TCP" class="headerlink" title="“靠谱”协议 TCP"></a>“靠谱”协议 TCP</h3><p>TCP 为了保证顺序性，每个包都有一个 ID。这建立连接的时候，会商定起始 ID 的值，然后按照 ID一个个发送。</p><p>为了保证不丢包，对于发送的包都要进行应答。但是这个应答不是一个一个来的，而是会应答某个之前的 ID，表示都收到了，这种模式称为<strong>累计确认</strong>和<strong>累计应答</strong>。</p><p>为了记录所有发送的包和接收的包，TCP 也需要发送端和接收端分别用缓存来保存这些记录。发送端的缓存里是按照包的 ID 一个个排列，根据处理的情况分成四个部分：</p><ul><li>第一部分：发送且已经确认的；</li><li>第二部分：发送尚未确认的；</li><li>第三部分：没有发送，但是已经等待发送的；</li><li>第四部分：没有发送，并且暂时还不会发送的。</li></ul><p>于是，发送端需要保持这样的数据结构：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181202220600506-1987444038.png" alt=""></p><ul><li>LastByteAcked：第一部分和第二部分的分界线</li><li>LastByteSent：第二部分和第三部分的分界线</li><li>LastByteAcked：第三部分和第四部分的分界线</li></ul><p>对于接收端来讲，它缓存记录的内容要简单一些，分为以下三个部分：</p><ul><li>第一部分：接收且确认过的；</li><li>第二部分：还没接收，但是马上就能接收的；</li><li>第三部分：还没接收，也没空间接收的。</li></ul><p>对应的数据结构就像这样：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181202220523814-175359992.png" alt=""></p><ul><li>MaxRcvBuffer：最大缓存量；</li><li>LastByteRead：这个值之后是已经接收，但是还没被应用层读取的；</li><li>NextByteExpected：第一部分和第二部分的分界线，下一个期待的包 ID。</li></ul><p>第二部分的窗口有多大呢？</p><p>NextByteExpected 和 LastByteRead 的差起始是还没被应用层读取的部分占用掉的 MaxRcvBuffer 的量，我们定义为 A，即：A = NextByteExpected - LastByteRead - 1。</p><p>那么，窗口大小，AdvertisedWindow = MaxRcvBuffer - A。</p><p>也就是：AdvertisedWindow = MaxRcvBuffer - (NextByteExpected - LastByteRead - 1)</p><p>而第二部分和三部分的分界线 = NextByteExpected + AdvertisedWindow - 1 = MaxRcvBuffer + LastByteRead。</p><h3 id="顺序与丢包问题"><a href="#顺序与丢包问题" class="headerlink" title="顺序与丢包问题"></a>顺序与丢包问题</h3><p>接下来，我们结合上述图例，用一个例子来看下 TCP 如何处理顺序与丢包问题的。</p><p>还是刚才的图，在发送端看来：</p><ul><li>1、2、3 是已经发送并确认的；</li><li>4、5、6、7、8、9 都是发送未确认的；</li><li>10、11、12 是还没发出的；</li><li>13、14、15 是接收方没有空间，不准备发送的。</li></ul><p>而在接收端看来：</p><ul><li>1、2、3、4、5 是已经完成 ACK，但还没读取的；</li><li>6、7 是等待接收的；</li><li>8、9 是已经接收，但是没有 ACK 的。</li></ul><p>发送端和接收端当前的状态如下：</p><ul><li>1、2、3 没有问题，双方达成了一致；</li><li>4、5 接收方发送 ACK 了，但是发送方还没收到，有可能丢了，有可能还在路上；</li><li>6、7、8、9 肯定都发了，但是 8、9 已经到了，6、7还没打，出现了乱序，于是在缓存中存储，但是没有返回 ACK。</li></ul><p>根据这个例子，我们可以知道，顺序问题和丢包问题都有了能发送，所以我们先来看<strong>确认与重发的机制</strong>。<br>假设 4 的确认到了，不幸的是，5 的 ACK 丢了，并且 6、7 的数据包也丢了，这时候会怎么处理呢？</p><p>一种方法是<strong>超时重试</strong>，也就是对每一个发送了，但是没有 ACK 的包，都有设一个定时器，一旦超过了一定的时间，就重新尝试。这个超时时间不宜过短，时间必须大于往返时间 RTT，否则就会引起不必要的重传也不宜过长，这样超时时间变长，访问就变慢了。</p><p>估计往返时间，需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断的变化。</p><p>除了采样 RTT，还要采样 RTT 的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，我们称为<strong>自适应重传算法（Adaptive Retransmission Algorithm）</strong>。</p><p>如果过一段时间，5、6、7 都超时了，就会重新发送。接收方发现 5 原来接收过，于是就丢弃5。收到了6，发送 ACK，要求下一个是 7，7 不幸又丢了。</p><p>当 7 再次超时的时候，如果有需要重传，TCP 的策略就是<strong>超时间隔加倍。每当遇到一次超时重传的实时，都会将下一次超时时间间隔设置为先前值的两倍。两次超时，就说明网络环境差，不宜频繁发送。</strong></p><p>可以看出，超时重发存在的问题是，超时周期可能较长。那是不是可以有更快的方式呢？</p><p>有一个可以<strong>快速重传</strong>的机制。当接收方收到一个序号大于下一个所期望的报文段时，就检测到了数据流中的一个间格，于是发送三个冗余的ACK，客户端收到后，就在定时器过期之前，重传丢失的报文段。</p><p>例如，接收方发现 6、8、9 都已经接收了，但是 7 没来。于是发送三个 6 的 ACK，要求下一个是 7。客户端收到三个，就会发现 7 的确丢了，不等超时，就马上重发。</p><p>除此之外，还有一种方式称为 <strong>Selective Acknowledgment（SACK）</strong>。这种方式需要在 TCP 头里加一个 SACK 的东西，可以将缓存的地图发格发送方。例如发送 ACK6、SACK8、SACK9，有了地图，发送方一下子就能看出来是 7 丢了，然后快速重发。</p><h3 id="流量控制问题"><a href="#流量控制问题" class="headerlink" title="流量控制问题"></a>流量控制问题</h3><p>接下来，我们再来看看流量控制机制。在对于包的确认中，会同时携带一个窗口大小的字段。</p><p>我们先假设窗口不变的情况，发送端窗口始终为 9。4 的确认来的时候，<strong>LastByteAcked 会右移一个</strong>，这个时候，第 13 个包就可以发送了。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181202220441515-677353744.png" alt=""></p><p>这个时候，假设发送端发送过猛，将第三部分中的 10、11、12、13 全部发送，之后就停止发送，则此时未发送可发送部分为 0。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181202220359870-1434717862.png" alt=""></p><p>当对于包 5 的确认到达的时候，在客户端相当于窗口再滑动了一格，这个时候，才可以有更多的包可以发送了，例如第 14 个包才可以发送。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181202220326497-1013008170.png" alt=""></p><p>如果接收方处理的太慢，导致缓存中没有空间了，可以通过确认信息修改窗口的大小，甚至可以设置为 0，则发送方将暂时停止发送。</p><p>我们可以假设一个极端情况，接收端的应用一直不读取缓存中的数据，当数据包 6 确认后，窗口大小就不会再是 9，而是减少一个变为了 8。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181202221428029-1293899815.png" alt=""></p><p>为什么会变为 8？你看，下图中，当 6 的确认消息到达发送端的时候，左边的 LastByteAcked 右移一位，而右边的未发送可发送区域因为已经变为 0，因此左边的 LastByteSend 没有移动，因此，窗口大小就从 9 变成了 8。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181202220155840-1665175926.png" alt=""></p><p>而如果接收端一直不处理数据，则随着确认的包越来越多，窗口越来越小，直到为 0。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181202220131896-367496677.png" alt=""></p><p>当这个窗口大小通过包 14 的确认到达发送端的时候，发送端的窗口也调整为 0，于是，发送端停止发送。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181202220057762-352180553.png" alt=""></p><p>当发生这样的情况时，发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。对于接收方来说，当接收比较慢的时候，要防止低能窗口综合征，别空出一个字节就赶紧告诉发送方，结果又被填满了。可以在窗口太小的时候，不更新窗口大小，直到达到一定大小，或者缓冲区一半为空，才更新窗口大小。</p><p>这就是我们常说的<strong>流量控制</strong>。</p><h3 id="拥塞控制问题"><a href="#拥塞控制问题" class="headerlink" title="拥塞控制问题"></a>拥塞控制问题</h3><p>最后，我们来看一下拥塞控制的问题。</p><p>这个问题，也是靠窗口来解决的。前面的滑动窗口 rwnd 是怕发送方把接收方缓存塞满，而<strong>拥塞窗口 cwnd</strong>，是怕把网络塞满。</p><p>这里有一个公式：</p><blockquote><p>LastByteSent - LastByteAcked &lt;= min{cwnd, rwnd}</p></blockquote><p>可以看出，是拥塞窗口和滑动窗口共同控制发送的速度。</p><p>那发送方怎么判断网络是不是满呢？这其实是个挺难的事情。因为对于 TCP 协议来讲，它压根不知道整个网络路径都会经历什么。TCP 发送包常被比喻为往一个水管里灌水，而 TCP 的拥塞控制就是在不堵塞、不丢包的情况下，尽量发挥带宽。</p><p>水管有粗细，网络有带宽，也就是每秒钟能够发送多少数据；</p><p>水管有长度，端到端有时延。在理想情况下：</p><blockquote><p>水管里的水量 = 水管粗细 x 水管长度</p></blockquote><p>而对于网络来讲：</p><blockquote><p>通道的容量 = 带宽 x 往返延迟</p></blockquote><p>如果我们设置发送窗口，<strong>使得发送但未确认的包的数量为通道的容量</strong>，就能够撑满整个管道。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181202220021136-1274727720.png" alt=""></p><p>如上图所示：</p><blockquote><p>假设往返时间为 8s，去 4s，回 4s，每秒发送一个包，每个包 1024 byte。</p></blockquote><p>那么在 8s 后，就发出去了 8 个包。其中前 4 个包已经到达接收端，但是 ACK 还没有返回，不能算发送成功。而 5-8 后四个包还在路上，没被接收。</p><p>这个时候，整个管道正好撑满。在发送端，已发送未确认的为 8 个包，也就是：</p><blockquote><p>带宽 = 1024byte/s x 8s（来回时间）</p></blockquote><p>如果我们在这个基础上再调大窗口，使得单位时间内更多的包可以发送，会出现什么现象呢？</p><p>原来发送一个包，从一端到另一端，假设一共经过四个设备，每个设备处理一个包耗时 1s，所以到达另一端需要耗费 4s。如果发送的更加快速，则单位时间内，会有更多的包到达这些中间设备，这些设备还是只能每秒处理一个包的话，多出来的包就会被丢弃，这不是我们希望看到的。</p><p>这个时候，我们可以想其他的办法。例如，这四个设备本来每秒处理一个包，但是我们在这些设备上加缓存，处理不过来的就在队列里面排着，这样包就不会丢失，但是缺点也是显而易见的，增加了时延。这个缓存的包，4s 肯定到达不了接收端，如果时延达到一定程度，就会超时，这也不是我们希望看到的。</p><p>针对上述两种现象：<strong>包丢失</strong>和<strong>超时重传</strong>。一旦出现了这些现象就说明，发送速度太快了，要慢一点。但是一开始，发送端怎么知道速度多快呢？怎么知道把窗口调整到合适大小呢？</p><p>如果我们通过漏斗往瓶子里灌水，我们就知道，不能一桶水一下子全倒进去，肯定会溢出来。一开始要慢慢的倒，然后发现都能够倒进去，就加快速度。这叫做<strong>慢启动</strong>。</p><p>一个 TCP 连接开始</p><ul><li>cwnd 设置为一个报文段，一次只能发送 1 个；</li><li>当收到这一个确认的时候，cwnd 加 1，于是一次能够发送 2 个；</li><li>当这两个包的确认到来的时候，每个确认的 cwnd 加 1，两个确认 cwnd 加 2，于是一次能够发送 4 个；</li><li>当这四个的确认到来的时候，每个确认 cwnd 加 1，四个确认 cwnd 加 4，于是一次能够发送 8 个。</li></ul><p>从上面这个过程可以看出，这是<strong>指数性的增长</strong>。</p><p>但是涨到什么时候是个头呢？一个值 ssthresh 为 65535 个字节，当超过这个值的时候，就会将将增长速度降下来。</p><p>此时，每收到一个确认后，cwnd 增加 1/cwnd。一次发送 8 个，当 8 个确认到来的时候，每个确认增加 1/8，8个确认一共增加 1，于是一次就能够发送 9 个，变成了<strong>线性增长</strong>。</p><p>即使增长变成了线性增长，还是会出现“溢出”的情况，出现拥塞。这时候一般就会直接降低倒水的速度，等待溢出的水慢慢渗透下去。</p><p>拥塞的一种变现形式是丢包，需要超时重传。这个时候，将 ssthresh 设为 cwnd/2，将 cwnd 设为 1，重新开始慢启动。也就是，一旦超时重传，马上“从零开始”。</p><p>很明显，这种方式太激进了，将一个高速的传输速度一下子停了下来，会造成网络卡顿。</p><p>前面有提过<strong>快速重传算法</strong>。当接收端发现丢了一个中间包的时候，发送三次前一个包的 ACK，告诉发送端要赶紧给我发下一个包，别等超时再重传。TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，cwnd 变为 cwnd/2，然后 sshthresh = cwnd。当三个包返回的时候，cwnd = sshthresh + 3。</p><p>可以看出这种情况下降速没有那么激进，cwnd 还是在一个比较高的值，呈线性增长。下图是两者的对比。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181202215858092-201529895.png" alt=""></p><p>就像前面说的一样，正是这种知进退，使得时延在很重要的情况下，反而降低了速度。但是，我们仔细想一想，TCP 的拥塞控制主要用来避免的两个现象都是有问题的。</p><p>第一个问题是丢包。<strong>丢包并不一定表示通道满了</strong>，也可能是管子本来就”漏水”。就像公网上带宽不满也会丢包，这个时候就认为拥塞，而降低发送速度其实是不对的。</p><p>第二个问题是 TCP 的拥塞控制要等到将中间设备都填满了，才发送丢包，从而降低速度。但其实，这时候降低速度已经晚了，在将管道填满后，不应该接着填，直到发生丢包才降速。</p><p>为了优化这两个问题，后来就有了 <strong>TCP BBR 拥塞算法</strong>。它企图找到一个平衡点，就是通过不断的加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，<strong>在这个平衡点可以很好的达到高带宽和低时延的平衡</strong>。</p><p>下图是 BBR 算法与普通 TCP 的对比：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201812/861679-20181202215757537-366791225.png" alt=""></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>顺序问题、丢包问题、流量控制都是通过滑动窗口来解决的。这就相当于领导和员工的备忘录，布置过的工作要有编号，干完了有反馈，活不能派太多，也不能太少；</li><li>拥塞控制是通过拥塞窗口来解决的，相当于往管道里面倒水，快了容易溢出，慢了浪费带宽，要摸着石头过河，找到最优值。</li></ul><p>参考：</p><ol><li>The TCP/IP Guide；</li><li>百度百科 - TCP词条；</li><li>刘超 - 趣谈网络协议系列课；</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TCP协议 </tag>
            
            <tag> 三次握手 </tag>
            
            <tag> 四次挥手 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 8 - TCP协议（上）：性恶就要套路深</title>
      <link href="/11/wangluoxieyi/ck0669dqs002wagaa47qdjrbf/"/>
      <url>/11/wangluoxieyi/ck0669dqs002wagaa47qdjrbf/</url>
      
        <content type="html"><![CDATA[<p>上次说了“性本善”的 UDP 协议，这哥们秉承“网之初，性本善，不丢包，不乱序”的原则，徜徉在网络世界中。</p><p>与之相对应的，TCP 就像是老大哥一样，了解了社会的残酷，变得复杂而成熟，秉承“性恶论”。它认为网络环境是恶劣的，丢包、乱序、重传、拥塞都是常有的事儿，一言不合可能就会丢包，送达不了，所以从算法层面来保证可靠性。</p><h3 id="TCP-包头格式"><a href="#TCP-包头格式" class="headerlink" title="TCP 包头格式"></a>TCP 包头格式</h3><p>老规矩，咱们先来看看 TCP 头的格式。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181128082418127-114482738.png" alt=""></p><p>从上面这个图可以看出，它比 UDP 要复杂的多。而复杂的地方，也正是它为了解决 UDP 存在的问题所必需的字段。</p><p>首先，源端口号和目标端口号是两者都有，不可缺少的字段。</p><p>接下来是<strong>包的序号</strong>。<strong>给包编号就是为了解决乱序的问题</strong>。老大哥做事，稳重为主，一件件来，面临再复杂的情况，也临危不乱。</p><p>除了发送端需要给包编号外，接收方也会回复<strong>确认序号</strong>。做事靠谱，答应了就要做到，暂时做不到也要给个回复。</p><p>这里要注意的是，TCP 是个老大哥没错，但不能说他一定会保证传输准确无误的完成。从 IP 层面来讲，如果网络的确那么差，是没有任何可靠性保证的，即使 TCP 老大哥再稳，他也管不了 IP 层丢包，他只能尽可能的保证在他的层面上的可靠性。</p><p>然后是一些<strong>状态位</strong>。有以下常见状态位：</p><ul><li>SYN（Synchronize Sequence Numbers，同步序列编号）：发起一个连接</li><li>ACK（Acknowledgement，确认字符）：回复</li><li>RST（Connection reset）：重新连接</li><li>FIN：结束连接</li></ul><p>从这些状态位就可以看出，TCP 基于“性恶论”，警觉性就很高，不像 UDP 和小朋友似的，随便一个不认识的小朋友都能玩到一起，他与别人的信任要经过多次交互才能建立。</p><p>还有一个<strong>窗口大小</strong>。这个是 TCP 用来进行流量控制的。通信双方各声明一个窗口，标识自己当前的处理能力，让发送端别发送的太快，要不然撑死接收端。也不能发送的太慢，要不然就饿死接收端了。</p><p>根据上述对 TCP 头的分析，我们知道对于 TCP 协议要重点关注以下几个问题：</p><ul><li>顺序问题，稳重不乱；</li><li>丢包问题，承诺靠谱；</li><li>连接伟豪，有始有终；</li><li>流量控制，把握分寸；</li><li>拥塞控制，知进知退。</li></ul><h3 id="TCP-的三次握手"><a href="#TCP-的三次握手" class="headerlink" title="TCP 的三次握手"></a>TCP 的三次握手</h3><p>了解完 TCP 头，我们就来看下 TCP 建立连接的过程，这就是著名的“<strong>三次握手</strong>”。</p><p>三次握手，过程是这样子的：</p><ul><li>A：你好，我是 A（<strong>SYN</strong>）。</li><li>B：你好 A，我是 B（<strong>SYN，ACK</strong>）。</li><li>A：你好 B（<strong>ACK 的 ACK</strong>）。</li></ul><p>着重记忆上述过程，后续很多分析都是基于这个过程来的。</p><p>记得刚接触三次握手的时候，就一直很纳闷，为啥一定要三次？两次不行吗？四次不行吗？然后很多人就解释，如果是两次，就怎样怎样，四次，又怎样怎样？但这其实都是<strong>从结果推原因</strong>，没有说明本质。</p><p>我们应该知道，<strong>握手是为了建立稳定的连接</strong>，这个是最终目的。而要达到这个目的，就要<strong>通信双方的交互形成一个确认的闭环</strong>。</p><p>拿上述 A、B 通信的例子来看，A 给 B 发信息，B 要告诉 A 他收到信息了。这时候，算是一个确认闭环吗？明显不是，因为 B 没有收到来自 A 的确认信息。</p><p>所以，要达到我们上述的目标，还要 A 给 B 一个确认信息，这样就形成了一个<strong>确认闭环</strong>。</p><p>A 给 B 的确认信息发出后，遇到网络不好的情况，也会出现丢包的情况。按理来说，还应该有个回应，但是，我们发现，好像这样下去就没玩没了啦。</p><p>所以，我们说，只要通信双方形成一个确认闭环后，就认为连接已建立。一旦连接建立，A 会马上发送数据，而 A 发送数据，后续的很多问题都得到了解决。</p><p>例如 A 发给 B 的确认消息丢了，当 A 后续发送的数据到达的时候，B 可以认为这个连接已经建立。如果 B 直接挂了，A 发送的数据就会报错，说 B 不可达，这样，A 也知道 B 出事情了。</p><p>三次握手除了通信双方建立连接外，主要还是<strong>为了沟通 TCP 包的序号问题</strong>。</p><p>A 要告诉 B，我发起的包的序号起始是从哪个号开始的，B 也要告诉 A，B 发起的包的序号的起始号。</p><p>TCP 包的序号是会随时间变化的，可以看成一个 32 位的计数器，每 4ms 加一。计算一下，这样到出现重复号，需要 4 个多小时。但是，4 个小时后，还没到达目的地的包早就死翘翘了。这是因为 IP 包头里的 TTL（生存时间）。</p><p>为什么序号不能从 1 开始呢？因为这样会很容易出现冲突。</p><p>例如，A 连上 B 之后，发送了 1、2、3 三个包，但是发送 3 的时候，中间丢了，或者绕路了，于是重新发送，后来 A 掉线了，重新连上 B 后，序号又从 1 开始，然后发送 2，但是压根没想发送 3，而如果上次绕路的那个 3 刚好又回来了，发给了 B ，B 自然就认为，这就是下一包，于是发生了错误。</p><p>就这样，双方历经千辛万苦，终于建立了连接。前面也说过，为了维护这个连接，双方都要维护一个状态机，在连接建立的过程中，双方的状态变化时序图就像下面这样：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181128084317084-1063029718.png" alt=""></p><p>整体过程是：</p><ol><li>客户端和服务端都处于 CLOSED 状态；</li><li>服务端主动监听某个端口，处于 LISTEN 状态；</li><li>客户端主动发起连接 SYN，处于 SYN-SENT 状态。</li><li>服务端收到客户端发起的连接，返回 SYN，并且 ACK 客户端的 SYN，处于 SYN-RCVD 状态；</li><li>客户端收到服务端发送的 SYN 和 ACK 之后，发送 ACK 的 ACK，处于 ESTABLISHED 状态；</li><li>服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态。</li></ol><h3 id="TCP-的四次挥手"><a href="#TCP-的四次挥手" class="headerlink" title="TCP 的四次挥手"></a>TCP 的四次挥手</h3><p>说完了连接，接下来就来了解下 TCP 的“再见模式”。这也常被称为<strong>四次挥手</strong>。</p><p>还拿 A 和 B 举例，挥手过程：</p><ol><li>A：B 啊，我不想和你玩了。</li><li>B：哦，你不想玩了啊，我知道了。这个时候，还只是 A 不想玩了，就是说 A 不会再发送数据，但是 B 此时还没做完自己的事情，还是可以发送数据的，所以此时的 B 处于<strong>半关闭状态</strong>。</li><li>B：A啊，好吧，我也不想和你玩了，拜拜。</li><li>A：好的，拜拜。</li></ol><p>这样这个连接就关闭了。看起来过程很顺利，是的，这是通信双方“和平分手”的场面。</p><p>A 开始说“不玩了”，B 说“知道了”，这个回合，是没什么问题的，因为在此之前，双方还处于合作的状态。</p><p>如果 A 说“不玩了”，没有收到回复，那么 A 会重新发送“不玩了”。但是这个回合结束之后，就很可能出现异常情况了，因为有一方率先撕破脸。这种撕破脸有两种情况。</p><p>一种情况是，A 说完“不玩了”之后，<strong>A 直接跑路</strong>，这是会有问题的，因为 B 还没有发起结束，而如果 A 直接跑路，B 就算发起结束，也得不到回答，B 就就不知道该怎么办了。</p><p>另一种情况是，A 说完“不玩了”，<strong>B 直接跑路</strong>。这样也是有问题的，因为 A 不知道 B 是还有事情要处理，还是过一会发送结束。</p><p>为了解决这些问题，TCP 专门设计了几个状态来处理这些问题。接下来，我们就来看看断开连接时的<strong>状态时序图</strong>。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181128084731080-1093887870.png" alt=""></p><p>整体过程是：</p><ol><li>A 说“不玩了”，就进入 FIN_WAIT_1 状态；</li><li>B 收到 “A 不玩”的消息后，回复“知道了”，就进入 CLOSE_WAIT 状态；</li><li>A 收到“B 说知道了”，进入 FIN_WAIT_2 状态。这时候，如果 <strong>B 直接跑路</strong>，则 A 将永远在这个状态。TCP 协议里面并没有对这个状态的处理，但是 Linux 有，可以调整 tcp_fin_timeout 这个参数，设置一个超时时间；</li><li>B 没有跑路，发送了“B 也不玩了”的消息，处于 LAST_ACK 状态；</li><li>A 收到“B 说不玩了”的消息，回复“A 知道 B 也不玩了”的消息后，从 FINE_WAIT_2 状态结束。</li></ol><p>最后一个步骤里，如果 A 直接跑路了，也会出现问题。因为 A 的最后一个回复，B 如果没有收到的话就会重复第 4 步，但是因为 A 已经跑路了，所以 B 会一直重复第 4 步。</p><p>因此，TCP 协议要求 A 最后要等待一段时间，这个等待时间是 TIME_WAIT，这个时间要足够长，长到如果 B 没收到 A 的回复，B 重发给 A，A 的回复要有足够时间到达 B。</p><p>A 直接跑路还有一个问题是，A 的端口就空出来了，但是 B 不知道，B 原来发过的很多包可能还在路上，如果 A 的端口被新的应用占用了，这个新的应用会受到上个连接中 B 发过来的包，虽然序列号是重新生成的，但是这里会有一个双保险，防止产生混乱。因此也需要 A 等待足够长的时间，等到 B 发送的所有未到的包都“死翘翘”，再空出端口。</p><p>这个等待的时间设为 2MSL，MSL 是 <strong>Maximum Segment Lifetime，即报文最大生存时间</strong>。它是任何报文再网络上存在的最长时间，超过这个时间的报文就会被丢弃。</p><p>因为 TCP 报文基于 IP 协议，而 IP 头中有一个 TTL 域，是 IP 数据报可以经过的最大路有数，每经过一个处理他的路由器，此值就减 1，当此值为 0 时，数据报就被丢弃，同时发送 ICMP 报文通知源主机。协议规定 MSL 为 2 分钟，实际应用中常用的是 30 秒、1分钟和 2 分钟等。</p><p>还有一种异常情况，<strong>B 超过了 2MS 的时间，依然没有收到它发的 FIN 的 ACK</strong>。按照 TCP 的原理，B 当然还会重发 FIN，这个时候 A 再收到这个包之后，就表示，我已经等你这么久，算是仁至义尽了，再来的数据包我就不认了，于是直接发送 RST，这样 B 就知道 A 跑路了。</p><h3 id="TCP-状态机"><a href="#TCP-状态机" class="headerlink" title="TCP 状态机"></a>TCP 状态机</h3><p>将连接建立和连接断开的两个时序状态图综合起来，就是著名的 <strong>TCP 状态机</strong>。我们可以将这个状态机和时序状态机对照看，就会更加明了。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181128082725658-1252065989.png" alt=""></p><p>图中加黑加粗部分，是上面说到的主要流程，相关说明：</p><ul><li>阿拉伯数字序号：建立连接顺序；</li><li>大写中文数字序号：断开连接顺序；</li><li>加粗实线：客户端 A 的状态变迁；</li><li>加粗虚线：服务端 B 的状态变迁；</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>TCP 包头很复杂，主要关注 5 个问题。顺序问题、丢包问题、连接维护、流量控制、拥塞控制；</li><li>建立连接三次握手，断开连接四次挥手，状态图要牢记。</li></ul><p>参考：</p><ol><li>百度百科-TCP 词条；</li><li>刘超-趣谈网络协议系列课；</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TCP协议 </tag>
            
            <tag> 三次握手 </tag>
            
            <tag> 四次挥手 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 7 - UDP 协议：性善碰到城会玩</title>
      <link href="/11/wangluoxieyi/ck0669dqc002uagaaegfnla3b/"/>
      <url>/11/wangluoxieyi/ck0669dqc002uagaaegfnla3b/</url>
      
        <content type="html"><![CDATA[<p>网络协议五步登天路，我们一路迈过了物理层、链路层，今天终于到了传输层。从这一层开始，很多知识应该都是服务端开发必备的知识了，今天我们就一起来梳理下。</p><p>其实，讲到 UDP，就少不了 TCP。这俩货简直就是个“连体兄弟”，只要出现一个，另一个肯定就在不远处等着你。</p><p>博主相信，绝大多数的服务端开发都碰到过“TCP 与 UDP 的区别”这样的面试题，而在实际业务开发中，也会对比 TCP 与 UDP，选择合适的协议进行开发。</p><p>所以，咱们还是老生常谈，先来看看这俩兄弟的区别。</p><h3 id="TCP-与-UDP-的区别"><a href="#TCP-与-UDP-的区别" class="headerlink" title="TCP 与 UDP 的区别"></a>TCP 与 UDP 的区别</h3><p>相信很多人都知道，TCP 是面向连接的，UDP 是面向无连接的。</p><p>那么，什么是面向连接，什么是面向无连接呢？</p><p>在互通之前，面向连接的协议会先建立连接，再进行通信。就像 TCP 会进行三次握手，而 UDP 不会。</p><p>那为什么会建立连接呢？TCP 进行三次握手，UDP 就不能发三个数据包玩玩，有什么区别呢？</p><p>其实这里所谓的建立连接，<strong>就是通过建立一定的数据结构来维护客户端和服务端交互的状态，用这样的数据结构来保证所谓的面向连接的特性。</strong></p><p>上面这段话中，有一个很重要的词-<strong>状态</strong>。也就是说，TCP 实质上是一个<strong>有状态</strong>的服务。这个状态，可以说是它和 UDP 的本质区别。</p><p>通俗点讲，有状态的 TCP 就是<strong>有脑子</strong>的，它会记住数据是否已经精确发送了，发到哪里了，应该接收哪个数据，不能容忍一点错误。</p><p>与之对应的，<strong>UDP 就是没脑子的</strong>，天真无邪，发出去的数据就发出去，不会考虑网络世界的“恶意”。</p><p>TCP 既然有脑子，那肯定能做到很多 UDP 做不到的事情，例如：</p><ol><li>提供可靠交付。通过 TCP 连接传输的数据，无差错、不丢失、不重复，且按序到达。而 UDP 则是<strong>不保证不丢失，不保证按序到达</strong>。</li><li>面向字节流。TCP 发送的时候是一个流，没有头尾。而 UDP 是<strong>基于数据报，一个个发，一个个收</strong>；</li><li>可进行拥塞控制。TCP 意识到包丢弃或者网络环境不好的时候，会调整自己的行为，决定要发快点，还是发慢点。而 UDP 则是<strong>应用让我发，我就发，管它洪水滔天</strong>。。</li></ol><h3 id="UDP-包头"><a href="#UDP-包头" class="headerlink" title="UDP 包头"></a>UDP 包头</h3><p>发送的 UDP 包到达目标机器后，发现 MAC 地址匹配，于是取下来，然后再交给 IP 层处理，发现 IP 匹配，接下来呢？数据包给谁呢？</p><p>发送的时候，接收机器怎么知道数据包是 UDP 的包呢？所以在 IP 头里面有个 8 位协议，这里会存放，数据包究竟是 TCP 还是 UDP。</p><p>处理完传输层的事情，内核的事情基本上就干完了，里面的数据应该交给应用程序自己去处理。可是，一台机器上跑着那么多的应用程序，应该给谁呢？</p><p>无论应用程序写的是使用 TCP 传呼机，还是 UDP 传数据，都要监听一个端口。正式这个端口，用来区分应用程序。</p><p>这样，UDP 头里面的内容就都出来了，如下图：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181125143420694-640172375.png" alt=""></p><p>当我们看到 UDP 包头的时候，发现的确有端口号，有源端口号和目标端口号。但是它除了端口号，就再没有其他的，和 TCP 头比起来，简单的一塌糊涂。</p><h3 id="UDP-三大特点"><a href="#UDP-三大特点" class="headerlink" title="UDP 三大特点"></a>UDP 三大特点</h3><p>上面提过，UDP 像个小孩子一样，比较简单，有以下特点：</p><ol><li><strong>沟通简单</strong>。没有花花肠子（大量的数据结构、处理逻辑、包头字段），秉承“性善论”，相信网络通路很容易到达，不容易被丢弃；</li><li><strong>轻信他人</strong>。不会建立连接，只认端口号，谁都可以给他传数据，他也可以传给任何人数据，甚至可以同时传给多人数据；</li><li><strong>愣头青，做事不懂权变</strong>。不会根据网络的请求进行拥塞控制，不管网络再差，它该怎么发还怎么发。</li></ol><h3 id="UDP-使用场景"><a href="#UDP-使用场景" class="headerlink" title="UDP 使用场景"></a>UDP 使用场景</h3><p>正所谓“祸兮福所倚”，虽然 UDP 有着很多问题，但也可以在特定场景中发挥更好的作用。</p><p>第一，<strong>需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用</strong>。这很好理解，就像你是领导，你会让你们组刚毕业的小伙伴去做一些没有那么难，或者是失败了也能忍受的实验性项目。</p><p>我们之前认识的 <a href="https://www.cnblogs.com/BeiGuo-FengGuang/p/9877801.html" target="_blank" rel="noopener">DHCP</a> 就是基于 UDP 协议的。一般的获取 IP 地址都是内网请求，而且一次获取不到 IP 也没关系，过一会还可以请求获取。</p><p>第二，<strong>不需要建立连接，一对一沟通，而且需要广播的应用</strong>。 UDP 的不面向连接的功能，可以承载广播或多播的协议。DHCP 就是一种广播的形式。</p><p>对于多播，我们之前提到的 IP 地址中的 D 类地址，也就是组播地址。使用这个地址，可以将包组播给一批机器。当一台机器上的某个进程想监听某个组播地址时，需要发送 IGMP 包，所在网络的路由器收到这个包，知道有个机器有个进程在监听这个组播地址。当路由器收到这个组播地址的数据包时，就会将包转发给这台机器，这样就实现了跨路由器的组播。</p><p>第三，<strong>需要处理速度快、延时低、可以容忍少数丢包，但是要求即便网络阻塞，也毫不退缩，一往无前的时候</strong>。</p><p>UDP 简单、处理速度快，不像 TCP 那样操那么多的心。并且，TCP 在网络不好出现丢包的时候，它的拥塞策略会主动的降低发送速度，这就相当于本来环境就差，还自断臂膀，用户本来就卡，这下更卡了。</p><p>当前很多应用都是要求低时延的，他们可不想用 TCP 如此复杂的机制，而是想根据自己的场景，实现自己的可靠和连接保证。例如，如果应用觉得，有的包丢了就丢了，没必要重传了，而有的比较重要的包丢了，则应用自己重传，不依赖 TCP。</p><p>由于 UDP 十分简单，基本啥都没做，也就给了应用“城会玩”的机会。就像在和平年代，每个人应该有独立的思考和行为，应该可靠且礼让。但是如果在战争年代，往往不太需要过于独立的思考，而需要士兵简单服从命令即可。</p><h3 id="基于-UDP-的“城会玩”的五个例子"><a href="#基于-UDP-的“城会玩”的五个例子" class="headerlink" title="基于 UDP 的“城会玩”的五个例子"></a>基于 UDP 的“城会玩”的五个例子</h3><h5 id="城会玩-一：网页或-APP-的访问"><a href="#城会玩-一：网页或-APP-的访问" class="headerlink" title="城会玩 一：网页或 APP 的访问"></a>城会玩 一：网页或 APP 的访问</h5><p>网页和手机 APP 都是基于 HTTP 协议的，而HTTP 协议是基于 TCP 的，建立连接都需要多次交互，对于时延比较大的移动互联网来讲，建立一次连接需要的时间会比较长，而且移动互联网还是在移动中，TCP 可能还会断了重连，这也是很耗时的。</p><p>除此之外，目前的 HTTP 协议，往往采取多个数据通道共享一个连接的情况这样本来为了加快传输速度，但是 TCP 的严格顺序策略使得哪怕共享通道，前一个不来，后一个和前一个即便没关系，也要等着，时延也会加大。</p><p>而 QUIC（Quik UDP Internet Connections，快速 UDP 互联网连接）是 Google 提出的一种基于 UDP 改进的通信协议，其目的是降低网络通信的延迟，提供更好的用户互动体验。</p><p>QUIC 在应用层会自己实现快速连接建立、减少重传时延，自适应拥塞控制，是应用层“城会玩”的代表。</p><h5 id="“城会玩”-二：流媒体的协议"><a href="#“城会玩”-二：流媒体的协议" class="headerlink" title="“城会玩” 二：流媒体的协议"></a>“城会玩” 二：流媒体的协议</h5><p>直播协议多使用 RTMP，这个协议就是基于 UDP 的。TCP 的严格顺序传输要保证前一个收到了，下一个才能确认。对于直播来讲，这显然是不合适的，因为老的视频帧丢了就丢了，就算再传过来用户也不在意，他们要看新的了，如果一直没来，用户就会一直显示卡顿，新的也看不了。所以，对于直播，实时性比较重要，宁可丢包，也不要卡顿的。</p><p>另外，对于丢包，其实对于食品播放来讲，有的包可以丢，有的包不能丢，因为视频的连续帧里面，有的包重要，有的包不重要，如果必须要丢包，隔几个帧丢一个，其实看视频的人不会感知，但是如果连续丢帧，用户就会有感知了。因此，在网络不好的情况下，应用希望选择性的丢帧。</p><p>还有就是，当网络不好的时候，TCP 会主动降低发送速度。这对本来就卡的看视频来讲是要命的，本来应该马上重传，而不是主动让步。因此，很多直播应用，都基于 UDP 实现了自己的视频传输协议。</p><h5 id="“城会玩”-三：实时游戏"><a href="#“城会玩”-三：实时游戏" class="headerlink" title="“城会玩” 三：实时游戏"></a>“城会玩” 三：实时游戏</h5><p>游戏有一个特点，就是实时性比较高。快一秒你干掉别人，慢一秒就被别人爆头，所以很多职业玩家会买非常专业的鼠标和键盘，争分夺秒。</p><p>因而，实时游戏中客户端和服务端要建立长连接，来保证实时传输，但是游戏玩家很多，服务器却不多，由于维护 TCP 连接需要在内核维护一些数据结构，因而一台机器能够支撑的 TCP 连接数量是有限的。而 UDP 由于是没有连接的，在异步 IO 机制引入之前，常常是应对海量客户端连接的策略。</p><p>另外还是 TCP 的强顺序问题，对战的游戏，对网络的要求很简单，玩家通过客户端发送给服务器鼠标和键盘行走的位置，服务器会处理每个用户发送过来的所有厂家，处理完再返回给客户端，客户端解析响应，渲染最新的场景展示给玩家。</p><p>如果出现一个数据包丢失，所有事情都需要停下来等待这个数据包重发。客户端会出现等待接收数据，然而玩家并不关心过期的数据，相信大家玩CF 的时候，如果激战中卡 1 秒，是不是就有拍键盘的冲动？</p><p>游戏对实时要求较为严格的情况下，采用自定义的 UDP 协议，自定义重传策略，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性能造成的影响。</p><h5 id="“城会玩”-四：IoT物联网"><a href="#“城会玩”-四：IoT物联网" class="headerlink" title="“城会玩” 四：IoT物联网"></a>“城会玩” 四：IoT物联网</h5><p>一方面，物联网领域终端资源少，很可能只是内存非常小的嵌入式系统，而维护 TCP 协议代价太大。另一方面，物联网对实时性要求也很高。Google 旗下的 Nest 建立 Thread Group，推出了物联网通信协议 Thread，就是基于 UDP 协议的。</p><h5 id="“城会玩”-五：移动通信领域"><a href="#“城会玩”-五：移动通信领域" class="headerlink" title="“城会玩” 五：移动通信领域"></a>“城会玩” 五：移动通信领域</h5><p>在 4G 网络里，移动流量上网的数据协议 GTP-U 也是基于 UDP 的。因为移动网络协议比较复杂，而 GTP 协议本身就包含复杂的手机上线下线的通信协议。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li><p>如果把 TCP 比作成熟的社会人，那么 UDP 就是头脑简单的小朋友。TCP 复杂，UDP 简单；TCP 维护连接，UDP 谁都相信；TCP 会知进退，UDP 愣头青一个，勇往直前；</p></li><li><p>UDP 虽然简单，但是它可以用在环境简单、需要多播、应用层自己控制传输的地方。例如 DHCP、QUIC 等。</p></li></ul><p>参考：</p><ol><li>百度百科-UDP 词条；</li><li>刘超-趣谈网络协议系列课；</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TCP协议 </tag>
            
            <tag> UDP协议 </tag>
            
            <tag> UDP与TCP的区别 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 6 - 路由协议：敢问路在何方？</title>
      <link href="/11/wangluoxieyi/ck0669dtp0043agaaj346e13c/"/>
      <url>/11/wangluoxieyi/ck0669dtp0043agaaj346e13c/</url>
      
        <content type="html"><![CDATA[<p>前面例子中，我们都是在一个局域网内折腾。今天就让我们扩大范围，在多个局域网甚至到广阔的互联网世界中遨游，看看这中间会发生什么。</p><p>这个过程中，跨网关访问是我们要了解的第一个内容。</p><h3 id="跨网关访问"><a href="#跨网关访问" class="headerlink" title="跨网关访问"></a>跨网关访问</h3><p>当我们要了解跨网关访问时，就牵扯到 MAC 地址和 IP 地址的变化，因此，我们先来看下 MAC 头和 IP 头的细节。</p><h4 id="MAC-头和IP-头的细节"><a href="#MAC-头和IP-头的细节" class="headerlink" title="MAC 头和IP 头的细节"></a>MAC 头和IP 头的细节</h4><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181120204824723-362613673.png" alt=""></p><p>如图，在 MAC 头里，先是目标 MAC 地址，然后是源 MAC 地址，最后是协议类型。</p><p>在 IP 头里，最重要的就是源 IP 地址和目标 IP 地址。除此之外，还有版本号，也就是我们常说的 IPv4 和 IPv6、服务类型 TOS（表示数据包优先级）、TTL（数据包生存周期）以及标识协议（TCP 和 UDP）</p><p>当我们访问博客园时，经过的第一个网关应该就是我们配置的默认网关。当本机访问默认网关时，还是走局域网内部访问的步骤：</p><ol><li>将源地址和目标 IP 地址放入 IP 头；</li><li>通过 ARP 协议获得网关的 MAC 地址；</li><li>将源 MAC 地址和网关的 MAC 地址放入 MAC 头中，发送给网关。</li></ol><p>而我们的网关，一般就是指<strong>家里的路由器，是一个三层转发的设备</strong>。它会把 MAC 头和 IP 头都取下来，然后根据里面的内容，看看接下来把数据包转发到哪里。</p><p>很多情况下，人们把网关叫做路由器。其实并不准备，用这个比喻应该更为恰当些：</p><blockquote><p>路由器是一台设备，它有五个网口或者网卡，相当于有五只手，分别连着五个局域网。每只手的 IP 地址都和局域网的 IP 地址有着相同的网段，每只手都是它握住的那个局域网的网关。</p></blockquote><p>任何一个想发往其他局域网的包，都会到达其中一只手，被拿进来，拿下 MAC 头和 IP 头，然后根据自己的<strong>路由算法</strong>，选择另一只手，加上 IP 头和 MAC 头，然后扔出去。</p><p>注意，在上面这个过程中，有出现<strong>路由算法</strong>。接下来，我们就来认识下它。</p><h3 id="路由算法"><a href="#路由算法" class="headerlink" title="路由算法"></a>路由算法</h3><p>路由算法，又名选路算法，是提高路由协议功能，尽量减少路由时所带来的开销的算法。</p><p>路由算法可以根据多个特性来加以区分，找到到达目的地的最佳路由。</p><p>路由算法的区分点有很多，有</p><ul><li>静态与动态</li><li>单路径与多路径</li><li>平坦与分层</li><li>主机智能与路由器智能</li><li>域内与域间</li><li>链接状态与距离向量</li></ul><p>这里主要介绍<strong>静态与动态</strong>路由算法。</p><h4 id="静态路由"><a href="#静态路由" class="headerlink" title="静态路由"></a>静态路由</h4><p>静态路由算法，实质上是由网关配置好的映射表。</p><p>我们家里的路由器，可能会有这样的路由配置</p><blockquote><p>访问博客园，从 2 号口出去，下一跳是 IP2；<br>访问百度，从 3 号口出去，下一跳是 IP3。</p></blockquote><p>类似上述这样的规则就是静态路由，按照一定的语法保存在路由器里。</p><p>每当要选择从哪个口抛出去的时候，就一条一条的匹配规则，找到符合的规则，就按规则办事，从指定口抛出去，找下一跳 IP。</p><h4 id="过网关的“变”与“不变”"><a href="#过网关的“变”与“不变”" class="headerlink" title="过网关的“变”与“不变”"></a>过网关的“变”与“不变”</h4><p>之前我们了解到，MAC 地址是一个局域网内才有效的地址。因此，MAC 地址只要过网关，就肯定会改变。而 IP 地址在过网关后 ，就不一定会改变了。</p><p>经过网关 A 后，如果IP 地址没有改变，那 A 就是<strong>转发网关</strong>，否则，就是<strong>NAT网关</strong>。</p><h5 id="转发网关"><a href="#转发网关" class="headerlink" title="转发网关"></a>转发网关</h5><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181120183127766-1231266411.png" alt=""></p><p>如上图，服务器 A 要访问服务器 B，要经过过程：</p><p><strong>1）服务器 A 到 网关 A</strong></p><ol><li>检查 B 的网段，发现不在同一个网段，因此发给网关</li><li>由于网关的 IP 地址是已经配置好了，因此发送 ARP 获取网关的 MAC 地址</li><li>发送包</li></ol><p>而最后发送包的内容主要有：</p><ul><li>源 MAC：服务器 A 的 MAC</li><li>模板 MAC：192.168.1.1 网关的 MAC</li><li>源 IP：192.168.1.101</li><li>目标 IP：192.168.4.101</li></ul><p>数据包到达 192.168.1.1 这个网口后，网口发现 MAC 地址是它的，就将包收进来，然后开始“思考”往哪里转发。</p><p>这时候，路由器 A 中配置了规则 A1：</p><blockquote><p>要访问 192.168.4.0/24，就从 192.168.56.1 这个网口出去，下一跳是 192.168.56.2</p></blockquote><p><strong>2）网关 A 到 网关 B</strong></p><p>于是，路由器 A 匹配了 A1，要从 192.168.56.1 这个口发出去，发给 192.168.56.2。于是，又开始了这个过程：</p><ol><li>检查 B 的网段，发现在同一个网段， ARP 获取 MAC 地址</li><li>发送包</li></ol><p>数据包的内容是：</p><ul><li>源 MAC：192.168.56.1 的 MAC</li><li>模板 MAC：192.168.56.2 的 MAC</li><li>源 IP：192.168.1.101</li><li>目标 IP：192.168.4.101</li></ul><p>数据包到达 192 .168.56.2 网口，网口发现 MAC 地址是它的，就将包收进来，然后去检查路由规则。</p><p>路由器 B 配置以下规则 B1：</p><blockquote><p>想访问 192.168.4.0/24，就从 192.168.4.1 </p></blockquote><p>而路由器 B 发现，它的右网口就是目标地址网段的，因此就没有下一跳了。</p><p><strong>3）网关 B 到 服务器 B</strong></p><p>路由器 B 匹配上 B1。从 192.168.4.1 出口，发给 192.168.4.101。数据包内容：</p><ul><li>源 MAC：192.168.4.1 的 MAC</li><li>模板 MAC：192.168.4.101 的 MAC</li><li>源 IP：192.168.1.101</li><li>目标 IP：192.168.4.101</li></ul><p>服务器 B 收到数据包，发现 MAC 地址是它的，就把包收进来。</p><p>通过上面的过程可以看出，每到一个新的局域网， MAC 地址都是要变的，而 IP 地址则都不变。在 IP 头里面，不会保存任何网关的 IP 地址。</p><p>而我们说的下一跳，<strong>就是某个 IP 要将这个 IP 地址转换为 MAC 放入 MAC 头</strong>。</p><h5 id="NAT-网关"><a href="#NAT-网关" class="headerlink" title="NAT 网关"></a>NAT 网关</h5><p>NAT 网关，也就是 Network Address Translation。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181120183155658-172470405.png" alt=""></p><p>由于各个局域网都有各自的网段，很容易出现 IP 冲突的情况。如上图，美国服务器 A 的 IP 地址和 法国服务器 B 的 IP 地址都是 192.168.1.101/24，从 IP 上看，好像是自己访问自己，但实际上从美国的 192.168.1.101 访问法国的 192.168.1.101。</p><p>如何解决这个问题呢？既然局域网之间没有商量好 IP 分配，各管各的，那到国际上，也就是中间的局域网里面，就需要使用另外的地址，就像出国后，我们要改用护照一样。</p><p>首先，目标服务器 B 在国际上要有一个<strong>国际的身份</strong>，我们给它一个 190.168.56.2.在网关 B 上，我们记下来，国际身份 192.168.56.2 对应国内身份 192.168.1.101.凡是要访问 192.168.56.2 的，网关都要转成 192.168.1.101。</p><p>于是，源服务器 A 要访问目标服务器 B，目标地址就变成国际 IP 地址 192.168.56.2。过程如下：</p><p><strong>1）源服务器 A 发数据包到网关 A</strong></p><ol><li>检查服务器 B IP，不在同一网段</li><li>ARP 获取网关 MAC 地址</li><li>发送包</li></ol><p>数据包的内容是这样的：</p><ul><li>源 MAC：服务器 A 的 MAC</li><li>目标 MAC：192.168.1.1 这个网口的 MAC</li><li>源 IP：192.168.1.101</li><li>目标 IP：192.168.56.2</li></ul><p>路由器 A 中 192.168.1.1 这个网口收到数据包后，检查 MAC 地址一致，将包收进来。</p><p>在路由器 A 中配置了规则：</p><blockquote><p>想访问 192.168.56.2/24，就从 192.168.56.1 网口发出去，发给 192.168.56.2，没有下一跳。</p></blockquote><p>由于路由器的右网口（192.168.56.1） IP 地址和目标 IP 地址在同一网段，因此没有下一跳。</p><p><strong>2）网关 A 到网关 B</strong><br>当网络包发送到中间的局域网时，服务器 A 也需要有个国际身份。因此，源 IP 地址 192.168.1.101 要改成 192.168.56.1，所以数据包的内容是：</p><ul><li>源 MAC：192.168.56.1 的 MAC</li><li>目标 MAC：192.168.56.2 的 MAC</li><li>源 IP：192.168.56.1</li><li>目标 IP：192.168.56.2</li></ul><p>包到达 192.168.56.2 这个网口后，发现 MAC 一致，就将包收进来。</p><p>而路由器 B 是 NAT 网关，它上面配置了，国际身份 192.168.56.2 对应国内的 192.168.1.101，于是目标地址改为 192.168.1.101。</p><p>同样的，路由器 B 中配置了规则：</p><blockquote><p>想访问 192.168.1.101，就从 192.168.1.1 网口出去，没有下一跳。</p></blockquote><p>于是，数据包就从 192.168.1.1 这个网口发给 192.168.1.101。</p><p><strong>3）网关 B 到服务器 B</strong><br>数据包从 192.168.1.1 网口发出后，同样经过这些步骤：</p><ol><li>检查服务器 B 的 IP，在同一网段</li><li>ARP 获取服务器 B 的 MAC 地址</li><li>发送包</li></ol><p>这时的数据包就变成了：</p><ul><li>源 MAC：192.168.1.1 的 MAC</li><li>目标 MAC：192.168.1.101 的 MAC</li><li>源 IP：192.168.56.1</li><li>目标 IP：192.168.1.101</li></ul><p>服务器收到包后，检查 MAC 地址一致，就将数据包收进来。</p><p>从服务器 B 接收的数据包可以看出，源 IP 为 服务器 A 的国际身份，因而发送返回包的时候，也发给这个国际身份，由路由器 A 做 NAT，转换为国内身份。</p><h4 id="动态路由"><a href="#动态路由" class="headerlink" title="动态路由"></a>动态路由</h4><h5 id="动态路由算法"><a href="#动态路由算法" class="headerlink" title="动态路由算法"></a>动态路由算法</h5><h6 id="距离矢量路由算法"><a href="#距离矢量路由算法" class="headerlink" title="距离矢量路由算法"></a>距离矢量路由算法</h6><p><strong>1）基本思路</strong></p><blockquote><p>基于Bellman-Ford 算法。每个路由器都保存一个路由表，包含多行，每行对应网络中的一个路由器，每一行包含两部分信息，一个是要到目标路由器，从哪条线出去，另一个是到目标路由器的距离</p></blockquote><p><strong>2）存在问题</strong></p><p>a. <strong>好消息传得块，坏消息传的慢</strong>。</p><blockquote><p>新加入的路由器能够很快的新路由器信息广播出去。但是如果一个路由器挂了，挂的消息没有广播。每个经过这个宕机节点的路由器，无法得知该节点一宕机，而是试图通过其他的路径访问，直到试过了所有的路径，才发现这个路由器已经宕机了。</p></blockquote><p>示例：</p><p>b. <strong>每次发送消息，要发送整个全局路由表</strong></p><p>上面的两个问题，限制了<strong><em>距离矢量路由</em></strong>的网络规模，仅适用于小型网络（小于 15 跳）。</p><h6 id="链路状态路由算法"><a href="#链路状态路由算法" class="headerlink" title="链路状态路由算法"></a>链路状态路由算法</h6><p><strong>1）基本思路</strong></p><blockquote><p>基于Dijkstra 算法。当一个路由器加入网络是，首先是发现邻居，给邻居说 hello，邻居都回复。然后计算和邻居的距离，发送一个 echo，要求马上返回，除以 2 就是距离。接着将自己和邻居之间的链路状态包广播出去，发送到整个网络的每个路由器。</p></blockquote><p>这种算法中，每个路由器都能在自己本地构建一个完整的图，然后针对这个图使用 Dijkstra 算法，找到两点之间的最短路径。</p><p>不像距离矢量路由协议那样，更新时发送整个路由表。链路状态路由协议只广播更新的或改变的网络拓扑，这使得更新信息更小，节省了宽带和 CPU 利用率。而且一旦一个路由器挂了，它的邻居都会广播这个消息，可以使得坏消息迅速收敛。</p><h5 id="动态路由协议"><a href="#动态路由协议" class="headerlink" title="动态路由协议"></a>动态路由协议</h5><h6 id="基于链路状态路由算法的-OSPF"><a href="#基于链路状态路由算法的-OSPF" class="headerlink" title="基于链路状态路由算法的 OSPF"></a>基于链路状态路由算法的 OSPF</h6><blockquote><p>OSPF（Open Shortest Path First, 开放式最短路径优先）协议，广泛应用在<strong><em>数据中心</em></strong>的协议。由于主要用在数据中心内部，用于路由决策，因此称为<strong><em>内部网关协议（Interior Gateway Protocol，简称 IGP）</em></strong></p></blockquote><p>内部网关协议的重点就是<strong><em>找到最短路径</em></strong>。当存在多个最短路径时，可以在这多个路径中进行负载均衡，这常常被称为<strong><em>等价路由</em></strong>。</p><p>等价路由不仅可以用来分摊流量，还可以提高容错率，当一条路径不通时，还可以通过另外一条路到达目的地。</p><h6 id="基于距离矢量路由算法的-BGP"><a href="#基于距离矢量路由算法的-BGP" class="headerlink" title="基于距离矢量路由算法的 BGP"></a>基于距离矢量路由算法的 BGP</h6><blockquote><p>针对网络之间的路由协议，称为<strong><em>外网路由协议（Border Gateway Protocol，简称 BGP）</em></strong></p></blockquote><p>每个数据中心都有自己的路由配置。例如，哪些外部 IP 可以让内部知晓，哪些内部 IP 可以让外部知晓，哪些可以通过，哪些不能通过。</p><p>因此，在各个数据中心进行交互时，需要一种协议，通过这种协议，可以知道相邻数据中心的路由配置，从而找到数据中心之间最好的路由。</p><p>BGP 协议就是这样的协议。它不着眼于发现和计算路由，而在于控制路由的传播和选择最好的路由。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>数据包要离开本局域网，就要经过网关，网关就是路由器的一个网口；</li><li>路由器是一个三层设备，理由有如何寻找下一跳的规则；</li><li>经过路由器之后的 MAC 头肯定会变。如果 IP 不变，就是 <strong>转发网关</strong>，否则就是 <strong>NAT网关</strong>；</li><li>路由分静态路由和动态路由，动态路由可以配置复杂的策略路由，控制转发策略；</li><li>动态路由主流算法有两种，距离矢量算法和链路状态算法。基于两种算法产生两种协议，BGP 协议和 OSPF 协议。</li></ul><p>参考：</p><ol><li>百度百科</li><li>刘超-趣谈网络协议系列课；</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 路由协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PHP 扩展管理</title>
      <link href="/11/uncategorized/ck0669ddi000dagaazt1s3nih/"/>
      <url>/11/uncategorized/ck0669ddi000dagaazt1s3nih/</url>
      
        <content type="html"><![CDATA[<p>一直对 PHP 扩展了解的似是而非，每次安装扩展都要百度教程，很容易出现各种错误。所幸整理下管理扩展的所有操作，方便日后操作。</p><h4 id="查看已加载的扩展"><a href="#查看已加载的扩展" class="headerlink" title="查看已加载的扩展"></a>查看已加载的扩展</h4><ol><li>输出 phpinfo()；</li><li>使用 get_loaded_extensions()；</li><li>使用 extension_loaded(string name) 函数检查是否加载指定扩展；</li><li>php -m</li></ol><h4 id="Windows-安装扩展"><a href="#Windows-安装扩展" class="headerlink" title="Windows 安装扩展"></a>Windows 安装扩展</h4><blockquote><p>扩展包地址：<a href="https://windows.php.net/downloads/pecl/releases/" target="_blank" rel="noopener">https://windows.php.net/downloads/pecl/releases/</a></p></blockquote><h5 id="1、下载扩展"><a href="#1、下载扩展" class="headerlink" title="1、下载扩展"></a>1、下载扩展</h5><p>下载的扩展一定要与本机的系统版本及 php 版本相适应，否则很容易出现加载异常的问题。</p><p>下面以本机加载 phpredis 扩展为例：</p><blockquote><p>本机及 PHP 版本：win10 x64 7.2.11 Thread Safety </p></blockquote><p>phpredis（4.1.1 版本） 扩展下载列表：</p><blockquote><p>php_redis-4.1.1-7.2-nts-vc15-x64.zip<br>php_redis-4.1.1-7.2-nts-vc15-x86.zip<br>php_redis-4.1.1-7.2-ts-vc15-x64.zip<br>php_redis-4.1.1-7.2-ts-vc15-x86.zip</p></blockquote><p>上面名称中：</p><ul><li>4.1.1：redis 扩展版本</li><li>7.2：PHP 版本</li><li>ts、nts：分别表示安装的 PHP 是否是进程安全的版本</li><li>vc：15 和 PHP 编译器版本</li><li>x86：电脑位数。</li></ul><p>上述信息都可以在 phpinfo() 函数输出的信息中找到。如下图，可以看到，本机的信息。因此，我们要下载的版本就是：</p><blockquote><p>php_redis-4.1.1-7.2-ts-vc15-x64.zip</p></blockquote><h5 id="2、移动-dll-文件"><a href="#2、移动-dll-文件" class="headerlink" title="2、移动 .dll 文件"></a>2、移动 .dll 文件</h5><p>解压下载后的文件，将 php_redis.dll 文件拷贝到扩展文件夹中。</p><h6 id="扩展文件夹"><a href="#扩展文件夹" class="headerlink" title="扩展文件夹"></a>扩展文件夹</h6><p>扩展文件夹，在 php4.x 的版本中，默认是 PHP\extensions，而 php5.x 的版本中是 PHP\ext。</p><p>此外，可以通过 php.ini 文件中的 extension_dir 字段，查看或指定扩展所在路径。</p><h5 id="3、重启服务器"><a href="#3、重启服务器" class="headerlink" title="3、重启服务器"></a>3、重启服务器</h5><h4 id="linux-安装"><a href="#linux-安装" class="headerlink" title="linux 安装"></a>linux 安装</h4><h5 id="1、编译安装"><a href="#1、编译安装" class="headerlink" title="1、编译安装"></a>1、编译安装</h5><p>a) 下载 .tgz 文件<br>如下图，我们从扩展列表中进入到扩展详情页，将下载地址复制出来，在 linux 目录下用 wget 命令下载扩展包。</p><pre><code>wget http://pecl.php.net/get/redis-4.1.1.tgz</code></pre><p>b) 解压编译</p><pre><code>// 1、解压tar -zxvf redis-4.1.1.tgz// 2、利用 phpize 生成 configure 文件cd redis-4.1.1/opt/php/bin/phpize// 3、编译。php-config 一般在 php/bin 目录下./configure --with-php-config=/opt/php/bin/php-config// 4、安装make &amp;&amp; make install</code></pre><p>c) 重启服务</p><h5 id="2、“傻瓜式”安装"><a href="#2、“傻瓜式”安装" class="headerlink" title="2、“傻瓜式”安装"></a>2、“傻瓜式”安装</h5><p>a) 移动 .so 文件<br>我们在解压扩展包文件后，如果目录中有 .so 文件，只需要将 .so 文件移动到扩展目录下即可。</p><p>而扩展目录则可以查看 php-config 中的 extension_dir 字段。</p><p>b) 修改 php.ini 文件<br>在配置文件中，添加：</p><pre><code>extension=redis.so</code></pre><p>c) 重启服务器</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 5 - ICMP 与 ping：投石问路的侦察兵</title>
      <link href="/11/wangluoxieyi/ck0669dq1002oagaafm8z7adb/"/>
      <url>/11/wangluoxieyi/ck0669dq1002oagaafm8z7adb/</url>
      
        <content type="html"><![CDATA[<p>日常开发中，我们经常会碰到查询网络是否畅通以及域名对应 IP 地址等小需求，这时候用的最多的应该就是 ping 命令了。 那你知道 ping 命令是怎么工作的吗？今天，我们就来一起认识下 ping 命令及其对应的 ICMP 协议。</p><h3 id="ICMP-协议"><a href="#ICMP-协议" class="headerlink" title="ICMP 协议"></a>ICMP 协议</h3><p>ICMP 全称 Internet Control Message Protocol，指<strong>互联网控制报文协议</strong>。</p><p>网络本身是不可靠的，数据包在传输过程中，可能会发生很多突发事件并导致数据传输失败。而网络层的 IP 协议是一个无连接的协议，它不会处理网络层的故障，因此，我们需要其它的协议，在数据包传输出现故障时，能将故障信息传回来，这样才能对应处理相关问题。</p><p>就像在电视剧里看到的古代战争一样，打仗的时候需要通过斥候来传递战局情况，进而更好的控制战局。而 ICMP 报文在网络世界中就充当“斥候”这样的角色。</p><p>ICMP 报文是封装在 IP 包里面的。因为传输指令的时候，肯定需要源地址和目标地址。它本身格式非常简单，如下图：</p><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181116181719850-1322895430.png" alt=""></p><p>ICMP 报文有很多的类型，不同的类型有不同的代码，<strong>最常用的类型是主动请求，代码为 8，主动请求的应答，代码为 0</strong>。从大的方面看可以分为 <strong>查询报文类型</strong>和<strong>差错报文类型</strong>。</p><h4 id="查询报文类型"><a href="#查询报文类型" class="headerlink" title="查询报文类型"></a>查询报文类型</h4><p>我们经常在电视剧里听到这样的话：来人，前方战事如何？斥候回来没？一有情况，立刻通报。</p><p>类似这种主帅发起，主动查看敌情的情况，就对应着 <strong>ICMP的查询报文类型</strong>。例如，常见的 ping 命令就是<strong>查询报文，是一种主动请求，并且获得主动应答的 ICMP 协议</strong>。因此，ping 命令发出的包也是符合 ICMP 协议格式的，只不过它在后面增加了自己的格式。</p><p>对 ping 的主动请求，进行网络抓包，称为 <strong>ICMP ECHO REQUEST</strong>。同理，主动请求的回复，称为<strong>ICMP ECHO REPLY</strong>。比起原生的 ICMP，这里面多了两个字段，一个是标识符，另一个是序号。这不难理解，大帅派出去两队斥候，一队是找谁要的，一队是侦查战况的，要有个标识才能区分。</p><p>另一方面，派出去的斥候，都要编个号。如果派出去 10 个，回来 10 个，就说明前方战况不错。如果派出去 10 个，回来 2 个，就说明情况可能不妙。</p><p>在选项数据中，ping 还会存放发送请求的时间值，来计算往返时间，说明路程的长短。</p><h4 id="差错报文类型"><a href="#差错报文类型" class="headerlink" title="差错报文类型"></a>差错报文类型</h4><p>差错报文主要是用来<strong>将发送的出错报文相关信息返回到源设备，以供源设备确定如果更好的重发失败的数据包</strong>。</p><p>还是拿我们的“大帅”举例。</p><p>当主帅正在大帐中看地图，思考战事时，外面的小兵突然喊到：大帅，不好啦，张将军遭遇埋伏，全军覆没了。</p><p>这种是异常情况发起的，来报告发生了不好的事情，对应 ICMP 的差错报文。</p><p>差错报文有以下常用的类型：</p><ul><li>3：终点不可达</li><li>4：源抑制</li><li>5：重定向</li><li>11：超时</li></ul><p><strong>第一种情况终点不可达</strong>。小兵报告，大帅，送给张将军的粮草没有送到。</p><p>那大帅肯定会问，为啥没有送到？这就对应 ICMP 中的以下代码了。</p><ul><li>网络不可达代码：0</li><li>主机不可达代码：1</li><li>协议不可达：2</li><li>端口不可达：3</li><li>需要进行分片但设置了不分片：4</li></ul><p>具体的场景就像这样：</p><ul><li>网络不可达：大帅，找不到地方</li><li>主机不可达：大帅，找到地方，没找到张将军</li><li>协议不可达：大帅，找到地方，也找到人了，但是口令没对上。</li><li>端口不可达：大帅，找到地方，找到了人，也对上了口令，但事情没对上。我去送粮草，人家说在等救兵。</li><li>需要进行分片但设置不分片：大帅，走到一半，山路狭窄，想换瞎扯，但是出发前你下令严禁换小车，就没办法送到了。</li></ul><p><strong>第二种是源站抑制</strong>。也就是让源站放慢发送速度（小兵：大帅，粮草送的太多了吃不完，你可以慢点送）。</p><p><strong>第三种是时间超时</strong>。也就是超过网络包的生存时间还是没到目的地（大帅，送粮草的人都把粮食吃完了，还没到地方，已经饿死了）。</p><p><strong>第四种是路由重定向</strong>。也就是下次发给另一个路由器（大帅，上次送粮草的人本来只要走大王村，一公里就到了，结果非要绕道张家界，多了五公里，下次记得走大王村）。</p><p>差错报文的结构相对复杂一些。除了前面还是 IP，ICMP 的前 8 个字节不变，后面则跟上出错的那个 IP 包的 IP 头和 IP 正文的前 8 个字节。</p><p>而且这类斥候特别尽责，不但字节返回来报信，还把一部分遗物带回来。</p><ul><li>斥候：大帅，张将军已经战死沙场，这是他的印信和佩剑。</li><li>大帅：张将军是怎么死的（可以查看 ICMP 的前 8 字节）？没错，这是张将军的剑（IP 数据包的头及正文前 8 字节）。</li></ul><h3 id="ping：查询报文类型的使用"><a href="#ping：查询报文类型的使用" class="headerlink" title="ping：查询报文类型的使用"></a>ping：查询报文类型的使用</h3><p>接下来，我们重点来看 ping 命令的发送和接收过程。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181116181827463-1109902557.png" alt=""></p><p>假定主机 A 的 IP 地址是 192.168.1.1，主机 B 的 IP 地址是 192.168.1.2，它们都在同一个子网。那么，当在主机 A 上运行“ping 192.168.1.2” 后，会发生什么呢？</p><ol><li><strong>源主机构建 ICMP 请求数据包</strong>。这个数据包内包含多个字段。最重要的有两个，一个是<strong>类型字段</strong>，对应请求数据包而言，该字段为 8。另一个是<strong>顺序号</strong>，主要用于区分连续 ping 的时候发出的多个数据包。每发出一个请求数据包，顺序号会自动加 1.为了能够计算往返时间 RTT，它会在报文的数据部分插入发送时间。</li><li><strong>IP 层构建 IP 数据包</strong>。ICMP 协议将数据包连同目标 IP 一起交给 IP 层，IP 层将以 192.168.1.2 作为目的地址，本机 IP 地址作为源地址，加上其他控制信息，构建一个 IP 数据包。</li><li><strong>加入 MAC 头</strong>。找到 192.168.1.2 对应的 MAC 地址，附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。</li></ol><p>主机 B 收到数据帧后，会进行如下步骤：</p><ol><li><strong>检查 MAC 地址，丢弃或接收数据帧，提取 IP 数据包</strong>。检查数据包目的 MAC 地址，并与本机 MAC 地址对比。如符合，就接收数据帧，否则就丢弃。接收后检查数据帧，将 IP 数据包从帧中提取处理，交给本机的 IP 层。</li><li><strong>IP 层检查IP</strong>。检查完成后，提取有用的信息交给 ICMP 协议。</li><li><strong>构建 ICMP 应答包</strong>。应答数据包的类型字段为 0，顺序号为接收到的请求数据包中的顺序号。</li><li>将应答数据包发给主机 A。</li></ol><p>在规定的时间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达。</p><p>如果接收到了应打包，则说明目标主机可达。此时，源主机会检测时间延迟。就是用当前时刻减该数据包从源主机发出去的时刻。</p><p>当然，这只是最简单的，同个局域网的情况。如果跨网段的话，还会涉及网关的转发、路由器的转发等。</p><p>可以看出，ping 命令是使用了 ICMP 里面的 ECHO REQUEST 和 ECHO REPLY 类型。</p><p>那其它类型呢？是不是只有真正遇到错误的时候，才能收到？答案是否定的。有一个 Traceroute 命令，它会使用 ICMP 的规则，故意制造一些能够产生错误的场景。</p><h3 id="Traceroute：差错报文类型的使用"><a href="#Traceroute：差错报文类型的使用" class="headerlink" title="Traceroute：差错报文类型的使用"></a>Traceroute：差错报文类型的使用</h3><p>Traceroute 命令有两个比较常用的功能。</p><p>第一个功能：</p><p><strong>通过设置特殊的 TTL，追踪去往目的地时经过的路由器</strong></p><p>Traceroute 的参数执行某个目的 IP 地址，会发送一个 UDP 的数据包。</p><p>将 TTL 设置成 1 时，表示这个数据包的 MP 为 1，碰到第一个“拦路虎”（通常是路由器或一个其它类型的关卡）就会阵亡了，然后就会返回一个 ICMP 包，这个包就是 <strong>网络差错包</strong>，类型是<strong>时间超时</strong>。</p><p>通过差错包，我们就能得到数据包到第一个关卡时花费的时间及其每个关卡的 IP 地址（有的主机不会响应 ICMP，所以会出现请求时全是 * 的情况）。</p><p>那怎么知道 UDP 有没有到达目的主机呢？Traceroute 程序会发送一份 UDP 数据包给目的主机，但它会选择一个不可能的值作为 UDP 端口号（大于30000）。当该数据报到达目的主机时，由于找不到对应端口号，所以会返回一个“端口不可达”的错误报文。这样，我们就知道 UDP 是否到达主机了。</p><p>第二个功能：</p><p><strong>设置数据包不分片，确定路径的 MTU</strong></p><p>发送分组，并设置“不分片”标志。发送的第一个分组的长度正好与出口的 MTU 相等。如果中间遇到窄的关卡就会被卡主，返回 ICMP 网络差错包，类型是“需要进行分片但设置了不分片”。就这样，每次收到ICMP“不能分片”差错时就减小分组的长度，从而确定整个路径中的 MTU。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>ICMP 相当于网络世界的侦察兵。常用的有两种类型，主动探查的查询报文和异常报告的差错报文。</li><li>ping 命令使用查询报文，Traceroute 命令使用差错报文。</li></ul><p>参考：</p><ol><li>刘超-趣谈网络协议系列课；</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 查询报文 </tag>
            
            <tag> ICMP协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 4 - 交换机与 VLAN：办公室太复杂，我要回学校</title>
      <link href="/11/wangluoxieyi/ck0669dq8002ragaa38ycvzn7/"/>
      <url>/11/wangluoxieyi/ck0669dq8002ragaa38ycvzn7/</url>
      
        <content type="html"><![CDATA[<p>上一次，我们通过宿舍联网打魔兽的需求，认识了如何通过物理层和链路层组建一个宿舍局域网。今天，让我们切换到稍微复杂点的场景，办公室。</p><p>在这个场景里，就不像在宿舍那样，搞几根网线，拉一拉，扯一扯就可以了。一个办公室少到数十人，大至上百人，每个人都有一个网口，如果再算上整个楼层楼层、甚至整栋楼，这个网口就更多了。</p><p>类似办公室这样，这些复杂场景的网络布线就牵扯出一个专业名词-<strong>拓扑结构</strong>。</p><h3 id="什么是拓扑结构？"><a href="#什么是拓扑结构？" class="headerlink" title="什么是拓扑结构？"></a>什么是拓扑结构？</h3><p>在解释拓扑结构前，我们要先明白什么是拓扑。拓扑是 Topology 的音译，直译是地志学，最早指研究地形、地貌相类似的有关学科。现在是研究几何图形或空间在连续改变形状后还能保持不变的一些性质的一个学科。</p><p>计算机网络的拓扑结构是引用拓扑学中研究<strong>与大小、形状无关的点、线关系的方法</strong>，把网络中的计算机和通信设备抽象为一个点，把传输介质抽象为一条线，<strong>由点和线组成的几何图形</strong>就是计算机网络的<strong>拓扑结构</strong>。</p><h3 id="办公室拓扑结构的形成"><a href="#办公室拓扑结构的形成" class="headerlink" title="办公室拓扑结构的形成"></a>办公室拓扑结构的形成</h3><p>上面说过，每个办公室会有几十个甚至上百个网口。这个时候，一个交换机肯定不够用，需要多台交换机连接，而多台交换机连接就形成了一个稍微复杂的拓扑结构。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181110173904204-1605651537.png" alt=""></p><p>我们先来看两台交换机的情形。两台交换机连接着三个局域网，每个局域网上都有多台机器。如果机器 1 只知道机器 4 的 IP 地址，当它想要访问机器 4 时，把包发出去的时候，它必须知道机器 4 的 MAC 地址。我们来看看这个过程：</p><ul><li>机器 1 发起广播，机器 2 和交换机 A 都收到广播。机器 2 收到广播后，知道不是找它的，所以没它什么事。</li><li>交换机 A 一开始是不知道任何拓扑信息的，在它收到这个广播后，采取的策略是，除了广播包来的方向外，它还要转发给其他所有的网口。</li><li>机器 3 和交换机 B  收到了广播信息了，同样的，机器 3 也知道和它没什么关系。</li><li>交换机 B 收到广播信息后，这时候它也不知道任何拓扑信息，所以也进行广播，将包转发到局域网三，也就是机器 4 和机器 5。</li><li>机器 4 收到广播是，它发现是找它的，就主动响应说，这是找我的，我的 MAC 地址是 XXX。</li></ul><p>在机器 1 收到机器 4 的 MAC 地址后，一个 ARP 请求就成功完成了。</p><p>在上面过程中，交换机 A 和交换机 B 都是能够学习到这样的信息：</p><ul><li>机器 1 是在左边这个网口。</li></ul><p>当了解这样的信息后，如果机器 2 访问 机器 1，机器 2 发起一个 ARP 请求获取机器 1 的 MAC 地址，这个广播消息会发给机器 1 和交换机 A。这个时候交换机 A 已经知道机器 1 是在左边的网卡，所以它就不会将请求广播到局域网二和局域网三。</p><p>就这样，当交换机学习完所有的拓扑信息后，两台交换机工作得会越来越好。</p><p>但是随着办公室越来越大，交换机数量肯定会越来越多，当整个拓扑结构复杂，这么多网线绕来绕去，不可避免的就会出现一些意料之外的情况，其中最常见的问题就是<strong>环路问题</strong>。</p><h3 id="环路与广播风暴"><a href="#环路与广播风暴" class="headerlink" title="环路与广播风暴"></a>环路与广播风暴</h3><p>如下图。当两个交换机环路连接两个局域网时，你知道会出现什么结果吗？<br><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181110173948166-1574011819.png" alt=""></p><p>我们来想象下机器 1 访问机器 2 的过程。</p><ul><li>机器 1 发起 ARP 广播</li><li>机器 2 收到广播，把 MAC 地址返回。</li></ul><p>咦，整个过程很顺利，没什么问题。</p><p>但是我们忽略了，两个交换机也是能收到广播包的。我们来看看两个交换机的广播过程：</p><ol><li>交换机 A 开始不知道拓扑信息，于是将广播信息放到局域网二</li><li>消息在局域网二广播，交换机 B 右网卡收到广播消息，于是将信息放到局域网一</li><li>消息在局域网一广播，交换机 A 左网口收到消息，又将广播信息放到局域网二</li><li>……</li></ol><p>看出来了吗？这样一直广播，就会形成一个环路，最终成为<strong>广播风暴</strong>，直到网络瘫痪。</p><p>上面过程，可能会有人说，两台交换机逐渐学习到拓扑结构后 ，是不是就可以了？那就让我们来看下它们的学习过程：</p><ol><li>在局域网一，交换机 A、B 收到机器 1 的广播包后，知道机器 1 都是在<strong>左网口</strong></li><li>当广播放到局域网二后，交换机 B <strong>右网口</strong>又收到了来自机器 1 的广播包，于是就误会机器 1 换位置了，就记住了机器 1 是在<strong>右网口</strong>，把之前学习到的信息清理掉</li><li>同理，交换机 A 右网口收到了机器 1 的广播包，同样误会了，于是也学会了，机器 1 在<strong>右网口</strong>，不是在左网口</li></ol><p>就这样，两个交换机会不断刷新“三观”，机器 1 是在左网口，过一会，发现不对，机器 1 是在右网口，过了一会，又发现不对，是在左网口。于是，又形成了一个“广播风暴”。</p><p>那么，有什么方法可以解决环路问题呢？这就到了 STP 协议出场的时候了。</p><h4 id="STP-协议中那些难以理解的概念"><a href="#STP-协议中那些难以理解的概念" class="headerlink" title="STP 协议中那些难以理解的概念"></a>STP 协议中那些难以理解的概念</h4><p>在数据结构中，有一个方法叫作<strong>最小生成树</strong>。有环的我们常称为<strong>图</strong>。将图中的环破了，就生成了<strong>树</strong>。而在计算机网络中，生成树的算法叫作 <strong>STP（Spanning Tree Protocol）</strong>。</p><p>STP 协议比较复杂，一开始很难看懂，让我们来通过华山论剑，决出五岳盟主的方式看看生成树的过程。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181110174039184-975223027.png" alt=""></p><p>在 STP 协议里面有很多概念，译名就非常拗口，让我们以门派中的职位来帮助大家理解。</p><ul><li>Root Bridge，也就是<strong>根交换机</strong>。可以比喻为“掌门”交换机，是某棵树的老大。</li><li>Designated Bridge，也就是<strong>指定交换机</strong>。这个比较难理解，可以想象成一个“小弟”，对于树来说，就是一棵树的树枝。所谓“指定”的意思是，我拜谁做大哥，其他交换机通过这个交换机到达根交换机，也就相当于拜他做了大哥。这里注意是树枝，不是叶子，因为叶子往往是主机。</li><li>Bridge Protocol Data Units（BPDU），<strong>网桥协议数据单元</strong>。可以比喻为“相互比较实力“的协议。行走江湖，比的就是武功，拼的就是实力。当两个交换机碰见的时候，也就是相连的时候，就需要互相比比内力。BPDU 只有掌门能发，隶属于某个掌门的交换机只能传达掌门的指示。</li><li>Priority Vector，<strong>优先级向量</strong>。可以比喻为实力（值越小越牛）。实力是啥？就是一组 ID，[Root Bridge ID, Root Path Cost, Bridge ID, and Port ID]。为什么这样设计呢？这是因为要看怎么来比实力。先看 Root Bridge ID，也就是老大的 ID，发现掌门一样，那就是师兄弟；再比 Root Path Cost，也就是我距离我老大的距离，也就是拿和掌门的关系比，看同一个门派内谁和老大关系铁；最后比 Bridge ID，比我自己的 ID，拿自己的本事比。</li></ul><p>概念都准备好了，下面我们看看 STP 是怎么工作的。</p><h3 id="STP-的工作过程"><a href="#STP-的工作过程" class="headerlink" title="STP 的工作过程"></a>STP 的工作过程</h3><p>一开始，江湖纷争，异常混乱。大家都觉得自己是掌门，谁也不服谁。于是，所有的交换机都认为自己是掌门，每个网桥都分配了一个 ID。这个 ID 里有管理员分配的优先级，当然管理员指定哪些交换机性能好，就给它们分配高的优先级。这种交换机生下来武功就很高，起步就是乔峰。</p><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181110174109306-1827776742.png" alt=""></p><p>既然都是掌门，互相都连长网线，那就互相发送 BPDU 来比功夫呗。这一比就发现，有人是岳不群，有人是封不平。赢的人接着做掌门，输的就只好做小弟了。当掌门的还会继续发 BPDU，而输的人就没有机会了，它们就只有在收到掌门发的 BPDU 的时候，转发一下，表示服从命令。</p><p>数字表示优先级。就像上面的图，5 和 6 碰见了，6 的优先级低（数字越小，优先级越高），所以乖乖做小弟。于是，一个小门派形成，5 是掌门，6 是小弟。其他诸如 1-7、2-8、3-4 这样的小门派也诞生了。接着，这些小的门派就好相互合并。</p><p>合并的过程会出现以下四种情形。</p><h5 id="情形一：掌门遇见掌门"><a href="#情形一：掌门遇见掌门" class="headerlink" title="情形一：掌门遇见掌门"></a>情形一：掌门遇见掌门</h5><p>当 5 碰到了 1，掌门碰见掌门，1 觉得自己是掌门，5 也刚刚跟别人 PK 完，成为掌门。这俩掌门比功夫，最终 1 胜出，于是 5 就率领所有的小弟归顺。结果就是 1 成功大掌门。</p><h5 id="情形二：同门相遇"><a href="#情形二：同门相遇" class="headerlink" title="情形二：同门相遇"></a>情形二：同门相遇</h5><p>同门相遇可以是掌门与自己的小弟相遇，这说明存在“环”了。这个小弟已经通过其他门路拜在你门下，结果你还不认识，还 PK 了一把。结果掌门发现这个小弟功夫不错，不应该级别这么低，就把它招到门下亲自带，那这个小弟就相当于升职了。</p><p>我们再来看，假如 1 和 6 相遇。6 原来就拜在 1 的门下，只不过 6 的上司是 5，5 的上司是 1。1 发现，6 距离我只有 2，比从 5 这里过来的 5（=4+1）近多了，那 6 就直接向我汇报吧。于是，5 和 6 分别汇报给 1。</p><p>同门相遇还可以是小弟相遇。这个时候就要比较谁和掌门的关系近。近的当大哥。刚才 5 和 6 同时向 1 汇报，后来 5 和 6 相遇比功夫的时候发现，5 你直接汇报给 1 距离是 4，如果 5 汇报给 6 再汇报给 1 ，距离只有 2+1=3，所以 5 干脆拜 6 为上司。<br><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181110174109306-1827776742.png" alt=""></p><h5 id="情形三：掌门与其他帮派小弟相遇"><a href="#情形三：掌门与其他帮派小弟相遇" class="headerlink" title="情形三：掌门与其他帮派小弟相遇"></a>情形三：掌门与其他帮派小弟相遇</h5><p>小弟拿本帮掌门和这个掌门比，赢了，这个掌门就拜入门下，输了，就拜入新掌门，并且会主键拉拢和自己连接的兄弟，一起“弃暗投明”。</p><p>例如，2 和 7 相遇，虽然 7 是小弟，2 是掌门，就个人武功而言，2 比 7 强，但是 7 的掌门是 1，比 2 牛，所以没办法，2 要拜入 7 的门派，并且连同自己的小弟都一起拜入。</p><h5 id="情形四：不同小弟相遇"><a href="#情形四：不同小弟相遇" class="headerlink" title="情形四：不同小弟相遇"></a>情形四：不同小弟相遇</h5><p>各自拿掌门比较，输了的拜入赢的门派，并且逐渐将与自己连接的兄弟拉入新门派。</p><p>例如，5 和 4 相遇。虽然 4 的武功好于 5，但是 5 的掌门是 1，比 4 牛，于是 4 拜入 5 的门派。后来当 3 和 4 相遇的时候，3 发现 4 已经“叛变”了，4 说我现在老大是 1，比你牛，要不你也来吧，于是 3 也拜入 1。</p><p>最红，生成一棵树，武林一统，天下太平。但是天下统一久了，也会有相应问题。常见的有<strong>广播和安全问题</strong>。</p><h3 id="广播和安全问题"><a href="#广播和安全问题" class="headerlink" title="广播和安全问题"></a>广播和安全问题</h3><p>机器多了，交换机也多了，就算交换机比 Hub 智能一些，但是还是难免有广播的问题。一大堆机器，相关的部门、不相关的部门，广播一大堆，性能就下来了。</p><p>就像一家公司，创业的时候，十来个人，坐在一个会议室，有事情大家讨论下，非常方便。当时如果变成了 50 个，全在一个会议室吵吵，就会乱的不得了。</p><p>另一方面，一个公司里，有的部门需要保密，比如人事部门，肯定要讨论升职加薪的事情。但是如果在一个广播域里，碰到一个会抓包的程序员，就能看的没有加密的敏感信息。</p><p>那咋办？能咋办，分部门，分会议室呗，让我们来看看怎么分。</p><p>有两种分的方法。一个是<strong>物理隔离</strong>。每个部门设一个单独的会议室，对应到网络方面，就是每个部门有单独的交换机，配置单独的子网。这样部门之间的沟通就需要路由器了。</p><p>这样的问题在于，有的部门人多，有的部门人少，而且部门的人数也会频繁发生变化，如果每个部门有单独的交换机，网口多了浪费，少了又不够用。</p><p>这时候，<strong>虚拟隔离</strong>就出来了。虚拟隔离，就是我们常说的 VLAN，或者叫做<strong>虚拟局域网</strong>。</p><p>使用 VLAN，一个交换机上会连属于多个局域网的机器，那交换机是怎么区分哪个机器属于哪个局域网呢？</p><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181110174205553-1740198427.png" alt=""></p><p>我们只需要在原来的二层头上加一个 TAG，里面有个 VLAN ID，共 12 位，可以划分 4096 个 VLAN。对于普通办公室，这个数量应该是够用的。</p><p>如果我们买的交换机支持 VLAN，当这个交换机把二层的头取下来的时候，就能够识别这个 VLAN ID。这样只有相同的 VLAN 的包，才会互相转发，不同 VLAN 的包，是看不到的。</p><p>这样，广播和安全问题就能够解决了。</p><p>这样，复杂的办公室网络布线就被我们用交换机与 VALN 搞定了。</p><p>参考：</p><ol><li><a href="https://baike.baidu.com/item/%E6%8B%93%E6%89%91%E7%BB%93%E6%9E%84/1488219?fr=aladdin" target="_blank" rel="noopener">百度百科-拓扑结构</a></li><li>刘超-趣谈网络协议系列课</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 交换机 </tag>
            
            <tag> VLAN </tag>
            
            <tag> 拓扑结构 </tag>
            
            <tag> 广播风暴 </tag>
            
            <tag> STP协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 3 - 从物理层到 MAC 层</title>
      <link href="/11/wangluoxieyi/ck0669dpi002hagaaouylsqcc/"/>
      <url>/11/wangluoxieyi/ck0669dpi002hagaaouylsqcc/</url>
      
        <content type="html"><![CDATA[<p>在上一篇博文中，我们见证了 IP 地址的诞生，机器一旦有了 IP，就可以在网络的环境里和其他的机器展开沟通了。</p><p>今天，我们来认识下 <strong>物理层</strong> 和 <strong>MAC</strong> 层。</p><p>日常生活中，身为 90 后的我们，如果不是通信相关专业出身的，应该从来没有接触过物理层和 MAC 层的设备。我们接触最多的，可能就是路由器了。而路由器实际上是第三层-网络层的设备了。</p><p>那咱们怎么认识物理层呢？就不扯那些深奥的理论了，从宿舍联机打魔兽说起吧。</p><p>要想宿舍里的几台电脑连接到一个局域网内，第一反应就是买个路由器，大家都连上去就 OK 了。但是在 15 年前，路由器还没有那么普及的时候，你在校园里找个通信专业的学生问，知道怎么组建宿舍局域网吗？他应该会回答你，有三种方式：</p><blockquote><ol><li>网线连接</li><li>集线器连接</li><li>交换机</li></ol></blockquote><h3 id="物理层"><a href="#物理层" class="headerlink" title="物理层"></a>物理层</h3><p>上面三种方式中，网线连接和集线器是完全在物理层工作，咱们就先见识下这两种方式。</p><h5 id="网线连接"><a href="#网线连接" class="headerlink" title="网线连接"></a>网线连接</h5><p>是的，你没看错，是用一根网线连接在两个电脑上。网线水晶头的第 1、2 和第 3、6脚，分别起着发、收信号的作用，要想通过一根网线将两台电脑连接在一个局域网上，需要额外做的操作就是将网线其中一端的 1 号和 3 号线、2 号和 6 号线互换一下位置，这样就能在物理层实现一端发送的信号，另一端成功接收。</p><p>当然，除了通过网线连接外，我们还需要配置这两台电脑的 IP 地址、子网掩码和默认网关，将这三项配置成为一个网络，否则是不通的。</p><p>这样，一个宿舍的两台电脑就可以联机打魔兽了。</p><p>问题来，如果又有一个舍友买了电脑，怎么把三台电脑连一起呢？先别说交换机这高档的东西，对于 15 年前的大学生来说，交换机太贵了，买不起。好在除了交换机外，还有个叫做 Hub 的东西，也就是<strong>集线器</strong>。</p><h5 id="集线器"><a href="#集线器" class="headerlink" title="集线器"></a>集线器</h5><p>这种设备有多个口，可以将宿舍里的多台电脑连接起来。和交换机不同的是，集线器很“傻”，它没有大脑，<strong>完全在物理层工作</strong>，将自己收到的每一个字节，都复制到其它端口上去。</p><p>这就像，小明想找小红表白，他不知道小红在哪个小区，于是他就找其它小伙伴，让每个小伙伴负责一个小区，去每一户问是不是小红家，找到小红的小伙伴就将表白语告诉小红。</p><h3 id="数据链路层"><a href="#数据链路层" class="headerlink" title="数据链路层"></a>数据链路层</h3><p>上面通过 Hub 实现局域网的方式，你可能已经发现了，Hub 采取的是<strong>广播</strong>的模式。如果每一台电脑发出的包，局域网内的其它电脑都能收到，那就麻烦了。这就需要解决几个问题：</p><ol><li>这个包是发给谁的？谁接收？</li><li>大家都在发生消息，会不会产生混乱？有没有先后的规则？</li><li>如果发生的时候出错了，怎么办？</li></ol><p>这几个问题，都是数据链路层，也就是 MAC 层要解决的问题。MAC 的全称是 <strong>Medium Access Control</strong>，即<strong>媒体介质访问控制</strong>。这里的控制，其实就是控制在往媒体上发数据时，谁先发、谁后发的问题，也就是<strong>防止发生混乱</strong>。这就解决了第二个问题。这个问题中的规则，学名叫<strong>多路访问</strong>。和我们交通管制一样，常见的有下面三种方式：</p><ul><li>方式一：分车道。每个车一个车道，你走你的，我走我的，互不干扰。这在计算机网络中叫做<strong>信道划分</strong>；</li><li>方式二：今天单号出现，明天双号出现，轮着来。这叫做<strong>轮流协议</strong>；</li><li>方式三：不管三七二十一，有事先出门，发现很堵，就回去等待 ，错过高峰期再走。这叫做<strong>随机接入协议</strong>。著名的以太网，用的就是这种方式。</li></ul><p>要解决第一个问题：发给谁？谁接收？这里用到一个物理地址，叫做<strong>链路层地址</strong>。但是因为第二层主要解决媒体接入控制的问题，所以它常常被称为 MAC 地址。</p><p>解决第一个问题就牵扯到第二层的<strong>网络包格式</strong>。对于以太网，第二层的最开始，就是目标 MAC 地址和源 MAC 地址。<br><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181107173709027-742897983.png" alt=""></p><p>接下来是<strong>类型</strong>。大部分的类型是 IP 数据包，其中 IP 里面包含 TCP、UDP，以及 HTTP 等，这些都是里层封装的事情。</p><p>有了这个目标 MAC 地址，数据包在链路上广播，MAC 的网卡才能发现，这个包是给它的。MAC 的网卡把包收进来，然后打开 IP 包，发现 IP 地址也是自己的，再打开 TCP 包，发现端口是 80，而 nginx 就是监听 80 端口。</p><p>于是就将请求提交给 nginx，nginx 返回一个网页，最后再经过层层封装，返回到 MAC 层。因为来的时候有源 MAC 地址，返回的时候，源 MAC 地址就变成了目标 MAC 地址，再返给请求的机器。</p><p>对于以太网，第二层的最后面是 CRC，也就是<strong>循环冗余检测</strong>。通过 XOR 异或的算法，来计算整个包是否在发送的过程中出现了错误，这主要解决了第三个问题。</p><p>这里还有一个没有解决的问题，当源机器知道目标机器的时候，可以将模板地址放入包里。如果不知道呢？一个广播的网络里面接入了 N 台地址，我怎么知道每个 MAC 地址是谁呢？这就是 ARP 协议，也就是已知 IP 地址，求 MAC 地址的协议<br><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181107173728130-421007362.png" alt=""></p><p>在一个局域网里，如果知道了 IP 地址，不知道 MAC 地址怎么办？这个在<a href="https://www.cnblogs.com/BeiGuo-FengGuang/p/9848805.html" target="_blank" rel="noopener">网络协议-概述</a>中有提过，本地通信靠“吼”。</p><p>发送一个广播包，广而告之，谁说这个 IP 谁来回答。具体询问和回答的报文就像下面这样：<br><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181107173754790-1077219675.png" alt=""></p><p>为了避免每次都用 ARP 协议，机器本地会进行 ARP 缓存。当然，缓存的 MAC 地址会有一个过期时间。</p><p>上面解决了广播发出的包，局域网内所有机器都能收到的问题。那么 Hub 是采用怎么样的方式？</p><p>实际上，Hub 不管某个接口是否需要，所有的数据都会发送出去，然后让主机来判断是否需要相关数据。这种方式会有两个问题：</p><ol><li>机器数目大幅增多后，产生冲突的概率就提高了。这很好理解，那么多小伙伴去找小红，发生交通事故的概率要大于，直接去她家表白发生交通事故的概率；</li><li>把大量不需要发送的包发送出去，浪费资源。</li></ol><p>明显可以看出，要解决上面两个问题，只要我们知道哪个接口对应哪个 MAC 地址就好了。如果目标 MAC 地址不是这台电脑的，这个口就不用转发了。</p><p>那么，谁能知道目标 MAC 地址是否就是连接某个口的电脑的 MAC 地址呢？这就需要一个能把 MAC 头拿下来，检查一下目标 MAC 地址，然后根据策略转发的设备，也就是我们之前提过的，<strong>二层设备-交换机</strong>。</p><p>交换机怎么知道每个口对应的电脑的 MAC 地址呢？这需要交换机<strong>能学习</strong>。这个也是交换机和 Hub 最明显的区别。</p><p>一台 MAC1 电脑将一个包发送给另一台 MAC2 电脑，当这个包到达交换机的时候，一开始交换机也不知道 MAC2 电脑再哪个口，所以没办法，它只能将包转发给除了来的那个口之外的其他所有的口。但是，这个时候，交换机会干一件很聪明的事情，就是交换机记住，MAC1 是来自一个明确的口，以后有包的目的地址是 MAC1 的，就直接发送到对应口就可以了。</p><p>当交换机作为一个关卡一样，过来一段时间后，就有了整个网络的一个结构了。这个时候，基本上不用广播，全部可以准确转发。而交换机学习的结果，我们成为<strong>转发表</strong>。当然，每台机器的 IP 地址会变，所在的口也会变，所以转发表也是有一个过期时间的。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>上面扯了一大堆，实际上也就是几句话的事：</p><ul><li>MAC 层是用来解决多路访问的堵车问题的</li><li>ARP 是通过“吼”的方式来寻找目标 MAC 地址，之后会记住一段时间，这个叫做 <strong>ARP 缓存</strong></li><li>交换机是升级版的 Hub，它有 MAC 地址学习能力，学完就能记住每个 MAC 地址对应哪个口，学习的成果叫<strong>转发表</strong></li></ul><p>参考：</p><ol><li>刘超-趣谈网络协议系列课；</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 物理层 </tag>
            
            <tag> MAC层 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python小应用-博客园隐藏的小秘密及各类排行榜【附源码】</title>
      <link href="/11/uncategorized/ck0669dms001pagaa9nqhkl1c/"/>
      <url>/11/uncategorized/ck0669dms001pagaa9nqhkl1c/</url>
      
        <content type="html"><![CDATA[<p>    接触博客园有不短的时间了，今天突然想到，我们博客园各位博友，一天中哪个时间段比较活跃？又有多少夜猫子在深更半夜，冒着“聪明绝顶”的风险熬夜码字看博文？首页所有博文中，哪个博友发布博文数量最多？又是哪个博友大范围“收割”阅读量和评论量？我们的各类排行榜中，谁能独占鳌头？</p><p>    今天，博主就现学现卖，用刚学完基础知识的 python 爬取下博客园相关数据，给大家分享下咱们博客园那些隐藏的“小秘密”。</p><h2 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h2><p>    想法出现了，怎么实现呢？</p><p>    第一反应就是想获取各位博友的<strong>登录信息</strong>和<strong>访问记录</strong>。这些数据应该是最准确的统计了。</p><p>    但是，不幸的是，博主把博客园翻了个“底朝天”，也没有找到哪些地方能获取到各位博友的登录信息和访问记录。</p><p>    想想也是，这些相当于各位博友的私密信息了，怎么会公开呢？咱就不痴心妄想了。</p><p>    爬不到登录信息和访问记录，还能用哪些数据呢？</p><p>    博主想了下，咱们在博客园逛游，一般都会先去<strong>首页</strong>看下有没有什么有趣的技术或者人生经验分享，碰到感兴趣的还可以和博主聊聊，缓解下紧绷的神经。</p><p>    那既然首页是多人访问的页面，我们统计首页博文的<strong>浏览量</strong>和<strong>评论量</strong>，应该也能在一定程度上反映出各位博友的活跃时间了。</p><p>于是，统计方案就定下来了：</p><blockquote><p>获取首页博文的浏览量和评论量，按时段进行统计。</p></blockquote><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>目标：</p><blockquote><p>获取首页博文的浏览量和评论量</p></blockquote><h3 id="爬取数据"><a href="#爬取数据" class="headerlink" title="爬取数据"></a>爬取数据</h3><p>    这还不简单，哪怕博主我是刚学完基础知识，也知道 python 在爬取 html 元素方面是专业的。</p><p>    一番折腾，终于按小时分段，获取到了第一页博文的浏览量和评论量：</p><pre><code>import requestsimport reimport jsonimport timeCRAWLING_URL = 'https://www.cnblogs.com/'def downloadPage():    """获取页面内容"""    print('获取页面内容用时')    url = CRAWLING_URL    res = requests.get(url).text    html = BeautifulSoup(res, 'lxml')    data = {}    postList = html.find_all(class_='post_item_foot')    for postInfo in postList:        content = postInfo.contents        # 发布时间字符串        timeStr = content[2][11:27]        localTime = time.localtime(time.mktime(            time.strptime(timeStr, '%Y-%m-%d %H:%M')))        # 以2018-11-01 15 格式时间 作为 key        timeIndex = time.strftime("%Y-%m-%d %H", localTime)        viewStr = content[4].contents[0].contents[0]        commontStr = content[3].contents[0].contents[0]        # 浏览量        view = int(re.findall("\d+", viewStr)[0])        # 评论量        commont = int(re.findall("\d+", commontStr)[0])        if timeIndex in data:            data[timeIndex]['view'] += view            data[timeIndex]['commont'] += commont            data[timeIndex]['postCount'] += 1        else:            data[timeIndex] = {                'view': view,                'commont': commont,                'postCount': 1            }    return data</code></pre><p>    第一页拿到了，离所有数据还远吗？</p><p>    事实证明，真的挺远的、、、</p><p>    当博主想拿第二页的数据时，很明显的可以看到第二页的地址是：</p><blockquote><p><a href="https://www.cnblogs.com/#p2" target="_blank" rel="noopener">https://www.cnblogs.com/#p2</a></p></blockquote><p>    于是博主这样做了</p><pre><code># ...CRAWLING_URL = 'https://www.cnblogs.com/#p'def crawlData(page, data):    url = CRAWLING_URL + str(page)    # ...def main():    pageNum = 11    data = {}    for page in range(1, pageNum):        data = crawlData(page, data)        page += 1    print(data)</code></pre><p>    看出来了吗？博主是直接将地址栏里的地址拼接上页码，想获取到对应页码的数据。</p><p>    事实证明，还是太嫩了。运行了好几次，发现统计数据明显不对，获取到的第二页的数据明显不是浏览器显示的。</p><p>    翻到第二页，看着页面元素，和第一页的一样啊，怎么爬到的数据就不对呢？</p><p>    作为一个后端开发，马上就意识到，在后面的页码页，肯定有额外的 ajax 请求，获取对应数据，展示到页面。</p><p>    翻到 network，果不其然。在非第一页的页面中，都会请求一个接口，获取指定页码的数据。原因找到了，赶紧修改请求地址和请求方式。</p><pre><code># ...CRAWLING_URL = 'https://www.cnblogs.com/mvc/AggSite/PostList.aspx'def crawlData(page, data):    """获取页面内容"""    url = CRAWLING_URL    headers = {        'Content-Type': 'application/json',    }    params = json.dumps({        'CategoryId': 808,        'CategoryType': "SiteHome",        'ItemListActionName': "PostList",        'PageIndex': page,        'ParentCategoryId': 0,        'TotalPostCount': 4000,    })    res = requests.post(url, data=params, headers=headers, verify=False).text    # ...</code></pre><p>    至此，首页博文的总浏览量、评论量以及发布数量已经按小时为区段进行汇总了。</p><h3 id="存储数据"><a href="#存储数据" class="headerlink" title="存储数据"></a>存储数据</h3><p>    数据拿到了，下一步就是<strong>数据存储</strong>了。这里，我们选用最简单的 excel 表格存储，也就是将统计的数据导出到 excel 表格中，以供后续分析统计。</p><pre><code>def main():    pageNum = 11    data = {}    # 获取所有数据    for page in range(1, pageNum):        data = crawlData(page, data)        print('已完成: %s/%s' % (page, pageNum - 1))        page += 1    # excel 表格存储    col = 2    ws1['A1'] = '日期'    ws1['B1'] = '查看人数'    ws1['C1'] = '评论人数'    ws1['D1'] = '发布数量'    for postCount in data:        col_A = 'A%s' % col        col_B = 'B%s' % col        col_C = 'C%s' % col        col_D = 'D%s' % col        col_E = 'E%s' % col        col_F = 'F%s' % col        ws1[col_A] = postCount        ws1[col_B] = data[postCount]['view']        ws1[col_C] = data[postCount]['commont']        ws1[col_D] = data[postCount]['postCount']        col += 1    wb.save(filename=dest_filename)    print('-------------SUCCESS--------------')</code></pre><p>    这样，我们就将数据存储到 excel 表格中了。</p><h3 id="分析数据"><a href="#分析数据" class="headerlink" title="分析数据"></a>分析数据</h3><p>    下一步就是<strong>数据分析</strong>。由于个人能力所限，这里先用 excel 表格进行相关的统计。</p><p>    由于博客园只提供 200 页的数据量，最后的数据到 8 月 20 日左右，所以 9 月份和 10 月份的数据是比较完整的。但是考虑到 10 月份有十一假期的原因，以及当前时间距离十月份较近，所以最终取 9 月份的数据进行相关统计。</p><h3 id="周数据"><a href="#周数据" class="headerlink" title="周数据"></a>周数据</h3><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181105202932153-554315312.png" alt=""><br><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181105195924959-270703456.png" alt=""><br><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181105203015430-170161232.png" alt=""><br><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181105204710408-948108177.png" alt=""></p><p>上图是 8.25-9.30 连续 5 周的数据统计，0 表示 周日。由图可以比较明显的看出一些趋势：</p><ol><li>每周的前四天是博文发布数量较高的，后三天发布数量明显减少；</li><li>查看人数和评论人数的趋势较为相符，两者的比例在 208:1 左右，也就是说平均 208 个阅读里面才会 1 个评论。</li></ol><p>    这里博主比较不解的是，为什么会在每周一有一个阅读高峰期？难道刚休息完，周一的时候会更有动力看博文补补课？</p><h3 id="天统计"><a href="#天统计" class="headerlink" title="天统计"></a>天统计</h3><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181106095303506-1548483768.png" alt=""><br><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181106103058279-754799432.png" alt=""><br><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181106103447220-1973438845.png" alt=""></p><p>上图是 9.3 - 9.6 按小时分段统计数据。可以看出：</p><ol><li>博文发布一般集中在上午 8-10 点，下午的 16-18 点以及晚上的 20-22 点</li></ol><p>    看来各位博友晚上即使不加班的也会努力码字啊，抓住下班后的两小时，很棒的习惯诶，博主也要更加努力向各位博友看齐了。</p><p>    最后，就是我们的重磅戏，各类排行榜。这里需要将<strong>时间分组</strong>修改为<strong>发布作者名称分组</strong>。</p><h3 id="各类排行榜"><a href="#各类排行榜" class="headerlink" title="各类排行榜"></a>各类排行榜</h3><p><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181107095033239-1653798529.png" alt=""><br><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181107095132954-2100084796.png" alt=""><br><img src="https://img2018.cnblogs.com/blog/861679/201811/861679-20181107095212606-710141713.png" alt=""></p><p>    以上排行榜数据时间段： 2018-08-21 09:24 至 2018-11-07 09:27 。</p><p>    好了，园子的小秘密就分享到这里。有兴趣的博友可以发掘下其他的小秘密。注意不要恶意攻击噢！</p><p>    源码地址：<a href="https://github.com/zibinli/python" target="_blank" rel="noopener">https://github.com/zibinli/python</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>工作两年</title>
      <link href="/11/gerenzongjie/ck0669dew000hagaatpjoqsv8/"/>
      <url>/11/gerenzongjie/ck0669dew000hagaatpjoqsv8/</url>
      
        <content type="html"><![CDATA[<p>毕业一年，工作将近两年。刚工作的时候会记录每一点的成长，随着时间的推移，写的越来越少。在这即将到来两年的时间点上，蓦然发现，已经好久没有进行个人总结了。</p><p>很多人都说，踏入工作 1-3 年是人生中一个重要的阶段。博主正处于这个阶段，不知道这个说法是对是错，但也知道，潜心学习，脚踏实地肯定不会错。</p><p>恰处于这个时间段的中间，借此博文，总结与反思这两年的成长与教训，如果能得到各位前辈的指点，那就更为值得了。</p><h3 id="第一份工作"><a href="#第一份工作" class="headerlink" title="第一份工作"></a>第一份工作</h3><h4 id="工作前"><a href="#工作前" class="headerlink" title="工作前"></a>工作前</h4><p>人生中会有很多难忘的第一次，我相信对于绝大多数人而言，第一次面试与第一份工作应该是其中之一。</p><p>博主就读于广州一所普通本科，和大多数大学生一样，前两年在班务与学生会间折腾，到大三时，突然发现自己马上就要毕业了，然后就开始焦虑，想着毕业到底要干些什么。</p><p>大学生毕业，一般就面临三个选择：就业、考研、考公务员。确定就业后，就要确定要就什么业。俗话说的好，”女怕嫁错郎，男怕入错行”，本着就业需谨慎的原则，兴致勃勃的咨询了好多师兄师姐，结果发现并没有很多选择。要么销售，要么IT。</p><p>那得了，就 IT 吧。虽然大学才开始接触编程，但所幸还学了一些计算机知识和编程原理，也不算零基础。就这样，在大三正式走上 IT 就业路，成为了一个”准程序员”。</p><p>大三跟着老师折腾了一年，大四开始准备简历，应战秋招。折腾了几个月，2016 年 12 月 1 号正式入职了 A 公司，也算开始了职业生涯。</p><h4 id="工作中"><a href="#工作中" class="headerlink" title="工作中"></a>工作中</h4><p>公司主要做 H5 营销游戏平台。创业型公司，老板人挺好，团队也很赞。</p><p>现在回头看来，在这家公司，时间上大致可以分为两个阶段，每个阶段对博主都有不同的影响，最主要的是，每个阶段，都有一个可以称为“导师”的人带着，也让博主从一个开发新人一步步迈向成熟。</p><p><strong>入职阶段</strong>。这个阶段对于很多人来说，应该都是比较难熬的阶段。对于刚踏入社会的博主来讲更是如此。</p><p>网上看过很多批评大学生的文章，都说大学生毕业眼高手低，心气高，能力低。但幸运的是，博主接触的这些同学、校友中，基本上没有这种情况，身边认识的基本上都持有一种观点：</p><blockquote><p>第一份工作，应该是一个跳板，而不是坑</p></blockquote><p>本着抓住当前跳板的想法，哪怕没玩过 git，没用过 yii，也没搞过微信开发，入职前两个月，靠着每天加班，拼命的去学习自己不熟悉的一切，两个月后对公司整个业务代码也算有个大概的认识，至少来个新功能不会心慌慌了。</p><p>言归正传，这个阶段带博主的是后端组组长，文哥，人牛话不多，运维、开发，乃至网络排线，接近全能，当然，全公司数他最忙。博主就是在他的指导下，靠着修复一个个 bug，才能快速熟悉整体业务代码。</p><p>简而言之，这个阶段学到了下面两点：</p><ol><li>技术上，会了 git，识了 yii，熟了 apache 与 mysql；</li><li>团队协作上，了解了互联网公司的工作流程，最重要的是，提高了与 产 品 对 撕 的 能 力！</li></ol><p><strong>重构阶段</strong>。说起重构，很多人对它，应该是“爱恨交织”。这也是公司发展过程中，技术部门必须正视的一件大事。</p><p>这个阶段博主基本上是跟着项目经理俊哥混。他是澳洲留学回来的，在技术方面和文哥是完全不同的风格。会更积极的去接触与尝试新技术，利用一些理论知识对整体方案进行评估。</p><p>重构开始后，博主负责的那一块业务代码要全部用 Node 重写，更悲催的是，那时对 Node 的认知也仅限于，它和 JS 的语法一样。就这样，开始了重构之路。</p><p>历时将近两个月，终于改写完成。不幸的是，又不小心引入了分布式数据一致性问题，出现 redis 数据与 mysql 数据不一致的问题，导致红包多发。</p><p>那段时间是压力最大，最难熬的一段时间。中间几度想申请离职，但想一想我们的“跳板原则”，就咬牙坚持了下来。</p><p>最后结果也算差强人意吧，虽然没有达到预定目标，但相比之前，业务架构更清晰，性能也提升了 5 倍左右。</p><p>这个阶段给我的最大感触就是，重构真的是要人命的一件事。</p><h4 id="离职"><a href="#离职" class="headerlink" title="离职"></a>离职</h4><p>一个人离职的原因有很多，但对于技术而言，团队氛围应该是一个相对比较重要的因素了。上面说过，公司团队氛围很好，这也是让我一再坚持的理由。</p><p>但一家公司不单单只有技术团队，老板的影响，其他团队的因素，都会导致公司走上不同的道路。博主公司就是存在发展大方向经常变动的问题，导致走了很多弯路，最后投资人看不到发展前景，迫使公司改变了大的发展方向，团队成员相继离职，这也是博主最终离开公司的原因。</p><p>当前，上述都是客观因素，就博主本人而言，一方面想换一个环境，让自己有更快的成长。另一方面，也想薪酬能跟着上涨。网上不是经常有人说：</p><blockquote><p>薪资涨幅低于 30% 的跳槽，都是失败的跳槽</p></blockquote><p>所以，也可以说成：</p><blockquote><p>当你想跳槽的时候，你的下一份薪资能有 30% 的涨幅吗？</p></blockquote><p>如果有底气，那就大胆的跳吧！</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>现在看来，在这家公司，最幸运的就是能有人带着正式进入 web 开发世界。跟着文哥学到了在 coding 世界，每个字母，每个标点都应该慎之又慎。跟着俊哥学到了，除了眼前的苟且（业务代码），我们还要努力接触远方的诗（新技术），保持对技术的热情。</p><p>下面是博主从第一家公司离职时所接触到的技术，作为创业型公司，这应该是一些很常见的技术，后续会为一些技术点写出单独的博文，以作个人总结，也希望能给刚入职的小伙伴一点点帮助。</p><h5 id="服务器"><a href="#服务器" class="headerlink" title="服务器"></a>服务器</h5><ol><li>Apache</li><li>Nginx</li></ol><h5 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h5><ol><li>Sql<ol><li>Mysql</li><li>Oracle</li></ol></li><li>NoSql<ol><li>Redis</li><li>Mongodb</li><li>Memcache</li><li>Influxdb</li></ol></li></ol><h5 id="编程语言"><a href="#编程语言" class="headerlink" title="编程语言"></a>编程语言</h5><ol><li>PHP</li><li>Node</li><li>Python</li><li>Java</li><li>C</li></ol><h5 id="相关应用"><a href="#相关应用" class="headerlink" title="相关应用"></a>相关应用</h5><ol><li>微信开发</li></ol><h2 id="第二份工作"><a href="#第二份工作" class="headerlink" title="第二份工作"></a>第二份工作</h2><p>目前在一家直播公司就职。刚入职几个月，定个未来的规划。</p><p>短期目标：</p><blockquote><ol><li>进一步了解公司业务架构</li><li>增强 nginx 服务器的了解</li><li>增强操作系统、redis 集群等基础知识的认知</li></ol></blockquote><p>中长期目标：</p><blockquote><ol><li>配合 CTO 完成业务拆分，增强对架构的认知</li></ol></blockquote><p>具体措施：</p><blockquote><ol><li>阅读相关书籍</li><li>学习相关网络课程</li><li>每月至少两篇博文</li></ol></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 个人总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 两年 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 2 - IP 是怎么来，又是怎么没的？</title>
      <link href="/10/wangluoxieyi/ck0669dx20074agaayjeye7in/"/>
      <url>/10/wangluoxieyi/ck0669dx20074agaayjeye7in/</url>
      
        <content type="html"><![CDATA[<p>了解完网络协议，我们会发现，网络通信的五层模型里，有两个很重要的概念：IP 地址和 MAC 地址。</p><p>那么 IP 地址是怎么来的，又是怎么没的？MAC 地址与 IP 地址又有什么区别？</p><p>这回答上面问题前，先热下身，大家知道如何查看本机的 IP 吗？这个问题，即便是没有专业学过计算机的人，只要折腾过电脑，重装过系统，大多都会知道答案：在 Windows 下是 ipconfig，在 linux 下是 ifconfig。</p><p>在 Windows 下输入 ipconfig，我们会看到这个界面：<br><img src="https://img2018.cnblogs.com/blog/861679/201810/861679-20181030165734160-2053570721.png" alt=""></p><p>在 linux 下输入 ifconfig，我们会看到这个界面：<br><img src="https://img2018.cnblogs.com/blog/861679/201810/861679-20181030165755322-934432138.png" alt=""></p><h2 id="IP-地址"><a href="#IP-地址" class="headerlink" title="IP 地址"></a>IP 地址</h2><p>可以看到，无论是在 Windows 还是在 linux 下，输入相关命令都能显示出这台机器上所有的网卡。大部分的网卡都会有一个 IP 地址。就像 192.168.1.73 ，就是我本机以太网的 IP 地址。</p><blockquote><p>IP 地址是<strong>一个网卡</strong>在网络世界中的通讯地址，相当于我们现实世界的门牌号码。</p></blockquote><p>注意，IP 地址是网卡的通讯地址，不是一台机器的通讯地址。很多时候，我们会说一个电脑只有一个 IP 地址，这种说法实质上并不正确，准确的来说，应该是：</p><blockquote><p>一个网卡在同一时段只能有一个 IP 地址，一台机器可以有多个 IP 地址。</p></blockquote><p>就像我们的笔记本，一般都会有线网卡和无线网卡，则有线网卡有一个 IP 地址，无线网卡也有一个 IP 地址。</p><p>一台机器有多个 IP 地址，那 IP 地址会不会重复呢？其实我们应该会碰到 IP 地址重复的情况。有时候我们电脑弹出网络地址冲突，出现无法上网的情况，那多半就是 IP 地址冲突了。</p><h3 id="格式"><a href="#格式" class="headerlink" title="格式"></a>格式</h3><p>就像上面输出的结果，192.168.1.73 就是一个 IP 地址。这个地址被点（.）分割为四个部分，每个部分有 8 个 bit，所以 IP 地址总共是 32 位。显然，32 位产生的 IP 地址在当今这个互联网社会，很明显就是”狼多肉少”。于是就有了 IPv6，也就是上面结果中的 fe80::515d:5483:ff4d:6db9/64。这个有 128 位，能满足我们现在的需求了。至于后面会不会出现 IPv8 ，那就看后面互联网世界的发展了。</p><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><p>我们应该都听说过，IP 地址分为 A、B、C、D、E 五类。对于 A、B、C 类，主要分两部分，前面一部分是网络号，后面一部分是主机号。<br><img src="https://img2018.cnblogs.com/blog/861679/201810/861679-20181030165845943-1138936572.png" alt=""></p><p>下图是 A、B、C 三类地址所能包含的主机数量。<br><img src="https://img2018.cnblogs.com/blog/861679/201810/861679-20181030165857569-1223148974.png" alt=""></p><p>这里面有个问题，C 类地址包含的主机数量太少，而 B 类地址包含的主机数量又太多，于是就有了一个折中的方式叫做<strong>无类型域间选路</strong>。</p><h3 id="无类型域间选路"><a href="#无类型域间选路" class="headerlink" title="无类型域间选路"></a>无类型域间选路</h3><p>顾名思义，无类型域间选路（CIDR）基本思想是<strong>取消地址的分类结构，取而代之的是允许以可变长分界的方式分配网络数</strong>。192.168.1.73/24 就是无类型域间选路格式的 IP 地址。这种格式的 IP 地址，将 32 位的 IP 地址一分为二，前面是网络号，后面是主机号。从哪里分呢？如果注意观察的话可以看到，上面地址中有一个斜杠，斜杠后一个数字 24。这个 24 的含义就是，前24 位是网络号，后 8 位是主机号。</p><h3 id="公有-IP-地址和私有-IP-地址"><a href="#公有-IP-地址和私有-IP-地址" class="headerlink" title="公有 IP 地址和私有 IP 地址"></a>公有 IP 地址和私有 IP 地址</h3><p><img src="https://img2018.cnblogs.com/blog/861679/201810/861679-20181030165910003-2041184349.png" alt=""></p><p>继续看上面的表格。表格最右列是私有 IP 地址段。平时我们在一个局域网内，看到的 IP 地址都是私有 IP 地址。因为这些地址允许组织内部的 IT 人员自己管理和分配，而且还可以重复。所以会出现你局域网的私有 IP 地址段和我局域网的是一样的。</p><p>就像我们上面说的，小明在自己家里给<strong>同单元</strong>的小伙伴说自己是五单元 101 号，小伙伴能理解，但是他如果这样和小红说，小红就会问，你是哪个小区的？这里的小区实际上就是公有 IP 地址，而五单元 101 号就是私有 IP 地址。</p><p>表格中的 192.168.0.x 是最常见的私有 IP 地址段。就像我们家里的路由器地址一般是 192.168.0.1 一样。</p><h3 id="IP-分配与释放"><a href="#IP-分配与释放" class="headerlink" title="IP 分配与释放"></a>IP 分配与释放</h3><p>IP 分配我们平时应该接触比较少。还记得在大学的时候，刚入学第一件事就是赶紧交网费。交网费时会有一个步骤，网管会让你提供 MAC 地址，然后把 IP 地址和 MAC 地址绑定，这也就是博主在隔壁宿舍无法通过网线上网的原因。</p><p>其实，如果你有相关的知识积累，可以用命令行自己配置 IP 地址。当然，能不能通信就看你的知识储备量了。</p><p>除了命令行配置外，我们平时应该对于 IP 分配应该都是用的 “拿来主义”。无论是在学校还是在办公室，都会有网络管理员把分配好的 IP 给你，直接使用就可以了。但是有时候也会好奇，网管是怎么分配 IP 的呢？难不成通过命令行一个个配置？这时候就要用到<strong>动态主机配置协议（DHCP）</strong>。</p><h4 id="动态主机配置协议"><a href="#动态主机配置协议" class="headerlink" title="动态主机配置协议"></a>动态主机配置协议</h4><p>这个协议的工作原理是怎样的呢？我们就拿一台机器新加入一个网络为例，来走一遍 DHCP 的工作流程。</p><p>当一台机器新加入一个网络时，肯定一脸懵逼，啥情况也不知道，只知道自己的 MAC 地址。没人理你怎么办？那不管三七二十一，先吼一声，告诉所有人，我来了，有人吗？这时候的沟通基本靠”吼”。这一步，我们称为 DHCP Discover。</p><p>新来的机器使用 IP 地址 0.0.0.0 发送了一个广播包，目的 IP 地址是 255.255.255.255。广播包封装在 UDP 里面，UDP 封装在 BOOTP 里面。在这个广播包里，新人大喊：我是新来的（Boot Request），我的 MAC 地址是 xxx，我还没有 IP，谁能给我个 IP 地址？格式就像下面这样：<br><img src="https://img2018.cnblogs.com/blog/861679/201810/861679-20181030170020219-2141282496.png" alt=""></p><p>这时候，网络里的 DHCP Server 就相当于这个局域网的管理员。他知道来了一个”新人”，需要给它分配一个 IP 地址，这个过程就是 DHCP Offer。同时，DHCP Server 保留为此机器提供的 IP 地址，从而不会再将相同的 IP 地址分配给其它的机器。而 DHCP Offer 的格式就像下图，里面有给新人分配的地址。<br><img src="https://img2018.cnblogs.com/blog/861679/201810/861679-20181030170042933-2023439288.png" alt=""></p><p>DHCP Server 仍然使用广播地址作为目的地址，因为，此时请求分配的新人还没有自己的 IP 地址。如果一个局域网中有多个 DHCP Server，这台新机器会收到多个 DHCP Offer。</p><p>它会选择其中一个 DHCP Offer，一般是最先到达的那个，并且会向网络发送一个 DHCP Request 广播数据表，包中包含客户端的 MAC 地址、接受分配的 IP 地址、提供此 IP 的 DHCP 服务器地址等，并告诉所有的 DHCP Server 它将接受哪一台服务器提供的 IP 地址，告诉其他 DHCP 服务器撤销它们提供的 IP 地址，以便提供给下一个 IP 请求分配者。新人广播包格式如下：<br><img src="https://img2018.cnblogs.com/blog/861679/201810/861679-20181030170128080-1631829146.png" alt=""></p><p>此时，由于还没有得到 DHCP Server 的最后确认，新机器仍然使用 0.0.0.0 为源 IP 地址、255.255.255.255 为目标地址进行广播。</p><p>当 DHCP Server 接收到新机器的 DHCP Request 之后，会广播返回给新机器一个 DHCP ACK 消息包，表明已经接受新机器的选择，并将这一 IP 地址分配信息和其他配置信息都放入该广播包，发给新机器。DHCP ACK 格式如下：<br><img src="https://img2018.cnblogs.com/blog/861679/201810/861679-20181030170151917-2050620167.png" alt=""></p><p>新机器收到 DHCP ACK 后，会检测分配的 IP 地址是否能够适应，如果不能使用，它就会给 DHCP Server 发出 DHCP Decline 消息，通知 DHCP Server 禁用这个 IP 地址，然后新机器就开始新的地址申请过程。</p><p>在新机器使用 IP 租期超过 50% 时，DHCP Client 会以单播形式向 DHCP Server 发送 DHCP Request 报文来续租 IP 地址。如果 DHCP Client 成功收到 DHCP Server 发送的 DHCP ACK 报文，则按相应时间延长 IP 地址租期；如果没有收到 DHCP Server 发送的 DHCP ACK 报文，则 DHCP Client 继续使用这个 IP 地址。</p><p>在新机器使用 IP 租期超过 87.5% 时，DHCP Client 会以广播形式向 DHCP Server 发送 DHCPRequest 报文来续租 IP 地址。如果 DHCP Client 成功收到 DHCP Server 发送的 DHCP ACK 报文，则按相应时间延长 IP 地址租期；如果没有收到 DHCP Server 发送的 DHCP ACK 报文，则 DHCP Client 继续使用这个IP地址，直到 IP 地址使用租期到期时，DHCP Client 才会向 DHCP Server 发送 DHCP Release 报文来释放这个 IP 地址，并开始新的 IP 地址申请过程。</p><h2 id="MAC-地址"><a href="#MAC-地址" class="headerlink" title="MAC 地址"></a>MAC 地址</h2><p>在我们查询 IP 地址的输出结果中，有一行：</p><blockquote><p>Link encap:Ethernet  HWaddr 28:d2:44:ce:77:51</p></blockquote><p>这个被称为 MAC 地址，是一个网卡的物理地址，用十六进制，6 个 byte 表示。</p><p>MAC 地址是一个很容易让人误解的地址。因为 MAC 地址号称全球唯一，不会存在有相同 MAC 地址的网卡。这就很容易让我们想，既然全球唯一，那网络通信直接用 MAC 地址不行吗？为什么要加个 IP 地址，多封装一层，再去通信呢？</p><p>当然是不行的。我们想把一个网络包从一个地方传到另一个地方，除了有确定的地址外，还需要有<strong>定位功能</strong>。就像你去广州找博主一样，我只告诉你我的身份证号，你能在广州找到我吗？这种寻找无异于大海捞针。但是如果我告诉你我的详细地址，你就可以直接通过导航找到对应的地址，然后再找到我。</p><p>IP 地址在一定程度上就承担了详细地址这种远程地位的功能。MAC 地址更像是身份证号，是一个唯一的标识。它的唯一性设计是为了组网的时候，不同的网卡放在一个网络里面，不用担心冲突。</p><p>当然，MAC 地址也有一定的定位功能。就像你来到了博主所在的办公室，你可以在办公室喊身份证号是 XXX 的是哪位？博主听到了，就会站起来回答你。但是如果你在博主听不到的地方喊，那肯定不会有人应你。这就说明，MAC 地址的通信范围比较小，仅仅局限在一个子网内。</p><p>参考：</p><ol><li>刘超-趣谈网络协议系列课；</li><li>百度百科-DHCP 词条；</li><li>百度百科-CIDR 词条；</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IP格式 </tag>
            
            <tag> IP分配和释放 </tag>
            
            <tag> DHCP-动态分配协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议 1 - 概述</title>
      <link href="/10/wangluoxieyi/ck0669dn3001sagaazd3kbxfg/"/>
      <url>/10/wangluoxieyi/ck0669dn3001sagaazd3kbxfg/</url>
      
        <content type="html"><![CDATA[<p>互联网世界中，网络协议的重要性不言而喻。很多人都知道，网络协议中的五层模型或者七层模型，这些在操作系统中，那都是“必考题”。上学的时候，无论是死记硬背，还是各种小抄，总得把下面这个图记下来。踏入工作，走进 web 开发“不归路”，发现还是不能落下它。<br><img src="https://img2018.cnblogs.com/blog/861679/201810/861679-20181029134506598-1350627036.png" alt=""></p><h2 id="协议三要素"><a href="#协议三要素" class="headerlink" title="协议三要素"></a>协议三要素</h2><ul><li><strong><em>语法</em></strong>，就是一段内容要符合一定的规则和格式。例如，括号要成对，结束要使用分号等。</li><li><strong><em>语义</em></strong>，就是这段内容要代表某种意义。例如，数字相减是有意义的，而数字减去文本一般来说就没有意义。</li><li><strong><em>顺序</em></strong>，就是规定先干什么，后干什么。就像我们常做的，先加某个数值，再减去某个数值等。</li></ul><p>HTTP 协议：</p><pre><code>HTTP/1.1 200 OKDate: Thu, 25 Oct 2018 01:56:12 GMTContent-Type: Content-Language:&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;base href="http://zibinli.github.io/" /&gt;&lt;meta charset="utf-8"/&gt; &lt;title&gt;ReliableCoder &lt;/title&gt;</code></pre><p>我们来看看上面的 HTTP 协议是否符合协议的三要素。</p><p>首先，符合语法，也就是说，只有按照上面那个格式来，浏览器才能解析。例如，上面是状态，然后是首部，最后是内容。</p><p>其次，符合语义，就是要按照约定的意思来。例如，状态 200，表示网页成功返回。如果不成功，就是常见的 404。</p><p>最后，符合顺序，点击浏览器，就是发送一个 HTTP 请求，然后才有上面那串返回的东西。</p><p>浏览器显然按照协议商定好的做了，才能将网页呈现在你面前。</p><h2 id="常用的网络协议"><a href="#常用的网络协议" class="headerlink" title="常用的网络协议"></a>常用的网络协议</h2><p>我们面试的时候经常会被问到这样一个问题：</p><blockquote><p>在浏览器输入一个地址，然后点击回车，此时到页面加载出来，这个过程发生了什么？</p></blockquote><p>我们就用打开博客的过程，看看互联网世界运行过程中，都使用了哪些网络协议。</p><p>当在浏览器里输入 “<a href="http://zibinli.github.io”，这是一个" target="_blank" rel="noopener">http://zibinli.github.io”，这是一个</a> URL，而浏览器知道它的名字是 zibinli.github.io，但是不知道具体的地点，所以浏览器不知道如何访问。</p><p>于是，它<em>打开地址簿去查找</em>。在这个过程中，我们一般使用<strong><em>地址簿协议-DNS</em></strong>，还可以使用另一种更加精准的地址簿查找协议-<strong><em>HTTPDNS</em></strong>。</p><p>无论使用哪一种方法查找，最终都可以得到这个地址：47.106.81.116。这个是 IP 地址，可以把它当做是互联网世界的“门牌号”。</p><p>知道了目标地址，浏览器就开始打包它的请求。对于普通的 HTTP 请求，一般会使用 HTTP 协议，但是如果对于购物的请求，往往会进行加密传输，因而会使用 HTTPS 协议。无论是什么协议，里面都会写明“我要看哪篇博文”。<br><img src="https://img2018.cnblogs.com/blog/861679/201810/861679-20181029121815054-331558801.png" alt=""></p><p>DNS、HTTP、HTTPS 所在的层我们成为<strong><em>应用层</em></strong>。经过应用层封装后，浏览器会将应用层的包交给下一层去完成，通过 socket 编程来实现。下一层是<strong><em>传输层</em></strong>。传输层有两种协议，一种是无连接的协议 UDP，一种是面向连接的协议 TCP。而所谓的面向连接就是，TCP 会保证这个包能够到达目的地，如果不能到达，就会重新发送，直至到达。</p><p>TCP 协议里面会有两个端口。一个是浏览器监听的端口，一个是博客服务器监听的端口。操作系统往往通过端口来判断，它得到的包应该给哪个 进程。<br><img src="https://img2018.cnblogs.com/blog/861679/201810/861679-20181029122625469-102645898.png" alt=""></p><p>传输层封装完毕后，浏览器会将包交给操作系统的<strong><em>网络层</em></strong>。网络层的协议是 <strong><em>IP 协议</em></strong>。在 IP 协议里面会有源 IP 地址和目标 IP 地址，也就是浏览器所在机器的 IP 地址和博客网站所在服务器的 IP 地址。<br><img src="https://img2018.cnblogs.com/blog/861679/201810/861679-20181029123146853-793062332.png" alt=""></p><p>操作系统既然知道了目标 IP 地址，下一步就是根据这个 IP 找到目标机器。它首先会判断，这个目标 IP 是本地人还是外地人。从 IP 很明显就能看出来，博客服务器不在本地。</p><p>操作系统知道了，要到目标机器，就要要离开本地去远方。那如何去远方呢？这个时候就可以拿出国旅游作类比。我们要去国外，就要经过海关。同样的，操作系统要去远方，也要经过<strong><em>网关</em></strong>。而操作系统启动的时候，就会被 DHCP 协议配置 IP 地址，以及默认的网关 IP 地址：192.168.1.1。</p><p>操作系统如何将 IP 地址发给网关呢？在本地通信基本靠吼，于是操作系统大吼一声，谁是 192.168.1.1 ？网关会回答它，我就是，我的本地地址在村东头。这个本地地址就是 MAC 地址，而大吼的那一声就是 <strong><em>ARP 协议</em></strong>。<br><img src="https://img2018.cnblogs.com/blog/861679/201810/861679-20181029130853658-1030309840.png" alt=""></p><p>操作系统拿到了 MAC 地址，就将 IP 包交给了下一层：MAC 层。网卡再将这个包含 MAC 地址的包发出去。由于这个包里面有网关的 MAC 地址，因而它能够到达网关。</p><p>网关收到包之后，会根据自己的知识，判断下一步应该怎么走。网关往往是一个路由器，到某个 IP 地址应该怎么走，这个叫做<strong><em>路由表</em></strong>。</p><p>路由器有点像玄奘西行路过的一个个国家的城关。每个城关连接着两个国家，每个国家相当于一个局域网，在每个国家内部，都可以使用本地的地址 MAC 进行通信。</p><p>一旦跨越城关，就需要拿出 IP 头来，里面写着贫僧来自东土大唐（源 IP 地址），想去西天（目标 IP 地址）拜佛求经。路过此地，借宿一晚，明日启行。请问接下来该怎么走？<br><img src="https://img2018.cnblogs.com/blog/861679/201810/861679-20181029132107119-451277843.png" alt=""></p><p>城关往往是知道这些“知识”的，因为城关和临近的城关也会经常沟通。到哪里应该怎么走，这种沟通的协议称为<strong><em>路由协议</em></strong>，常用的有 OSPF 和 BGP。</p><p>城关与城关之间是一个国家，当网络包知道了下一步去哪个城关，还是要使用国家内部的 MAC 地址，通过下一个城关的 MAC 地址，找到下一个城关，然后再问下一步的路怎么走，一直到走出最后一个城关。</p><p>最后一个城关知道这个网络包要去的地方，于是，就对着这个国家吼一声（ARP协议），谁是目标 IP ？目标服务器就会回复一个 MAC 地址。网络包过关后，通过这个 MAC 地址就能找到目标服务器。</p><p>目标服务器发现 MAC 地址对上了，取下 MAC 头来，然后发送给操作系统的网络层。网络层发现 IP 也对上了，就取下 IP 头。 IP 头里会写上一层封装的是 TCP 协议，然后将其交给传输层，即 TCP 层。</p><p>在这一层里，对于收到的每个包，都会有一个回复的包说明收到了。这个回复的包不是这次请求的结果，而仅仅是 TCP 层的一个收到回复。这个回复会沿着刚才来的方向走回去，报个平安。</p><p>如果过一段时间，发送端的 TCP 层没有收到平安回复，就会重新发送这个包，重复上面的过程，直到收到平安到达的回复为止。这个重试不是浏览器重新进行请求，对于浏览器而言，只发送一次请求，而 TCP 层在没有收到平安回复时，不断闷头重试。除非 TCP 层出了问题，比如连接断了，才需要浏览器的应用层重新发送请求。</p><p>当网络包平安到达 TCP 层后，TCP 头中有目标端口号，通过这个端口号，可以找到博客网站的进程正在监听这个端口号，假设是 Nginx，于是就将这个包发给 Nginx，进行相关业务处理。处理完成后，将相关数据打包，然后回复给浏览器，显示出博文页。</p><p>下图就是整个HTTP 请求中可能用到的协议。后续会通过从底层到上层的顺序来一一分享。<br><img src="https://img2018.cnblogs.com/blog/861679/201810/861679-20181029201638833-487867638.png" alt=""></p><p>参考：</p><ol><li>刘超-趣谈网络协议系列课；</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 协议概述 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nginx 伪静态</title>
      <link href="/10/uncategorized/ck0669dc80006agaapabzff85/"/>
      <url>/10/uncategorized/ck0669dc80006agaapabzff85/</url>
      
        <content type="html"><![CDATA[<p>最近有个在官网加【行业资讯】的需求。考虑到主要目的是为了推广，决定对资讯的栏目和内容页进行伪静态处理。</p><p>下面以文章 id 为 5 的文章页为例。原始地址为：</p><blockquote><p>oriUrl = <a href="http://blog.muzixizao.com/?p=5" target="_blank" rel="noopener">http://blog.muzixizao.com/?p=5</a></p></blockquote><p>其实所谓的伪静态，就是<strong>去除地址里的动态参数</strong>，比如 ?、= 等，以便更适应搜索引擎优化搜索，当然，也可以美化我们的 url。</p><p>现在，我们可以将上述链接的伪静态地址定为：</p><blockquote><p>staticUrl = <a href="http://blog.muzixizao.com/p/5.html" target="_blank" rel="noopener">http://blog.muzixizao.com/p/5.html</a></p></blockquote><p>也就是说，当我们在地址栏中输入 staticUrl 时，需要服务器匹配到 oriUrl 匹配的路由。这个对于 nginx 而言，一个正则匹配就够了。</p><pre><code>location / {    rewrite ^/p/(\d+).html$ /?p=$1; 将 /p/140.html 重写成 /?p=140}</code></pre><p>对于 nginx 的路由匹配不太明白的，可以参考 <a href="https://www.cnblogs.com/BeiGuo-FengGuang/p/9844128.html" target="_blank" rel="noopener">Nginx location匹配规则</a>。</p><p>如果有较多的匹配规则，可以将伪静态的路由重写抽离成一个单独的文件，在对应域名下引入重写文件即可。</p><pre><code># rewrite.conflocation / {    rewrite ^/p/(\d+).html$ /?p=$1; 将 /p/140.html 重写成 /?p=140}</code></pre><pre><code># nginx.conflocation / {    include rewrite.conf}</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Nginx location匹配规则</title>
      <link href="/10/uncategorized/ck0669dci0007agaa8z7ndxgv/"/>
      <url>/10/uncategorized/ck0669dci0007agaa8z7ndxgv/</url>
      
        <content type="html"><![CDATA[<h3 id="1、语法"><a href="#1、语法" class="headerlink" title="1、语法"></a>1、语法</h3><pre><code>location [=|~|~*|^~|@] /uri/ {  ...} </code></pre><h3 id="2、说明"><a href="#2、说明" class="headerlink" title="2、说明"></a>2、说明</h3><p>从上面的语法出发，可以了解到 location 可以区分为三个部分，接下来一个一个的研究一下。</p><h5 id="1"><a href="#1" class="headerlink" title="1) [=||*|^~|@]"></a>1) [=|<del>|</del>*|^~|@]</h5><ul><li>= : 表示精确匹配后面的url</li><li>~ : 表示正则匹配，但是区分大小写</li><li>~* : 正则匹配，不区分大小写</li><li>^~ : 表示普通字符匹配，如果该选项匹配，只匹配该选项，不匹配别的选项，一般用来匹配目录</li><li>@ : “@” 定义一个命名的 location，使用在内部定向时，例如 error_page</li></ul><p>上面定义了几个不同的符号，表示不同的匹配规则，那么先后顺序呢？</p><ol><li>= 前缀的指令严格匹配这个查询。如果找到，停止搜索；</li><li>所有剩下的常规字符串，最长的匹配。如果这个匹配使用 ^~ 前缀，搜索停止；</li><li>正则表达式，在配置文件中定义的顺序；</li><li>如果第 3 条规则产生匹配的话，结果被使用。否则，使用第 2 条规则的结果。</li></ol><h6 id="测试示例1"><a href="#测试示例1" class="headerlink" title="测试示例1:"></a>测试示例1:</h6><pre><code>location = /world {    return 600;}location = /hello {    return 600;}location ~ /hellowo {    return 602;}location ^~ /hello {    return 601;}</code></pre><pre><code>- 请求 localhost/world 返回600- 请求 localhost/world2 localhost/test/world 返回其他- 请求 localhost/hello  返回600- 请求 localhost/hello/123 返回601- 请求 localhost/hellow 返回601- 请求 localhost/hellowo 返回601- 请求 localhost/test/hellowo  返回602- 请求 localhost/test/hello 返回其他</code></pre><p>因此可以知道:</p><ul><li>= 是精确完整匹配，且优先级最高；</li><li>正则匹配时，如果 ~ 和 ^~ 同时匹配规则，则 ^~ 优先；</li><li>^~ 这个规则不会匹配请求 url 中后面的路径，如上面的 /test/hello 没有匹配上</li><li>^~ 不支持正则，和 = 相比，范围更广，hellowo 是可以被 ^~ 匹配，但是 = 不会匹配；</li><li>~ 路径中只要包含就可以匹配，如上面的 /test/hellowo 返回了 602</li></ul><h6 id="测试示例2"><a href="#测试示例2" class="headerlink" title="测试示例2:"></a>测试示例2:</h6><pre><code>location ~ /hello {  return 602;}location ~ /helloworld {  return 601;}</code></pre><pre><code>- 请求 localhost/world/helloworld 返回 602- 请求 localhost/helloworld 返回 602</code></pre><p>调整上面的顺序</p><pre><code>location ~ /helloworld {  return 601;}location ~ /hello {  return 602;}</code></pre><pre><code>- 请求 localhost/helloworld 返回601- 请求 localhost/world/helloworld 返回601- 请求 localhost/helloWorld 返回602</code></pre><p>所以同时正则匹配时</p><ul><li>放在前面的优先匹配</li><li>注意如果不区分大小写时，使用 ~*</li><li>尽量将精确匹配的放在前面</li></ul><h6 id="测试示例3"><a href="#测试示例3" class="headerlink" title="测试示例3:"></a>测试示例3:</h6><pre><code>location ^~ /hello/ {  return 601;}location /hello/world {  return 602;}</code></pre><p>这种场景中，存在一个没有符合的路由规则，那么实际的测试是怎样呢？</p><pre><code>- http://localhost/hello/wor 返回601- http://localhost/hello/world 返回602- http://localhost/hello/world23 返回602- http://localhost/hello/world/123 返回602</code></pre><p>从上面的示例可以看出</p><ul><li>没有符合时，全匹配是优先 ^~ 的</li></ul><h5 id="2-uri"><a href="#2-uri" class="headerlink" title="2) [uri]"></a>2) [uri]</h5><p>这里主要填的是需要匹配的 path 路径，根据前面的符号，这里可以填写精确到 path 路径，也可以填正则表达式，下面则主要针对正则进行说明</p><pre><code>. ： 匹配除换行符以外的任意字符? ： 重复0次或1次+ ： 重复1次或更多次* ： 重复0次或更多次\d ：匹配数字^ ： 匹配字符串的开始$ ： 匹配字符串的介绍{n} ： 重复n次{n,} ： 重复n次或更多次[c] ： 匹配单个字符c[a-z] ： 匹配a-z小写字母的任意一个小括号()之间匹配的内容，可以在后面通过$1来引用，$2表示的是前面第二个()里的内容。正则里面容易让人困惑的是\转义特殊字符。</code></pre><h2 id="路由转发"><a href="#路由转发" class="headerlink" title="路由转发"></a>路由转发</h2><pre><code>请求 path 匹配只是第一步，匹配完成之后，如何将请求转发给其它的 web 服务呢？</code></pre><h3 id="1、反向代理"><a href="#1、反向代理" class="headerlink" title="1、反向代理"></a>1、反向代理</h3><p>通常可见的一种使用姿势就是使用 nginx 代理请求，转发到内部的其它 web 服务上</p><p>主要通过 prixy_pass 来实现</p><pre><code>location ^~ /webs {    proxy_pass http://127.0.0.1:8080/webs;}</code></pre><p>上面规则的含义是，将所有以 webs 开头的请求，转发到 8080 端口的 web 服务上。</p><p>上面是直接写死转发到一个 ip 上，如果是多个机器提供服务，可以这样配置</p><pre><code>## 下面放在http的括号内，作为第一层upstream test.online {    server 47.106.81.116:8080 weight=1;    server 47.106.81.117:8080 weight=1;}location ^~ /webs {    proxy_pass http://test.online;    proxy_redirect default;}</code></pre><h3 id="2、Rewrite-命令"><a href="#2、Rewrite-命令" class="headerlink" title="2、Rewrite 命令"></a>2、Rewrite 命令</h3><p>rewrite功能就是，使用nginx提供的全局变量或自己设置的变量，结合正则表达式和标志位实现url重写以及重定向。</p><p>rewrite只能放在server{},location{},if{}中，并且只能对域名后边的除去传递的参数外的字符串起作用, 如</p><pre><code>http://blog.muzixizao.com/a/we/index.php?id=1&amp;u=str</code></pre><p> 只对/a/we/index.php重写。</p><pre><code>语法: rewrite regex replacement [flag];</code></pre><p>示例:</p><pre><code>location ^~ /hexo {  root '/Users/yihui/GitHub/';}location ~ /hello {  rewrite ^(/hello).*$ /hexo/public/index.html last;  return 603;}</code></pre><p>将hello开头的，全部转发到/hexo/public/index.html</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>位运算符</title>
      <link href="/10/uncategorized/ck0669dcx0008agaa8wk2yunh/"/>
      <url>/10/uncategorized/ck0669dcx0008agaa8wk2yunh/</url>
      
        <content type="html"><![CDATA[<h3 id="位运算一览表"><a href="#位运算一览表" class="headerlink" title="位运算一览表"></a>位运算一览表</h3><table><thead><tr><th>符号</th><th>示例</th><th>含义</th></tr></thead><tbody><tr><td>&amp;</td><td>$a &amp; $b</td><td>按位与。将 $a 和 $b 中都为 1 的位设为 1</td></tr><tr><td>|</td><td>$a | $b</td><td>按位或。将 $a 和 $b 中任何一个为 1 的位设为 1</td></tr><tr><td>^</td><td>$a ^ $c</td><td>按位异或。将 $a 和 $b 中相同位不一致的位设为 1</td></tr><tr><td>~$a</td><td>~$a</td><td>按位取反。将 $a 为 1 的位设为 0，为 0 的位设为 1</td></tr><tr><td>&lt;&lt;</td><td>$a &lt;&lt; $c</td><td>左移。将 $a 的位向 <strong>左</strong> 移动 $b 次</td></tr><tr><td>&gt;&gt;</td><td>$d &gt;&gt; $b</td><td>左移。将 $a 的位向 <strong>右</strong> 移动 $b 次</td></tr></tbody></table><h3 id="amp-运算符"><a href="#amp-运算符" class="headerlink" title="&amp; 运算符"></a>&amp; 运算符</h3><blockquote><p>按位与。相同为 1，不同为 0</p><pre><code>$a = 1; // 0001$b = 2; // 0010echo $a &amp; $b; // 0000</code></pre><p>按位比较，相同位得1，不同位得 0。由于 1 和 2 的二进制数中每个位都不相同，所以结果为: 0000，也就是 0。</p></blockquote><h3 id="运算符"><a href="#运算符" class="headerlink" title="| 运算符"></a>| 运算符</h3><blockquote><p>按位或。有 1 为 1，无 1 为 0</p><pre><code>$a = 1; // 0001$b = 3; // 0011echo $a | $b; // 0011</code></pre></blockquote><p>按位比较，相同位得 0 ，不同位 得 1，所以结果为: 0011，也就是 3。</p><h3 id="运算符-1"><a href="#运算符-1" class="headerlink" title="^ 运算符"></a>^ 运算符</h3><blockquote><p>按位异或。相同为 0，不同为 1</p><pre><code>$a = 1; // 0001$b = 3; // 0011echo $a ^ $b; // 0010</code></pre></blockquote><p>按位比较，相同位得 0 ，不同位 得 1，所以结果为: 0010，也就是 2。</p><h3 id="运算符-2"><a href="#运算符-2" class="headerlink" title="~ 运算符"></a>~ 运算符</h3><blockquote><p>按位取反。1 取 0，0 取 1</p><pre><code>$a = 1; // 0000 0000 0000 0000 0000 0000 0000 0001$a1 = ~$a;echo $a1; // -2。 </code></pre><p>这个运算符相比较其它位运算符要复杂一些。我们知道，大多数编程语言中，最高位是符号位，那么，32 位操作系统下，PHP 整数的最大值是:<br>0111 1111 1111 1111 1111 1111 1111 1111 = 2147483647</p></blockquote><p>因此，当对 1 进行按位取反后，得到</p><blockquote><p>$A1 = 1111 1111 1111 1111 1111 1111 1111 1110</p></blockquote><p>符号位为 1，即为 <strong>负数</strong>。在计算机中，负数以其对应绝对值的补码形式表达。也就是说，$a1 的补码是 $A1，则</p><blockquote><p>反码 = 补码 - 1 = 1111 1111 1111 1111 1111 1111 1111 1101</p></blockquote><p>那么 $a1 对应的整数就是:</p><blockquote><p>原码 = 反码各位取反 = 0000 0000 0000 0000 0000 0000 0000 0010 = -2;</p></blockquote><h3 id="lt-lt-运算符"><a href="#lt-lt-运算符" class="headerlink" title="<< 运算符"></a>&lt;&lt; 运算符</h3><blockquote><p>各位向左移动，末尾补 0</p><pre><code>$a = 2; // 0000 0000 0000 0000 0000 0000 0000 0010$a1 = $a &lt;&lt; 3;echo $a1; // 16</code></pre><p>32 位系统下，一个整数用 32 位表示。当位数向左移动，舍去多余的位数，末尾补 0 ，则得到 $a1 为：<br>0000 0000 0000 0000 0000 0000 0001 0000 = 16</p></blockquote><p>因此</p><blockquote><p>$a &lt;&lt; $b = $a^($b+1) // $a 的 ($b + 1) 次方</p></blockquote><p>左移运算符有一个比较有趣的地方，当一个数向左移动超过计算机指定整数位时，就会出现不符合我们上述总结的原数平方规则的情况。比如 2 在 64 位系统下，向左移动 62、63、64 位：</p><pre><code>echo 2 &gt;&gt; 61 // 4611686018427387904echo 2 &gt;&gt; 62 // -9223372036854775808echo 2 &gt;&gt; 63 // 0echo 2 &gt;&gt; 64 // 0</code></pre><p>有兴趣的朋友可以列出对应二进制数，推演下计算过程。</p><h3 id="gt-gt-运算符"><a href="#gt-gt-运算符" class="headerlink" title=">> 运算符"></a>&gt;&gt; 运算符</h3><blockquote><p>各位向右移动，前面补 0</p><pre><code>$a = 8; // 0000 0000 0000 0000 0000 0000 0000 1000$a1 = $a &lt;&lt; 3;echo $a1; // 16</code></pre></blockquote><h3 id="左移和右移运算符“误区”"><a href="#左移和右移运算符“误区”" class="headerlink" title="左移和右移运算符“误区”"></a>左移和右移运算符“误区”</h3><p>关于左移和右移运算符，很多朋友可能会看到这样的总结:</p><blockquote><p><del>左移平方，右移开方</del></p></blockquote><p>其实严格来说，这只针对<strong>值为 2 的正整数次幂的整数有效</strong>。当不是 2 的正整数次幂时，比如：</p><pre><code>$a = 9; // 0000 0000 0000 0000 0000 0000 0000 1001$a1 = $a &gt;&gt; 1;echo $a1; // 4</code></pre><p>所以，遇到左移和右移运算符时，要实际情况实际分析，不能一味的按照别人的总结走。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>编程思想：面向对象和面向过程</title>
      <link href="/10/bianchengsixiang/ck0669dnb001vagaap2s8fs0g/"/>
      <url>/10/bianchengsixiang/ck0669dnb001vagaap2s8fs0g/</url>
      
        <content type="html"><![CDATA[<p><span style="font-size: 14px;">　　何谓面向对象？何谓面向过程？对于这编程界的两大思想，一直贯穿在我们学习和工作当中。我们知道面向过程和面向对象，但要让我们讲出来个所以然，又感觉是不知从何说起，最后可能也只会说出一句就是那样啦，你知道啦。而这种茫然，其实就是对这两大编程思想的迷糊之处。本文通过学生到校报道注册的实例，阐述了面向过程和面向对象两大思想。希望能对你的学习和工作有所帮助。</span></p><h2>一、面向过程</h2><p><span style="font-size: 14px;">　　首先我们来认识下，什么是面向过程？如果咬文嚼字的话可以这样来理解，面向过程就是面向解决问题的过程进行编程。仔细思考一下，我们在学习和工作中，当我们去实现某项功能或完成某项任务时，是不是会不自觉的按部就班的罗列出我们要做的事情？（如果没有，建议以后试着步骤化解决问题）。而当我们按着我们罗列的步骤去解决问题时，实质上就是按照面向过程的思想去解决问题。我们罗列的步骤就是过程，按照步骤解决问题就是面向过程。</span></p><p><span style="font-size: 14px;">　　传统的面向过程的编程思想总结起来就八个字——<span style="color: #ff0000;"><strong>自顶向下，逐步细化</strong></span>！实现步骤如下：</span></p><ol><li><span style="font-size: 14px;">将要实现的功能描述为一个从开始到结束按部就班的连续的步骤（过程）；</span></li><li><span style="font-size: 14px;">依次逐步完成这些步骤，如果某一步的难度较大，又可以将该步骤再次细化为若干个子步骤，以此类推，一直到结束得到想要的结果；</span></li><li><span style="font-size: 14px;">程序的主体是函数，一个函数就是一个封装起来的模块，可以实现一定的功能，各个子步骤往往就是通过各个函数来完成的，从而实现代码的重用和模块化编程！</span></li></ol><p><span style="font-size: 14px;">案例：学生到校报道注册</span></p><p align="center">面向过程流程图：</p><p align="center"><img src="https://raw.githubusercontent.com/zibinli/blog/master/other/_v_images/20190902154638865_14963.png" alt=""></p><p><span style="font-size: 14px;">面向过程，就是按照我们分析好了的步骤，按部就班的依次执行就行了！所以当我们用面向过程的思想去编程或解决问题时，首先一定要把详细的实现过程弄清楚。一旦过程设计清楚，代码的实现简直轻而易举。</span></p><h2>二、面向对象</h2><p><span style="font-size: 14px;">　　讨论完了面向过程，我们再来认识下面向对象。所谓的面向对象，就是在编程的时候尽可能的去模拟真实的现实世界，按照现实世界中的逻辑去处理一个问题，分析问题中参与其中的有<span style="color: #ff0000;"><strong>哪些实体</strong></span>，这些实体应该<span style="color: #ff0000;"><strong>有什么属性和方法</strong></span>，我们<span style="color: #ff0000;"><strong>如何通过调用这些实体的属性和方法</strong></span>去解决问题。</span></p><p><span style="font-size: 14px;">现实世界中，任何一个操作或者是业务逻辑的实现都需要一个实体来完成，也就是说，<span style="color: #ff0000;"><strong>实体就是动作的支配者</strong></span>，没有实体，就肯定没有动作发生！</span></p><p><span style="font-size: 14px;">　　现在让我们思考下，上述注册报名的每一个步骤都有哪些动词？</span></p><p><span style="font-size: 14px; background-color: #ffff00;">　　提出 提供 缴 收 获得 分配 增加</span></p><p><span style="font-size: 14px;">　　有动词就一定有实现这个动作的实体！</span></p><p><span style="font-size: 14px;">　　所谓的模拟现实世界，就是使计算机的编程语言在解决相关业务逻辑的方式，与真实的业务逻辑的发生保持一致！需要使每一个动作的背后都一个完成这个动作的实体！</span></p><p><span style="font-size: 14px;">　　因为任何功能的实现都是依赖于一个具体的<span style="color: #ff0000;"><strong>实体的“动作|操作|行动”<span style="color: #666666;">，</span></strong></span>可以看作是一个又一个的实体在发挥其各自的“能力”并在内部进行协调有序的调用过程！</span></p><p><span style="font-size: 14px;">　　当采用面向对象的思想解决问题时，可分为下面几步：</span></p><ol><li style="list-style-type: none;"><ol><li><span style="font-size: 14px;">分析哪些动作是由哪些实体发出的；</span></li><li><span style="font-size: 14px;">定义这些实体，为其增加相应的属性和功能；</span></li><li><span style="font-size: 14px;">让实体去执行相应的功能或动作。</span></li></ol></li></ol><p><span style="font-size: 14px;">　　采用面向对象的思想，解决上面的报名问题，应该如下：</span></p><p><span style="font-size: 14px;"><strong><span style="color: #000000;">第一步：分析那些动作是由哪些实体发出的</span></strong></span></p><ul><li><span style="font-size: 14px;">学生提出报名</span></li><li><span style="font-size: 14px;">学生缴费</span></li><li><span style="font-size: 14px;">机构收费</span></li><li><span style="font-size: 14px;">教师分配教室</span></li><li><span style="font-size: 14px;">班级增加学生信息</span></li></ul><p><span style="font-size: 14px;">　　于是，在整个过程中，一共有四个实体：</span></p><p><span style="font-size: 14px;">　　学生、机构、教师、班级！</span></p><p><span style="font-size: 14px;">　　在现实中的一个具体的实体，就是计算机编程中的一个对象！</span></p><p><span style="font-size: 14px;"><strong>第二步：定义这些实体，为其增加相应的属性和功能</strong></span></p><p><span style="font-size: 14px;">　　属性就是实体在现实世界中的一些特征表现。如：</span></p><ul><li style="list-style-type: none;"><ul><li><span style="font-size: 14px;">人的属性：姓名、性别、身高、三围、体重、电话号码、家庭住址、籍贯等</span></li><li><span style="font-size: 14px;">手机的属性：品牌、价格、颜色、尺寸、待机时间等</span></li></ul></li></ul><p><span style="font-size: 14px;">　　功能就是能完成的动作，在面向对象的术语中，动作就叫作方法或者函数。如：</span></p><ul><li style="list-style-type: none;"><ul><li><span style="font-size: 14px;">人的动作（功能）：吃饭、睡觉、学习、打游戏、走路、跑步、缴费！</span></li><li><span style="font-size: 14px;">手机的动作（功能）：打电话、发短信、拍照、打游戏、视频、看电影等</span></li></ul></li></ul><p><span style="font-size: 14px;">　　下图显示了在上述实例中出现的实体以及相应的属性和功能：</span></p><p><img style="display: block; margin-left: auto; margin-right: auto;" src="https://raw.githubusercontent.com/zibinli/blog/master/other/_v_images/20190902154601515_29527.png" alt=""></p><p><strong><span style="font-size: medium;">第三步：让实体去执行相应的功能或动作</span></strong></p><ul><li><span style="font-size: 14px;">学生提出报名</span></li><li><span style="font-size: 14px;">学生缴费</span></li><li><span style="font-size: 14px;">学校收费</span></li><li><span style="font-size: 14px;">教师分配教室</span></li><li><span style="font-size: 14px;">班级增加学生信息</span></li></ul><p><span style="font-size: 14px;">　　所以说，面向过程主要是针对功能，而面向对象主要是针对能够实现该功能的背后的实体。面向对象实质上就是面向实体，所以当我们使用面向对象进行编程时，一定要建立这样一个观念：万物皆对象！</span></p><h2>三、面向对象和面向过程的比较</h2><p><span style="font-size: 14px;">　　在我们将面向过程和面向对象讨论完后，会明显的感觉两者之间有着很大的区别。面向过程简单直接，易于入门理解，模块化程度较低。而面向对象相对于面向过程较为复杂，不易理解，模块化程度较高。可总结为下面三点：</span></p><ol><li><span style="font-size: 14px;">都可以实现代码重用和模块化编程，但是面对对象的模块化更深，数据更封闭，也更安全！因为面向对象的封装性更强！</span></li><li><span style="font-size: 14px;">面对对象的思维方式更加贴近于现实生活，更容易解决大型的复杂的业务逻辑</span></li><li><span style="font-size: 14px;">从前期开发角度上来看，面对对象远比面向过程要复杂，但是从维护和扩展功能的角度上来看，面对对象远比面向过程要简单！</span></li></ol><p><span style="font-size: 14px;">　　如何选择面向对象还是面向过程，对于一个有着丰富开发经验的老手来说，这是个得心应手的过程。而对于一个新手而言，其实从两者的对比就可以看出，当我们的业务逻辑比较简单时，使用面向过程能更快的实现。但是当我们的业务逻辑比较复杂时，为了将来的维护和扩展，还是面向对象更为靠谱点！当然，当我们被经理催着上交项目时，不要再选择纠结了，哪个能让你更快的完成项目就用哪个吧！</span></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 编程思想 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 常见问题及解决方案 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PHP核心编程知识点</title>
      <link href="/10/uncategorized/ck0669dry0039agaazsg3qpyn/"/>
      <url>/10/uncategorized/ck0669dry0039agaazsg3qpyn/</url>
      
        <content type="html"><![CDATA[<h2>一、PHP基本语法</h2><ol><li>PHP标记：一共有四种，只推荐使用第一种</li><li>语句结束符：分号</li><li>注释：行注释（//&nbsp; #）和块注释(/*&nbsp;&nbsp; */)，注释的规范</li></ol><h2>二、常见的输出语句</h2><ol><li>print</li><li>echo</li><li>var_dump</li><li>print_r</li><li>printf</li></ol><h2>三、变量</h2><ol><li>变量的组成：变量名和变量值组成，变量名引用变量值</li><li>内存的组成：堆区、栈区、用户代码区，全局数据区（变量区、常量区、静态变量区），变量名在栈区，变量值是在变量区中</li><li>变量的基本语法：$</li><li>变量的命名规则</li><li>可变变量：变量的名又可以用一个变量来代替</li><li>变量的基本操作<ul><li>增：声明变量</li><li>删：删除变量，unset的行为：删除变量名空间，消除引用关系</li><li>该：修改变量的值</li><li>查：获取变量的值，输出变量</li></ul></li><li>变量间的传值<ul><li>值传递：传递后两个变量独占占用各自的变量名空间和变量值空间，互补干扰</li><li>引用传递：传递后两个变量的变量名共同引用相同的变量值空间</li></ul></li><li>预定义变量<ul><li>$_SERVER</li><li>$_GET</li><li>$_POST</li><li>$_REQUEST</li></ul></li><li>其他</li></ol><h2>四、常量</h2><ol><li>常量的定义：define('名’,值,是否不区分大小写)&nbsp;&nbsp; const 常量名=常量值</li><li>常量的语法意义：用来规范数据保证数据在运行的过程中不被改变</li><li>判断常量是否存在：defined(‘常量名’)，返回一个布尔值</li><li>常量的命名规则，特殊的常量名使用constant(‘常量名’)方式进行访问</li><li>获取所有的常量：get_defined_constants()</li><li>预定义常量<ul><li>含义</li></ul></li><li>魔术常量：该常量的值由其所在的位置决定</li></ol><h2>五、数据类型</h2><h4>1.数据类型简介</h4><ul><ul><li>程序 = 数据结构 + 算法</li><li>PHP的数据类型：三大类，8小类</li></ul></ul><h4>2.进制及进制转换</h4><ol><li>其他进制转换为十进制：按权展开！</li><li>十进制转二进制<ol><li>整数<ul><li>除二取余法</li><li>填充法</li></ul></li><li>小数：乘二取整</li></ol></li><li>十进制转其他进制<ul><li>整数：除 n 取余</li><li>小数：乘 n 取整</li></ul></li><li>八进制、二进制、十六进制直接的互转<ol><li>二、八之间的互转<ul><li>八转二：一拆三（421码）</li><li>二转八：三并一</li></ul></li><li>二、十六之间的互转<ul><li>十六转二：一拆四</li><li>二转十六：四并一</li></ul></li><li>八、十六之间的互转<ul><li>八转十六：先一拆三，再四并一</li><li>十六转八：先一拆四，再三并一</li></ul></li></ol></li></ol><h4>3.整型数据</h4><ol><li>表示形式<ul><li>十进制</li><li>八进制，以0开头</li><li>十六进制，以0x开头</li></ul></li><li>在内存中的形式：二进制的补码的形式存放的</li><li>原码、反码和补码的概念</li></ol><h4>4.浮点型数据</h4><ol><li>表示形式：<ol><li>小数形式</li><li>指数形式<ul><li>e不区分大小写</li><li>e后必须要有数字</li><li>e后必须是整数</li></ul></li></ol></li><li>在内存中的形式：只能以指数的形式存放</li><li>浮点数的比较：不要使用浮点数进行比较，因为会浮点数会丢失精度</li></ol><h4>5.布尔型数据</h4><ol><li>只有true和false两个值，不区分大小写</li><li>在进行逻辑判断的时候，以下的值会当成false进行处理<ul><li>整数0</li><li>浮点数0:0.0</li><li>字符串0：’0’</li><li>空字符串：’’</li><li>空类型：NULL</li><li>空数组：array（）</li><li>对象和资源型永远为真！</li></ul></li></ol><h4>6.字符串数据</h4><ul><li>单引号</li><li>双引号</li><li>定界符：Heredoc</li><li>定界符：Nowdoc</li></ul><h4>7.特殊数据类型</h4><ul><li>NULL类型</li><li>resource型</li></ul><h4>8.类型转换</h4><ol><li><p>类型自动转换</p><ul><li>字符串型自动转换为数值型</li><li>其他类型自动转换为布尔型</li></ul></li><li>类型强制转换<ul><li>利用类型强制转换运算符()来完成的！</li><li>使用(array)进制强制转换的时候的注意事项</li></ul></li></ol><h4>9.类型相关函数</h4><ul><li>类型相关的函数<ul><li>gettype</li><li>settype</li><li>isset</li><li>empty</li><li>is_type系列</li></ul></li></ul><h3>六、运算符</h3><h4>1.几个概念</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; a.运算符的概念</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; b.运算符的分类</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; c.运算符的优先级和结合性</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; d.表达式和语句</p><h4>2.算术运算符</h4><ul><ul><li>求余运算符：在运算之前先把两个操作数都自动转换为整型，符号是由被除数决定的</li><li>自增自减：++和——在前面和在后面的区别</li></ul></ul><h4>3.赋值运算符</h4><ul><ul><li>复合的赋值运算符</li><li>赋值运算符的结合性：右结合</li><li>赋值表达式的值就是被赋值的那个变量的值$a = 100</li></ul></ul><h4>4.字符串连接符</h4><ul><ul><li>主要和逗号的区别</li><li>在运算之前是将两边的操作数都自动转换为字符串类，然后进行横向的“拼接”</li></ul></ul><h4>5.关系运算符</h4><ul><ul><li>=和==的区别</li><li>==和===的区别</li></ul></ul><h4>6.逻辑运算符</h4><ul><ul><li>逻辑与 &amp;&amp; 或者and</li><li>逻辑或 ||&nbsp; 或者 or</li><li>逻辑非 ！</li><li>逻辑异或 xor</li><li>注意短路运算</li></ul></ul><h4>7.条件运算符</h4><ul><ul><li>形式：表达式1 ？ 表达式2 ： 表达式3</li><li>也有短路运算的行为，相当于简单的if……else语句</li></ul></ul><h4>8.位运算符</h4><ul><ul><li>按位与 &amp;</li><li>按位或 |</li><li>按位非 ~</li><li>按位异或 ^</li><li>按位左移：&lt;&lt;，右边补0</li><li>按位右移：&gt;&gt;，左边正数补0，负数补1</li></ul></ul><h4>9.其他运算符</h4><ul><ul><li>new、clone、instanceof、@</li></ul></ul><h3>七、流程控制</h3><h4>1.流程控制简介</h4><ul><ul><li>三大结构：顺序、选择、循环</li><li>算法的表示：流程图、伪代码、自然语言</li></ul></ul><h4>2.if语句</h4><ul><ul><li>条件执行：只有if没有else</li><li>if……else……</li><li>if……elseif……</li></ul></ul><h4>3.switch语句</h4><ul><ul><li>开关语句：一旦case后面的表达式的值和switch后面表达式的值一致，开关就打开了，一直遇到右花括号或者break语句为止！</li><li>与if语句的区别：if语句是条件分支，switch语句是状态分支</li></ul></ul><h4>4.while语句</h4><ul><ul><li>当型循环：里面的循环体有可能一次都不执行</li><li>百钱买百鸡：面向过程的编程思想——自顶向下，逐步细化！</li></ul></ul><h4>5.do-while语句</h4><ul><ul><li>直到型循环：里面的循环体至少要执行一次</li><li>辗转相除法求最大公约数：体会while循环和do-while循环的区别</li></ul></ul><h4>6.for语句</h4><ul><ul><li>使用的最多，因为最简洁紧凑</li><li>执行流程</li><li>表达式1、表达式2、表达式3都可以省略</li></ul></ul><h4>7.循环的中断语句</h4><ul><ul><li>continue：结束当前的本次循环，继续下一次循环</li><li>break：结束当前整个循环</li><li>中断的层次：默认值为1</li></ul></ul><h4>8.流程控制语句的替代语法</h4><ul><ul><li>把所有的左花括号都用冒号来代替</li><li>整个流程控制语句结束后，再用endIf、endWhile、endFor、endForeach等来结束</li><li>do-while没有这种替代语法</li></ul></ul><h4>9.文件载入</h4><ol><li>体现了网站的分层设计，以提高代码的重用性</li><li>有四种不同的载入的方式，只是语法上的一些差异</li><li>载入的原理（过程）<ul><li>退出PHP模式，进入HTML模式</li><li>将目标文件内的源代码载入到当前位置（相当于将其中的源码复制到当前载入的位置）</li><li>将被载入的源代码先进行预编译然后执行（文件的载入是发生在执行阶段）</li><li>再次进入PHP模式</li></ul></li><li>载入时的路径问题<ul><li>相对路径：./&nbsp;&nbsp;&nbsp; ../&nbsp;&nbsp;&nbsp;</li><li>默认路径：可以在php.ini中进行配置（include_path）</li><li>绝对路径：一般都要先定义目录常量</li></ul></li><li>四种载入方式的区别<ul><li>include和require</li><li>include和include_once</li></ul></li></ol><h4>10.脚本的执行控制</h4><ul><ul><li>die或exit</li><li>sleep</li></ul></ul><h3>八、函数</h3><h4>1.函数的定义</h4><h4>2.函数的组成</h4><ol><li>函数名</li><li>函数参数列表</li><li>函数体</li></ol><h4>3.函数调用</h4><h4>4.可变函数</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 函数名可以用一个变量来代替</p><h4>5.匿名函数</h4><h4>6.函数的参数</h4><ol><li>形参和实参</li><li>参数的值传递和引用传递</li><li>形参的默认值</li><li>参数的数量问题<ol><li>实参多于形参</li><li>实参少于形参：只有一种正确的情况，那就是形参有默认值的时候</li><li>不定参数的函数<ul><li>基本思想：干脆一个都不定义</li><li>func_get_args()用来接收实参的值，是一个索引数组</li><li>func_get_arg()用来获取某一个实参的值，索引是从0开始</li><li>func_num_args()，用于获取实参的数量</li></ul></li></ol></li><li>函数体<ul><li>return语句</li><li>函数内允许出现多个return语句，但是只能执行其中的一条</li><li>如果一个函数内确实有很多的值需要返回，一般的做法就是把这些值放到一个数组（对象）里面，然后返回这个数组就行了</li></ul></li><li>函数的作用域<ul><li>全局作用域（全局变量）</li><li>局部作用域（局部变量）</li><li>超全局作用域（预定义变量）</li><li>$GLOBALS</li><li>关键字global</li></ul></li></ol><h4>7.变量的生命周期</h4><ul><ul><li>概念：与变量的作用域的区别</li><li>静态局部变量：使用关键字static</li></ul></ul><h4>8.函数的递归调用</h4><ul><ul><li>概念：就是函数在执行的时候自己调用自己，不是一种新的语法，而是一种算法的描述</li><li>递归调用的关键点：递归出口，递归点，写程序的时候先写递归出口，然后再写递归点</li><li>特点：代码书写比较简单，本质上就是以空间换取时间</li></ul></ul><h4>10.字符串函数</h4><ul><ul><li>strlen</li><li>substr</li><li>strtolower|strtoupper</li><li>ucfirst：首字母大写</li><li>strrev</li><li>strpos</li><li>strrpos</li><li>strchr|strstr</li><li>strrchr</li><li>trim</li><li>str_replace(要替换的字符，替换成什么字符，从哪个字符串替换);</li></ul></ul><h4>11.时间函数</h4><ul><ul><li>time：返回一个时间戳</li><li>date：将一个时间戳格式化为指定的格式（常见的时间占位符：Y-m-d H:i:s）</li><li>strtotime</li><li>microtime，加上参数true就是返回一个浮点型的时间戳</li></ul></ul><h4>12.数学函数</h4><ul><ul><li>abs</li><li>sqrt</li><li>pow</li><li>ceil|floor</li><li>round</li><li>rand|mt_rand</li></ul></ul><h3>九、数组</h3><ol><li><p>数组初步</p><ol><li>数组创建：显示创建，隐式创建、利用强制类型转换符创建</li><li>数组访问：中括号语法</li><li>数组分类：<ol><li>键值之间的关系：索引数组和关联数组</li><li>数组的维度：一维和多维数组</li></ol></li></ol></li><li>foreach遍历</li><ol><li>基本语法</li><li>几个细节</li><li>数组的指针：reset，next、current、key</li></ol></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>PHP中WEB典型应用技术</title>
      <link href="/10/uncategorized/ck0669dwp006zagaas0dqg1qz/"/>
      <url>/10/uncategorized/ck0669dwp006zagaas0dqg1qz/</url>
      
        <content type="html"><![CDATA[<h2>主要讲5个方面：</h2><ol><li>PHP与web页面的交互：表单传值，文件的上传与下载</li><li>http协议</li><li>PHP的会话技术：cookie和session</li><li>PHP的图像技术：GD库，图像的常见的制作和操作，验证码，二维码，水印、缩略图，3D图等等</li><li>文件操作：打开、关闭、读取文件、写入文件，遍历目录等</li></ol><h3>一、PHP与web页面的交互：表单传值，文件的上传与下载</h3><h4>1、表单传值</h4><p><strong>&nbsp;&nbsp;&nbsp; 1.1、单选框</strong></p><p>single.html</p><div class="cnblogs_code"><pre> 1 &lt;!DOCTYPE html&gt;  2 &lt;html&gt;  3 &lt;head&gt;  4     &lt;title&gt;单选项传值&lt;/title&gt;  5     &lt;meta charset="utf-8"&gt;  6 &lt;/head&gt;  7 &lt;body&gt;  8     &lt;form method="GET" action="single.php"&gt;  9         &lt;p&gt;用户名：&lt;input type="text" name="username" /&gt;&lt;/p&gt; 10         &lt;p&gt; 11 <span>           性  别： 12            &lt;input type="radio" name="gender" value="1" /&gt;<span>男 13            &lt;input type="radio" name="gender" value="2" /&gt;<span>女 14            &lt;input type="radio" name="gender" value="3" /&gt;<span>保密 15         &lt;/p&gt; 16         &lt;p&gt;密  码：&lt;input type="password" name="password" /&gt;&lt;/p&gt; 17         &lt;p&gt;&lt;input type="submit" value="提交"&gt;&lt;/p&gt; 18     &lt;/form&gt; 19 &lt;/body&gt; 20 &lt;/html&gt;</span></span></span></span></pre></div><p>&nbsp;</p><p>single.php</p><div class="cnblogs_code"><pre>1 &lt;?<span>php2 3 header('Content-type:text/html;charset=utf8'<span>); 4 echo '&lt;pre&gt;'<span>; 5 var_dump($_GET);</span></span></span></pre></div><p>&nbsp;</p><p>注意：</p><ul><li>一组选择的name值必须相同；</li></ul><ul><li class="_mce_tagged_br">必须要有value属性，且value属性的值不能相同。</li></ul><p><strong>&nbsp;&nbsp; 1.2、多选框</strong></p><p>muliSelect.html</p><div class="cnblogs_code"><pre> 1 &lt;!DOCTYPE html&gt;  2 &lt;html&gt;  3 &lt;head&gt;  4     &lt;title&gt;单选项传值&lt;/title&gt;  5     &lt;meta charset="utf-8"&gt;  6 &lt;/head&gt;  7 &lt;body&gt;  8     &lt;form method="POST" action="muliSelect.php"&gt;  9         &lt;p&gt;用户名：&lt;input type="text" name="username" /&gt;&lt;/p&gt; 10         &lt;p&gt; 11 <span>           爱 好： 12            &lt;input type="checkbox" name="hobby[]" value="唱歌"&gt;<span>唱歌 13            &lt;input type="checkbox" name="hobby[]" value="跳舞"&gt;<span>跳舞 14            &lt;input type="checkbox" name="hobby[]" value="电影"&gt;<span>电影 15            &lt;input type="checkbox" name="hobby[]" value="篮球"&gt;<span>篮球 16         &lt;/p&gt; 17         &lt;p&gt;&lt;input type="submit" value="提交"&gt;&lt;/p&gt; 18     &lt;/form&gt; 19 &lt;/body&gt; 20 &lt;/html&gt;</span></span></span></span></span></pre></div><p>&nbsp;</p><p>muliSelect.php</p><div class="cnblogs_code"><pre> 1 &lt;?<span>php 2  3 header('Content-type:text/html;charset=utf8'<span>);  4 /*echo '&lt;pre&gt;';  5 var_dump($_POST);*/  6 // 1,连接数据库  7 mysql_connect('localhost:3306','root','aaa'<span>);  8 mysql_query('set names utf8'<span>);  9 mysql_query('use php2018'<span>); 10 // 2,接收数据 11 $user_name = trim($_POST['username'<span>]); 12 $user_gender = $_POST['gender'<span>]; 13 $hobby = $_POST['hobby'<span>]; 14 $user_password = md5(trim($_POST['password'<span>]));15 16 // 将数组转换成字符串才能写入数据库 17 $user_hobby = implode(',',$hobby<span>);18 19 // 3,数据入库 20 $sql = "<span>insert into user values 21         (null,'$user_name','$user_gender','$user_hobby','$user_password')"<span>;22 23 $result = mysql_query($sql<span>);24 25 if($result<span>) { 26     echo '插入成功'<span>; 27 }else<span> { 28     echo '插入失败'<span>; 29 <span>}30 31 /*create table user( 32     user_id int primary key auto_increment, 33     user_name varchar(20) not null default '匿名', 34     user_gender enum('1','2','3') comment '1是男2是女3是保密', 35     user_hobby set('唱歌','跳舞','电影','篮球'), 36     user_password char(32) 37 );*/</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre></div><p>&nbsp;</p><p>注意：</p><ul><li>当我们用PHP获取多选框的值时，会获得一个数组；</li></ul><ul><li class="_mce_tagged_br">当我们将多选框的值存入数据库时，需要将获得的数组用 implode() 函数分成一个字符串，再存入数据库中。</li></ul><h4>2、文件上传</h4><p>实现文件上传，由下面几步：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1）、在服务器端要开启文件上传功能；</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2）、在浏览器端提供能够进行文件上传的表单。其实就是给表单添加属性：enctype=”multipart/form-data”；</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3）、使用$_FILES接收上传的文件的相关信息；</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4）、验证文件；</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5）、将文件从临时文件夹移动到指定的目录下。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 其实就是利用一个函数：move_upload_file(临时文件名，目标存放的目录及文件名);有一个返回值，如果上传成功就返回true，否则就返回false；</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PHP默认的上传临时文件夹是在C盘下，有时候因为权限问题会导致上传失败， 因此我们一般会修改上传的临时文件夹。</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<img src="http://images2015.cnblogs.com/blog/861679/201610/861679-20161003104052739-489958778.png" alt=""></p><p><strong>封装文件上传函数</strong></p><p>upload.php</p><div class="cnblogs_code"><pre>  1 &lt;?<span>php  2   3 # 文件上传函数  4   5 /**  6   7 * 文件上传  8   9 * @param array $file 上传文件的信息（是一个数组，有5个元素） 10  11 * @param array $allow 文件上传的类型 12  13 * @param string &amp; $error 引用类型，用来记录错误信息 14  15 * @param string $path 文件上传的路径 16  17 * @param int $maxsize = 2*1024*1024 允许上传的文件的大小 18  19 * @return false|$newname 如果上传失败就返回false，成功则返回文件的新名字 20  21 */ 22  23 function upload($file,$allow,&amp; $error,$path,$maxsize=2097152<span>){ 24  25 # 1,判断系统错误 26  27 switch ($file['error'<span>]) { 28  29 case 1: 30  31 $error = '上传错误，超出了文件限制的大小！'<span>; 32  33 return false<span>; 34  35 case 2: 36  37 $error = '上传错误，超出了表单允许的大小！'<span>; 38  39 return false<span>; 40  41 case 3: 42  43 $error = '上传错误，文件上传不完整！'<span>; 44  45 return false<span>; 46  47 case 4: 48  49 $error = '请先选择要上传的文件！'<span>; 50  51 return false<span>; 52  53 case 6: 54  55 case 7: 56  57 $error = '对不起，服务器繁忙，请稍后再试！'<span>; 58  59 return false<span>; 60  61 <span>} 62  63 # 2,判断逻辑错误 64  65 // 2.1，判断文件大小 66  67 if ($file['size'] &gt; $maxsize<span>) { 68  69 $error = '超出文件大小，允许的最大值为：'. $maxsize . '字节'<span>; 70  71 return false<span>; 72  73 <span>} 74  75 // 2.2，判断文件类型 76  77 if (!in_array($file['type'], $allow<span>)) { 78  79 //文件类型非法 80  81 $error = '上传的文件类型不正确，允许的类型有：' . implode(',', $allow<span>); 82  83 return false<span>; 84  85 <span>} 86  87 # 3, 得到文件的新名字 88  89 $newname = randName($file['name'<span>]); 90  91 # 4，移动临时文件到指定路径 92  93 $target = $path . '/' . $newname<span>; 94  95 if (move_uploaded_file($file['tmp_name'], $target<span>)) { 96  97 return $newname<span>; 98  99 }else<span> {100 101 $error = '发生未知错误，上传失败！'<span>;102 103 return false<span>;104 105 <span>}106 107 <span>}108 109 # 定义一个产生随机名字的函数110 111 /**112 113 * @param string $filename 文件的旧名字114 115 * @param string $newname 文件的新名字116 117 */118 119 function randName($filename<span>) {120 121 //生成文件名的时间部分122 123 $newname = date('YmdHis'<span>);124 125 //加上随机的六位数126 127 $str = '0123456789'<span>;128 129 //得到六位随机数130 131 for ($i=0; $i &lt; 6; $i++<span>) {132 133 //将每次得到的随机数加到新名字后134 135 $newname .= $str[mt_rand(0,strlen($str<span>))];136 137 <span>}138 139 // 加上后缀名140 141 $newname .= strrchr($filename, '.'<span>);142 143 return $newname<span>;144 145 <span>}146 147 ?&gt;</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre></div><p>&nbsp;</p><h4>3、文件下载</h4><p><a href="file:///C:/Users/%E6%9D%8E%E5%AD%90%E5%BD%AC/AppData/Local/Temp/OpenLiveWriter-559524038/supfiles270D5EE7/clipboard9.png" target="_blank" rel="noopener"><img title="clipboard" src="file:///C:/Users/%E6%9D%8E%E5%AD%90%E5%BD%AC/AppData/Local/Temp/OpenLiveWriter-559524038/supfiles270D5EE7/clipboard_thumb2.png" alt="clipboard" width="244" height="92" border="0"></a></p><h3>二、http协议</h3><h4>1、请求协议</h4><p>&nbsp;<strong>&nbsp;&nbsp; 1.1、组成：</strong>请求行、请求头、空行、请求数据</p><p>&nbsp;&nbsp;&nbsp; 1.1.1、请求行。分为三个部分：请求方式、请求路径、协议版本</p><p>&nbsp;&nbsp;&nbsp; 1.1.2、请求头。</p><p>&nbsp;&nbsp;&nbsp; 请求头就是所有当前需要用到的协议项的集合！</p><p>&nbsp;&nbsp;&nbsp; 协议项就是浏览器在请求服务器的时候事先告诉服务器的一些信息，而且每一个协议项都要单独的占用一行！</p><p>&nbsp;&nbsp; 常见的请求头：</p><ul><li>host：当前url中所要请求的服务器的主机名（域名）</li><li>accept-encoding：是浏览器发给服务器,声明浏览器支持的压缩编码类型 比如gzip</li><li>accept_charset：表示，浏览器支持的字符集</li><li>referer：表示，此次请求来自哪个网址</li><li>accept-language：可以接收的语言类型，cn，en等</li><li>cookie：</li><li>user-agent：用户代理，当前发起请求的浏览器的内核信息</li><li>accept：表示浏览器可以接收的数据类型，text/html，image/img</li><li>content-length（post）：只有post提交的时候才会有的请求头，显示当前提交的数据长度（字节）</li><li>if-modified-since（get）：在客户端向服务器请求某个资源文件时，询问此资源文件是否被修改过</li><li>content-type（post）：定义网络文件的类型和网页的编码，决定浏览器将以什么形式、编码读取这个文件</li></ul><p>&nbsp;&nbsp;&nbsp; 1.1.3、空行</p><p>&nbsp;&nbsp;&nbsp; 用来分离请求头和请求数据，意思就是请求头到处结束！</p><p>&nbsp;&nbsp;&nbsp; 1.1.4、请求数据</p><h4>2、响应协议</h4><p>&nbsp;&nbsp;&nbsp; 2.1、组成：响应行、响应头、空行、响应主体</p><h3>三、会话技术</h3><h4>1、cookie</h4><p>&nbsp;&nbsp;<strong>&nbsp; 1.1、基本操作</strong></p><ul><li>增删改：setCookie(名，值)</li><li>查：$_COOKIE</li></ul><p><strong>&nbsp;&nbsp; 1.2、属性</strong></p><ul><li>有效期：默认一个会话周期。可通过setCookie第三个参数设置；</li><li>有效路径：默认当前目录及其子目录。可通过第四个参数设置；</li><li>有效域：默认当前站点（子域），可通过第五个参数设置；</li><li>是否仅安全传输：默认否，第六个参数设置；</li><li>HTTPONLY：默认否，第七个参数设置。</li></ul><p><strong>&nbsp;&nbsp; 1.3、注意事项</strong></p><ul><li>cookie的值，仅仅支持字符串类型；</li><li>cookie的键（下标），可以写成数组下标的形式。</li></ul><h4>2、session</h4><p><strong>&nbsp;&nbsp;&nbsp; 2.1、基本操作</strong></p><p>&nbsp;&nbsp;&nbsp; 增删该查都是通过$_SESSION数组来完成的。</p><p><strong>&nbsp;&nbsp;&nbsp; 2.2、属性</strong></p><p>&nbsp;&nbsp;&nbsp; session的实现需要cookie的支持，它的属性和cookie的属性一样。</p><p><strong>&nbsp;&nbsp;&nbsp; 2.3、注意事项</strong></p><ul><li>session数据可以是任意类型的数据（cookie只能是字符串类型）</li><li>$_SESSION数组元素的下标只能是字符串型（关联型），不能是索引数组</li></ul><p><strong>&nbsp;&nbsp; 2.4、session的销毁</strong></p><ul><li>unset()：销毁session中某个数据，并没有销毁会话数据区；</li><li>$_SESSION = ARRAY()：清空$_SESSION，并没有销毁会话数据区；</li><li>session_desroy(()：销毁会话数据区。</li></ul><h4>3、cookie和session的区别</h4><table border="1" cellspacing="0" cellpadding="2"><tbody><tr><td valign="top" width="109">&nbsp;</td><td valign="top" width="184">cookie</td><td valign="top" width="106">session</td></tr><tr><td valign="top" width="109">存储位置</td><td valign="top" width="184">浏览器端</td><td valign="top" width="106">服务器端</td></tr><tr><td valign="top" width="109">数据量</td><td valign="top" width="184">大</td><td valign="top" width="106">小</td></tr><tr><td valign="top" width="109">存储的数据类型</td><td valign="top" width="184">只能是字符串</td><td valign="top" width="106">任意类型</td></tr><tr><td valign="top" width="109">安全性</td><td valign="top" width="184">较低</td><td valign="top" width="106">较高</td></tr><tr><td valign="top" width="109">默认的有效路径</td><td valign="top" width="184">只能是当前目录及其子目录</td><td valign="top" width="106">整站有效</td></tr></tbody></table><p>&nbsp;</p><h3>四、图像技术</h3><h4>1、GD图片制作</h4><p><strong>&nbsp;&nbsp;&nbsp; 1.1、创建画布</strong></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; imagecreatetruecolor(width,height);</p><p><strong>&nbsp;&nbsp;&nbsp; 1.2、创建画笔颜色</strong></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; imagecolorallocate(img,red,green,blue);</p><p><strong>&nbsp;&nbsp;&nbsp; 1.3、绘制文字（在画布上画画）</strong></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; imagestring(img,size,x,y,string,color);</p><p><strong>&nbsp;&nbsp;&nbsp; 1.4、输出或保存图片</strong></p><ul><li>输出：imagepng(图片资源);</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 输出前要：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1）、设置响应头信息：header("content-type:image/png");</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2）、清除缓存区数据：ob_clean();</p><ul><li>保存：imagepng(图片资源，路径/图片名称);</li></ul><h4>2、实现验证码</h4><p>captcha.php</p><div class="cnblogs_code"><pre> 1 &lt;?<span>php 2  3 # 1、创建画布 4  5 $canWidth = 170; // 画布的宽 6  7 $canHei = 40; // 画布的高 8  9 $img = imagecreatetruecolor($canWidth, $canHei<span>);10 11 # 2、为画布填充背景色12 13 $bgColor = imagecolorallocate($img, mt_rand(0,120), mt_rand(0,120), mt_rand(0,120<span>));14 15 imagefill($img, 1, 1, $bgColor<span>);16 17 #/3、定义在画布上的显示文字18 19 // 显示随机字符的范围20 21 $arr = array_merge(range('a', 'z'), range('A', 'Z'), range(0, 9<span>));22 23 // 得到指定位数的随机字符24 25 $str = ''<span>;26 27 shuffle($arr<span>);28 29 $charNum = 4; //验证码个数30 31 $keyArr = array_rand($arr,$charNum<span>);32 33 foreach ($keyArr as $value<span>) {34 35 $str .= $arr[$value<span>];36 37 <span>}38 39 // 4、将字符写入到画布40 41 $span = ceil($canWidth/($charNum+1<span>));42 43 for ($i=1; $i &lt;= $charNum; $i++<span>) {44 45 // 为画布创建画笔色46 47 $charColor = imagecolorallocate($img, mt_rand(120,255), mt_rand(120,255), mt_rand(120,255<span>));48 49 imagestring($img, 5, $span*$i, 12, $str[$i-1], $charColor<span>);50 51 <span>}52 53 // 5、创建干扰线54 55 for ($i=0; $i &lt; 8; $i++<span>) {56 57 //创建干扰线颜色58 59 $linColor = imagecolorallocate($img, mt_rand(75,150), mt_rand(75,150), mt_rand(75,150<span>));60 61 //创建干扰线62 63 imageline($img, mt_rand(0,$canWidth-1), mt_rand(0,$canHei-1), mt_rand(0,$canWidth-1), mt_rand(0,$canHei-1), $linColor<span>);64 65 <span>}66 67 // 6、显示图片68 69 header('content-type:image/png'<span>);70 71 ob_clean<span>();72 73 imagepng($img<span>);74 75 ?&gt;</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre></div><p>&nbsp;</p><h3>五、文件操作</h3><h4>1、目录基本操作</h4><ul><li>创建目录：mkdir(目录地址和名字,权限)；</li><li>删除删除：rmdir(目录地址)；</li><li>移动/重命名目录：rename(原始文件路径,新的文件路径)；</li></ul><p>（此处的移动实质上也是重命名，不过目录的名字不单单是文件名，还包括目录的路径，当我们改变目录的路径时，既是移动目录，也可以说是重命名；）</p><ul><li>获取目录内容：</li></ul><ol><li>打开目录，opendir，得到一个目录句柄（目录资源）；</li><li>依次读取目录内的文件，readdir；</li><li>关闭目录句柄（closedir）；</li></ol><p><strong>2、常用目录操作函数</strong></p><ul><li>getcwd：获取当前的工作路径；</li><li>chdir：改变当前的工作路径；</li><li>rewinddir：重置资源指针，回到第一个；</li><li>scandir：浏览某一目录，以索引数组的形式返回目录中内容。</li></ul><p><strong>3、递归遍历目录</strong></p><p>bianli.php</p><div class="cnblogs_code"><pre> 1 &lt;?<span>php 2  3 /** 4  5 * 递归遍历文件 6  7 * @param string $path 目录路径（地址） 8  9 * @param int $deep=0 当前目录的深度10 11 */12 13 function readDirs($path,$deep=0<span>) {14 15 $dir_handle = openDir($path); //得到$path目录的句柄16 17 while (false !== $file = readDir($dir_handle<span>)) {18 19 //筛选掉./和../20 21 if ($file == "." || $file == ".."<span>) {22 23 continue<span>;24 25 <span>}26 27 //输出文件28 29 echo str_repeat('-', $deep*3),$file,'&lt;br/&gt;'<span>;30 31 //进入递归点和递归出口32 33 if (is_dir($path . '/' .$file<span>)) {34 35 readDirs($path . '/' .$file,$deep+1<span>);36 37 <span>}38 39 <span>}40 41 <span>}42 43 $path = './'<span>;44 45 readDirs($path<span>);46 47 ?&gt;</span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre></div><p>&nbsp;</p><h4>2、文件操作</h4><p><strong>&nbsp;&nbsp;&nbsp; 2.1、文件基本操作</strong></p><ul><li><ul><li>读：file_get_contents；读取指定路径的文件内容，以字符串形式返回；</li><li>写：file_put_contents；覆盖写，往指定文件写入指定数据，并覆盖以前的内容。如果需要追加数据，则需要设置第三个参数FILE_APPEND；</li></ul></li></ul><p><strong>&nbsp;&nbsp;&nbsp; 2.2、常用文件函数</strong></p><ul><li>filetype：获取一个文件的类型。windows下文件类型有三种，dir、file、unknown。</li><li>file_exists：判断一个文件是否存在；</li><li>is_dir：判断一个文件是否是dir文件；</li><li>is_file：判断一个文件是否是file文件；&nbsp;</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>PHP环境搭建</title>
      <link href="/9/uncategorized/ck0669dme001lagaahyd32cmb/"/>
      <url>/9/uncategorized/ck0669dme001lagaahyd32cmb/</url>
      
        <content type="html"><![CDATA[<p><a href="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202155023-1218058624.png" target="_blank" rel="noopener"><img style="background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border: 0px;" title="lip_image002" src="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202155539-1763219213.png" alt="lip_image002" width="244" height="53" border="0"></a></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 首先要搞明白，apache、php和mysql三者的关系。在调用关系上，如上图所示。apache作为一个服务器，调用php模块处理php文件，而php则通过扩展，用mysql处理相关数据。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 其实所谓的配置环境就是 apache 调用 php 以及 php 扩展 mysql 的过程。</p><p><strong>1、apache 调用 php。</strong>（apache相当于一个老板，他需要招聘有各种能力的员工以完成工作）</p><p>&nbsp;&nbsp;&nbsp; 1）、在apache配置文件中，将PHP模块（php5_module）加载到 apache 中&nbsp; （PHP相当于被apache招聘的员工）</p><p>LoadModule php5_module "d:/wamp/php/php5apache2_2.dll"</p><p><a href="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202156164-454089025.png" target="_blank" rel="noopener"><img style="background-image: none; padding-top: 0px; padding-left: 0px; margin: 0px; display: inline; padding-right: 0px; border: 0px;" title="clipboard" src="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202157852-1022539553.png" alt="clipboard" width="244" height="172" border="0"></a></p><p>&nbsp;&nbsp;&nbsp; 2）、有了员工，当然要给员工分配任务，也就是在apache中将PHP文件交给php解析引擎处理</p><p><a href="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202158586-1316393906.png" target="_blank" rel="noopener"><img style="background-image: none; padding-top: 0px; padding-left: 0px; margin: 0px; display: inline; padding-right: 0px; border: 0px;" title="clipboard[1]" src="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202159273-1129178030.png" alt="clipboard[1]" width="244" height="59" border="0"></a></p><p>&nbsp;&nbsp;&nbsp; 3）、最后要在apache配置文件中加载php的配置文件</p><p><a href="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202159805-2032860626.png" target="_blank" rel="noopener"><img style="background-image: none; padding-top: 0px; padding-left: 0px; margin: 0px; display: inline; padding-right: 0px; border: 0px;" title="clipboard[2]" src="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202200445-795031211.png" alt="clipboard[2]" width="244" height="49" border="0"></a></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 在对应文件夹中增加 php.ini</p><p><a href="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202200992-1176862433.png" target="_blank" rel="noopener"><img style="background-image: none; padding-top: 0px; padding-left: 0px; margin: 0px; display: inline; padding-right: 0px; border: 0px;" title="clipboard[3]" src="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202201586-712955536.png" alt="clipboard[3]" width="244" height="135" border="0"></a></p><p>&nbsp;&nbsp;&nbsp; 4）、修改时区。由于系统时间的不稳定，所以在apache配置文件中要修改对应的时区信息</p><p><a href="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202202070-1440803649.png" target="_blank" rel="noopener"><img style="background-image: none; padding-top: 0px; padding-left: 0px; margin: 0px; display: inline; padding-right: 0px; border: 0px;" title="clipboard[4]" src="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202202648-1862378044.png" alt="clipboard[4]" width="244" height="53" border="0"></a></p><p><strong>2、php 扩展 mysql</strong></p><p>&nbsp;&nbsp;&nbsp; 其实就分为两个步骤：a、开启 php 的 mysql 扩展功能；b、告诉 php 在什么位置可以找到扩展文件</p><p>&nbsp;&nbsp;&nbsp; 1）、开启 php 的 mysql 扩展功能</p><p><a href="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202203102-1284793036.png" target="_blank" rel="noopener"><img style="background-image: none; padding-top: 0px; padding-left: 0px; margin: 0px; display: inline; padding-right: 0px; border: 0px;" title="clipboard[5]" src="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202203617-1273463352.png" alt="clipboard[5]" width="244" height="120" border="0"></a></p><p>&nbsp;&nbsp;&nbsp; 2）、告知PHP在哪个目录下能找到扩展文件</p><p><a href="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202204008-1512233414.png" target="_blank" rel="noopener"><img style="background-image: none; padding-top: 0px; padding-left: 0px; margin: 0px; display: inline; padding-right: 0px; border: 0px;" title="clipboard[6]" src="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202204492-16148322.png" alt="clipboard[6]" width="244" height="125" border="0"></a></p><p><strong>3、虚拟主机的配置</strong></p><p>所谓的虚拟主机，其实就是将你电脑上的某个文件夹与特定的域名联系起来。主要有域名和文件夹路径两部分。</p><p>&nbsp;&nbsp;&nbsp; 1）、首先要在 apache 配置文件中加载虚拟主机的配置文件（因为虚拟主机的配置文件在 apache 配置文件中是默认没有加载的）</p><p><a href="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202205148-1736182518.png" target="_blank" rel="noopener"><img style="background-image: none; padding-top: 0px; padding-left: 0px; margin: 0px; display: inline; padding-right: 0px; border: 0px;" title="clipboard[7]" src="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202205695-1825676395.png" alt="clipboard[7]" width="244" height="122" border="0"></a></p><p>&nbsp;&nbsp;&nbsp; 2）、在虚拟主机配置文件中创建虚拟主机</p><p><a href="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202206242-1862610262.png" target="_blank" rel="noopener"><img style="background-image: none; padding-top: 0px; padding-left: 0px; margin: 0px; display: inline; padding-right: 0px; border: 0px;" title="clipboard[8]" src="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202206836-724130420.png" alt="clipboard[8]" width="244" height="125" border="0"></a></p><p>&nbsp;&nbsp;&nbsp; 3）、配置本地的浏览器端域名解析</p><p><a href="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202207305-1965751552.png" target="_blank" rel="noopener"><img style="background-image: none; padding-top: 0px; padding-left: 0px; margin: 0px; display: inline; padding-right: 0px; border: 0px;" title="clipboard[9]" src="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202207758-1410731619.png" alt="clipboard[9]" width="244" height="103" border="0"></a></p><p><strong>4、目录访问权限</strong></p><p>&nbsp;&nbsp;&nbsp; 在 apache 的配置文件中，除了单独设置访问权限的目录，其它所有的目录都是被默认为拒绝访问的。也就说，当你配置虚拟主机后，一定要给对应的文件夹加上访问权限。也因此，我们一般将配置的访问权限的指令段和虚拟主机的配置放在一起，方便管理。如下图：</p><p><a href="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202208148-831295409.png" target="_blank" rel="noopener"><img style="background-image: none; padding-top: 0px; padding-left: 0px; margin: 0px; display: inline; padding-right: 0px; border: 0px;" title="clipboard[10]" src="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202208539-86850821.png" alt="clipboard[10]" width="244" height="92" border="0"></a></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对目录进行权限设置后，我们会发现，有时候对目录的访问并没有得到想要的结果，这就与访问目录时的访问顺序有关。如下图，当我们访问目录时，所进行的两个步骤。</p><p><a href="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202208945-534114046.png" target="_blank" rel="noopener"><img style="background-image: none; padding-top: 0px; padding-left: 0px; margin: 0px; display: inline; padding-right: 0px; border: 0px;" title="lip_image002[1]" src="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202209523-156475466.png" alt="lip_image002[1]" width="244" height="171" border="0"></a></p><p>以上对目录的访问顺序，自然也出现了两个问题，什么时候显示索引页？什么时候显示目录？这就与下图中所示的两个配置 DirectoryIndex 和 Options 有关了。</p><p>&nbsp;&nbsp;&nbsp; DirectoryIndex 配置与索引页有关。当我们设置后面多个索引页时，会从左往右依次检索，一旦发现有此文件，便会立即执行。</p><p>&nbsp;&nbsp;&nbsp; 而 Options 则与展示目录列表有关。当我们设置此配置后，访问目录时，如果没有索引页，就会将被访问目录中的内容以列表的形式展示出来。</p><p><a href="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202209914-10746061.png" target="_blank" rel="noopener"><img style="background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border: 0px;" title="clipboard[11]" src="http://images2015.cnblogs.com/blog/861679/201609/861679-20160915202210508-10330267.png" alt="clipboard[11]" width="244" height="76" border="0"></a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
